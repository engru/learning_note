# 一、Redis 的线程模型

## 1.原理

​	Redis 内部使用文件事件处理器 `file event handler`，这个**文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型**。它采用 **IO 多路复用机制同时监听多个 socket**，根据 socket 上的事件来选择对应的事件处理器进行处理。

文件事件处理器的结构包含 4 个部分：

- 多个 socket
- IO 多路复用程序
- 文件事件分派器
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

> 多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。

来看客户端与 Redis 的一次通信过程：

![Redis-single-thread-model](/Users/jack/Desktop/md/images/01-0249933.png)

- 客户端 socket01 向 Redis 的 server socket 请求建立连接，此时 server socket 会产生一个 `AE_READABLE` 事件，**IO 多路复用程序监听到 server socket 产生的事件后，将该事件压入队列中。文件事件分派器从队列中获取该事件，交给`连接应答处理器`。**==连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 `AE_READABLE` 事件与命令请求处理器关联。==
- 假设此时客户端发送了一个 `set key value` 请求，此时 Redis 中的 **socket01** 会产生 `AE_READABLE` 事件，IO 多路复用程序将事件压入队列，此时事件分派器从队列中获取到该事件，由于前面 socket01 的 `AE_READABLE` 事件已经与命令请求处理器关联，因此**事件分派器将事件交给命令请求处理器来处理**。命令请求处理器读取 socket01 的 `key value` 并在自己内存中完成 `key value` 的设置。操作完成后，它会将 socket01 的 `AE_WRITABLE` 事件与令回复处理器关联。
- 如果此时客户端准备好接收返回结果了，那么 Redis 中的 socket01 会产生一个 `AE_WRITABLE` 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，**由命令回复处理器对 socket01 输入本次操作的一个结果，比如 `ok`，之后解除 socket01 的 `AE_WRITABLE` 事件与命令回复处理器的关联。**

## 2.效率高的原因

1、纯内存操作。

> Redis 为了达到最快的读写速度，将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以 Redis 具有快速和数据持久化的特征。
>
> 如果不将数据放在内存中，磁盘 I/O 速度为严重影响 Redis 的性能。

**2、核心是基于非阻塞的 IO 多路复用机制。**

3、单线程反而避免了多线程的频繁上下文切换问题。

> Redis 利用队列技术，将并发访问变为串行访问，消除了传统数据库串行控制的开销

4、Redis 全程使用 hash 结构，读取速度快，还有一些特殊的数据结构，对数据存储进行了优化，如压缩表，对短数据进行压缩存储，再如，跳表，使用有序的数据结构加快读取的速度。

​	可以在同一个服务器部署多个 Redis 的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果想使用多个 CPU ，可以考虑一下分区。

# 二、Redis持久化

Redis 提供了两种方式，实现数据的持久化到硬盘。

- 1、【全量】RDB 持久化，是指在指定的时间间隔内将内存中的**数据集快照**写入磁盘。实际操作过程是，fork 一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。
- 2、【增量】AOF持久化，以日志的形式记录服务器所处理的每一个**写、删除操作**，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。

## **RDB 优缺点**

① 优点

- **灵活设置备份频率和周期。**你可能打算每个小时归档一次最近 24 小时的数据，同时还要每天归档一次最近 30 天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。

- **非常适合冷备份，对于灾难恢复而言，RDB 是非常不错的选择。**因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。推荐，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说 Amazon 的 S3 云服务上去，在国内可以是阿里云的 OSS 分布式存储上。

- **性能最大化。**对于 Redis 的服务进程而言，在开始持久化时，它唯一需要做的只是 fork 出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行 IO 操作了。也就是说，RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis 保持高性能。

  > 一个进程，包括代码、数据和分配给进程的资源。fork（）函数通过系统调用创建一个与原来进程几乎完全相同的进程，也就是两个进程可以做完全相同的事，但如果初始参数或者传入的变量不同，两个进程也可以做不同的事。
  > 一个进程调用fork（）函数后，系统先给新的进程分配资源，例如存储数据和代码的空间。然后把原来的进程的所有值都复制到新的新进程中，只有少数值与原来的进程的值不同。相当于克隆了一个自己。

- **恢复更快。相比于 AOF 机制，RDB 的恢复速度更更快，更适合恢复数据，特别是在数据集非常大的情况。**

② 缺点

- 如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么 RDB 将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。

  > 所以，RDB 实际场景下，需要和 AOF 一起使用。

- 由于 RDB 是通过 fork 子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是 1 秒钟。

  > 所以，RDB 建议在业务低估，例如在半夜执行。

## **AOF 优缺点**

① 优点

- 该机制可以带来更高的数据安全性，即数据持久性。**Redis 中提供了 3 种同步策略，即每秒同步、每修改(执行一个命令)同步和不同步。**
  - 事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。
  - 每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。
  - 不同步，则每次发生的数据变化不会同时记录到磁盘。
- 由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。
  - 因为以 append-only 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高。
  - 另外，如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在 Redis 下一次启动之前，我们可以通过 Redis-check-aof 工具来帮助我们解决数据一致性的问题。
- ==如果日志过大，Redis可以自动启用 **rewrite** 机制。==即使出现后台重写操作，也不会影响客户端的读写。因为在 rewrite log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。再创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。
- AOF 包含一个格式清晰、易于理解的日志文件用于记录所有的**修改操作**。事实上，我们也可以通过该文件完成数据的重建。

② 缺点

- **对于相同数量的数据集而言，AOF 文件通常要大于 RDB 文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。**
- 根据同步策略的不同，AOF 在运行效率上往往会慢于 RDB 。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和 RDB 一样高效。
- 以前 AOF 发生过 bug ，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志/merge/回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug 。不过 AOF 就是为了避免 rewrite 过程导致的 bug ，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。

**如何选择**

- 不要仅仅使用 RDB，因为那样会导致你丢失很多数据

- 也不要仅仅使用 AOF，因为那样有两个问题，第一，你通过 AOF 做冷备，没有 RDB 做冷备，来的恢复速度更快; 第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug 。

- Redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。

  - 如果同时使用 RDB 和 AOF 两种持久化机制，那么在 Redis 重启的时候，会使用 **AOF** 来重新构建数据，因为 AOF 中的**数据更加完整**。

    > 一般来说， 如果想达到足以媲美 PostgreSQL 的数据安全性， 你应该同时使用两种持久化功能。如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用 RDB 持久化。
    >
    > 有很多用户都只使用 AOF 持久化，但并不推荐这种方式：因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外，使用 RDB 还可以避免之前提到的 AOF 程序的 bug。

在 Redis4.0 版本开始，允许你使用 RDB-AOF 混合持久化方式，详细可见 [《Redis4.0 之 RDB-AOF 混合持久化》](https://yq.aliyun.com/articles/193034) 。也因此，RDB 和 AOF 同时使用，是希望达到安全的持久化的推荐方式。

> - bgsave 做镜像全量持久化，AOF 做增量持久化。因为 bgsave 会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要 AOF 来配合使用。在 Redis 实例重启时，会使用 bgsave 持久化文件重新构建内存，再使用 AOF 重放近期的操作指令来实现完整恢复重启之前的状态。
> - 对方追问那如果突然机器掉电会怎样？取决于 AOF 日志 sync 属性的配置，如果不要求性能，在每条写指令时都 sync 一下磁盘，就不会丢失数据。但是在高性能的要求下每次都 sync 是不现实的，一般都使用定时 sync ，比如 1 秒 1 次，这个时候最多就会丢失 1 秒的数据。
> - 对方追问 bgsave 的原理是什么？你给出两个词汇就可以了，fork 和 cow 。fork 是指 Redis 通过创建子进程来进行 bgsave 操作。cow 指的是 copy on write ，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。这里 bgsave 操作后，会产生 RDB 快照文件。

为什么不建议在主 Redis 节点开启 RDB 功能呢？因为会带来一定时间的阻塞，特别是数据量大的时候。

> - 子进程/fork相关的阻塞：在bgsave的时候，Redis主进程会fork一个子进程，利用操作系统的写时复制技术，这个子进程在拷贝父进程的时候理论上是很快的，因为并不需要全拷贝，比如主进程虽然占了10g内存，但子进程拷贝他可能只要200毫秒，也就阻塞了200毫秒(此耗时基本跟主进程占用的内存是成正比的)，这个具体的时间可以通过统计项info stats 里的last_fork_usec查看。
> - cpu/单线程相关的阻塞：**Redis主进程是单线程跑在单核cpu上的，如果显示绑定了CPU，则子进程会与主进程共享一个CPU，而子进程进行持久化的时候是非常占CPU（强势90%），因此这种情况也可能导致提供服务的主进程发生阻塞（因此如果需要持久化功能，不建议绑定CPU）；**
> - 内存相关的阻塞：**虽然利用写时复制技术可以大大降低进程拷贝的内存消耗，但这也导致了父进程在处理写请求时需要维护修改的内存页，因此这部分内存过大的话（修改页数多或每页占空间大）也会导致父进程的写操作阻塞。**（而不巧的是，Linux中TransparentHugePage会将复制内存页面单位有4K变成2M，这对于Redis来说是比较不友好的，也是建议优化的，具体可度之）
> - 磁盘相关的阻塞：极端情况下，假设整个机器的内存已经所剩无几，触发了内存交换（SWAP），则整个Redis的效率将会非常低下（显然这不仅仅针对save/bgsave），因此，关注系统的io情况，也是定位阻塞问题的一种方法。

# 三、Redis的“过期”和“淘汰”策略

## 1.“过期”策略

Redis 的过期策略，就是指当 Redis 中缓存的 key 过期了，Redis 如何处理。

Redis 提供了 3 种数据过期策略：

- 被动删除：当读/写一个已经过期的 key 时，会触发惰性删除策略，直接删除掉这个过期 key 。

  > 只有key被操作时(如GET)，REDIS才会被动检查该key是否过期，如果过期则删除之并且返回NIL。
  >
  > 1、这种删除策略对CPU是友好的，删除操作只有在不得不的情况下才会进行，不会其他的expire key上浪费无谓的CPU时间。
  >
  > 2、但是这种策略对内存不友好，一个key已经过期，但是在它被操作之前不会被删除，仍然占据内存空间。如果有大量的过期键存在但是又很少被访问到，那会造成大量的内存空间浪费。expireIfNeeded(redisDb *db, robj *key)函数位于src/db.c。
  >
  > 但仅是这样是不够的，**因为可能存在一些key永远不会被再次访问到，这些设置了过期时间的key也是需要在过期后被删除的，我们甚至可以将这种情况看作是一种内存泄露----无用的垃圾数据占用了大量的内存，而服务器却不会自己去释放它们，这对于运行状态非常依赖于内存的Redis服务器来说，肯定不是一个好消息**

- 主动删除：由于惰性删除策略无法保证冷数据被及时删掉，所以 Redis 会定期主动淘汰一批已过期的 key 。

  > 先说一下时间事件，对于持续运行的服务器来说， 服务器需要定期对自身的资源和状态进行必要的检查和整理， 从而让服务器维持在一个健康稳定的状态， 这类操作被统称为常规操作（cron job）。
  >
  > 在 Redis 中， 常规操作由 `redis.c/serverCron` 实现， 它主要执行以下操作：
  >
  > - 更新服务器的各类统计信息，比如时间、内存占用、数据库占用情况等。
  > - 清理数据库中的过期键值对。
  > - 对不合理的数据库进行大小调整。
  > - 关闭和清理连接失效的客户端。
  > - 尝试进行 AOF 或 RDB 持久化操作。
  > - 如果服务器是主节点的话，对附属节点进行定期同步。
  > - 如果处于集群模式的话，对集群进行定期同步和连接测试。
  >
  > Redis 将 `serverCron` 作为时间事件来运行， 从而确保它每隔一段时间就会自动运行一次， 又因为 `serverCron` 需要在 Redis 服务器运行期间一直定期运行， 所以它是一个循环时间事件： `serverCron` 会一直定期执行，直到服务器关闭为止。
  >
  > 在 Redis 2.6 版本中， 程序规定 `serverCron` 每秒运行 `10` 次， 平均每 `100` 毫秒运行一次。 从 Redis 2.8 开始， 用户可以通过修改 `hz`选项来调整 `serverCron` 的每秒执行次数， 具体信息请参考 `redis.conf` 文件中关于 `hz` 选项的说明。

- maxmemory：当前已用内存超过 maxmemory 限定时，触发主动清理策略，即 [「数据“淘汰”策略」](http://svip.iocoder.cn/Redis/Interview/#) 。

  > 当前已用内存超过maxmemory限定时，触发**主动清理**策略：
  >
  > - volatile-lru：只对设置了过期时间的key进行LRU（默认值）
  > - allkeys-lru ： 删除lru算法的key
  > - volatile-random：随机删除即将过期key
  > - allkeys-random：随机删除
  > - volatile-ttl ： 删除即将过期的
  > - noeviction ： 永不过期，返回错误当mem_used内存已经超过maxmemory的设定，对于所有的读写请求，都会触发redis.c/freeMemoryIfNeeded(void)函数以清理超出的内存。注意这个清理过程是阻塞的，直到清理出足够的内存空间。所以如果在达到maxmemory并且调用方还在不断写入的情况下，可能会反复触发主动清理策略，导致请求会有一定的延迟。 
  >
  > 当mem_used内存已经超过maxmemory的设定，对于所有的读写请求，都会触发redis.c/freeMemoryIfNeeded(void)函数以清理超出的内存。注意这个清理过程是阻塞的，直到清理出足够的内存空间。所以如果在达到maxmemory并且调用方还在不断写入的情况下，可能会反复触发主动清理策略，导致请求会有一定的延迟。
  >
  > 清理时会根据用户配置的maxmemory-policy来做适当的清理（一般是LRU或TTL），这里的LRU或TTL策略并不是针对redis的所有key，而是以配置文件中的maxmemory-samples个key作为样本池进行抽样清理。
  >
  > maxmemory-samples在redis-3.0.0中的默认配置为5，如果增加，会提高LRU或TTL的精准度，redis作者测试的结果是当这个配置为10时已经非常接近全量LRU的精准度了，并且增加maxmemory-samples会导致在主动清理时消耗更多的CPU时间，建议：
  >
  > - 尽量不要触发maxmemory，最好在mem_used内存占用达到maxmemory的一定比例后，需要考虑调大hz以加快淘汰，或者进行集群扩容。
  > - 如果能够控制住内存，则可以不用修改maxmemory-samples配置；如果Redis本身就作为LRU cache服务（这种服务一般长时间处于maxmemory状态，由Redis自动做LRU淘汰），可以适当调大maxmemory-samples。

在 Redis 中，同时使用了上述 3 种策略，即它们**非互斥**的。

参照： [《关于 Redis 数据过期策略》](https://www.cnblogs.com/chenpingzhao/p/5022467.html)

## 2.“淘汰”策略

Redis 内存数据集大小上升到一定大小的时候，就会进行数据淘汰策略。

### 数据淘汰策略：

> **volatile-lru策略和volatile-random策略适合我们将一个Redis实例既应用于缓存和又应用于持久化存储的时候，然而我们也可以通过使用两个Redis实例来达到相同的效果，值得一提的是将key设置过期时间实际上会消耗更多的内存，因此我们建议使用allkeys-lru策略从而更有效率的使用内存。**

1. volatile-lru

   > 从已设置过期时间的数据集中挑选**最近最少使用的数据淘汰**。redis并不是保证取得所有数据集中最近最少使用的键值对，而只是随机挑选的几个键值对中的， 当内存达到限制的时候无法写入非过期时间的数据集。
   >
   > 

2. volatile-ttl

   > 从已设置过期时间的数据集中挑选**将要过期的数据淘汰**。redis 并不是保证取得所有数据集中最近将要过期的键值对，而只是随机挑选的几个键值对中的， 当内存达到限制的时候无法写入非过期时间的数据集。
   >
   > 这种策略使得我们可以向Redis提示哪些key更适合被eviction。

3. volatile-random

   > 从已设置过期时间的数据集中**任意选择数据淘汰**。当内存达到限制的时候无法写入非过期时间的数据集。

4. allkeys-lru

   > **从数据集中挑选最近最少使用的数据淘汰。**当内存达到限制的时候，对所有数据集挑选最近最少使用的数据淘汰，可写入新的数据集。
   >
   > ==如果我们的应用对缓存的访问符合幂律分布，也就是存在相对热点数据，或者我们不太清楚我们应用的缓存访问分布状况，我们可以选择allkeys-lru策略。==可保证热点数据不要被淘汰

5. allkeys-random

   > **从数据集中任意选择数据淘汰**，当内存达到限制的时候，对所有数据集挑选随机淘汰，可写入新的数据集。
   >
   > **如果我们的应用对于缓存key的访问概率相等，则可以使用这个策略。**

6. no-enviction

   > 当内存达到限制的时候，不淘汰任何数据，不可写入任何数据集，所有引起申请内存的命令会报错。

### 配置：

通过配置redis.conf中的maxmemory这个值来开启内存淘汰功能：# maxmemory ；值得注意的是，maxmemory为0的时候表示我们对Redis的内存使用没有限制。根据应用场景，选择淘汰策略：# maxmemory-policy noeviction。

### 内存淘汰的过程：

> 首先，客户端发起了需要申请更多内存的命令（如set）。
>
> 然后，Redis检查内存使用情况，如果已使用的内存大于maxmemory则开始根据用户配置的不同淘汰策略来淘汰内存（key），从而换取一定的内存。
>
> 最后，如果上面都没问题，则这个命令执行成功。

### 动态改配置命令

此外，redis支持动态改配置，无需重启。

设置最大内存

```
config set maxmemory 100000
```

设置淘汰策略

```
config set maxmemory-policy noeviction
```

参照： [《Redis实战（二） 内存淘汰机制》](http://blog.720ui.com/2016/redis_action_02_maxmemory_policy/)

# 四、Redis数据结构

- 字符串 String
- 字典Hash
- 列表List
- 集合Set
- 有序集合 SortedSet

- HyperLogLog
- Geo
- Pub / Sub

- BloomFilter
- RedisSearch
- Redis-ML
- JSON

另外，在 Redis 5.0 增加了 Stream 功能，一个新的强大的支持多播的可持久化的消息队列，提供类似 Kafka 的功能。

# 五、Redis使用场景

## 缓存

对于热点数据，缓存以后可能读取数十万次，因此，对于热点数据，缓存的价值非常大。例如，分类栏目更新频率不高，但是绝大多数的页面都需要访问这个数据，因此读取频率相当高，可以考虑基于 Redis 实现缓存。

## 会话缓存

此外，还可以考虑使用 Redis 进行会话缓存。例如，将 web session 存放在 Redis 中。

## 时效性

例如验证码只有60秒有效期，超过时间无法使用，或者基于 Oauth2 的 Token 只能在 5 分钟内使用一次，超过时间也无法使用。

## 访问频率

出于减轻服务器的压力或防止恶意的洪水攻击的考虑，需要控制访问频率，例如限制 IP 在一段时间的最大访问量。

## 计数器

数据统计的需求非常普遍，通过原子递增保持计数。例如，应用数、资源数、点赞数、收藏数、分享数等。

## 社交列表

社交属性相关的列表信息，例如，用户点赞列表、用户分享列表、用户收藏列表、用户关注列表、用户粉丝列表等，使用 Hash 类型数据结构是个不错的选择。

## 记录用户判定信息

记录用户判定信息的需求也非常普遍，可以知道一个用户是否进行了某个操作。例如，用户是否点赞、用户是否收藏、用户是否分享等。

## 交集、并集和差集

在某些场景中，例如社交场景，通过交集、并集和差集运算，可以非常方便地实现共同好友，共同关注，共同偏好等社交关系。

## 热门列表与排行榜

按照得分进行排序，例如，展示最热、点击率最高、活跃度最高等条件的排名列表。

## 最新动态

按照时间顺序排列的最新动态，也是一个很好的应用，可以使用 Sorted Set 类型的分数权重存储 Unix 时间戳进行排序。

## 消息队列

Redis 能作为一个很好的消息队列来使用，依赖 List 类型利用 LPUSH 命令将数据添加到链表头部，通过 BRPOP 命令将元素从链表尾部取出。同时，市面上成熟的消息队列产品有很多，例如 RabbitMQ。因此，更加建议使用 RabbitMQ 作为消息中间件。

## 秒杀

- 提前预热数据，放入Redis
- 商品列表放入Redis List
- 商品的详情数据 Redis hash保存，设置过期时间
- 商品的库存数据Redis sorted set保存
- 用户的地址信息Redis set保存
- 订单产生扣库存通过Redis制造分布式锁，库存同步扣除
- 订单产生后发货的数据，产生Redis list，通过消息队列处理
- 秒杀结束后，再把Redis数据和数据库进行同步
- 可能还会引入http缓存，或者将消息对接用MQ代替等方案

> **1、显示最新的项目列表**
>  下面这个语句常用来显示最新项目，随着数据多了，查询毫无疑问会越来越慢。
>
> ```
> SELECT * FROM foo WHERE … ORDER BY time DESC LIMIT 10
> ```
>
> 在Web应用中，“列出最新的回复”之类的查询非常普遍，这通常会带来可扩展性问题。
> 比如说，我们的一个Web应用想要列出用户贴出的最新20条评论。在最新的评论边上我们有一个“显示全部”的链接，点击后就可以获得更多的评论。
>  我们假设数据库中的每条评论都有一个唯一的递增的ID字段，可以使用分页来制作主页和评论页，使用Redis的模板，每次新评论发表时，我们会将它的ID添加到一个Redis列表：`LPUSH latest.comments`
>  我们将列表裁剪为指定长度，因此Redis只需要保存最新的5000条评论： `LTRIM latest.comments 0 5000`
>  每次我们需要获取最新评论的项目范围时，我们调用一个函数来完成(使用伪代码)：
>
> ```lua
> FUNCTION get_latest_comments(start, num_items):
> id_list = redis.lrange(“latest.comments”,start,start+num_items – 1)
> IF id_list.length < num_items
> id_list = SQL_DB(“SELECT … ORDER BY time LIMIT …”)
> END
> RETURN id_list
> END
> ```
>
> 这里我们做的很简单。在Redis中我们的最新ID使用了常驻缓存，这是一直更新的。但是我们做了限制不能超过5000个ID，因此我们的获取ID函数会一直询问Redis。只有在start/count参数超出了这个范围的时候，才需要去访问数据库。
>  我们的系统不会像传统方式那样“刷新”缓存，Redis实例中的信息永远是一致的。SQL数据库(或是硬盘上的其他类型数据库)只是在用户需要获取“很远”的数据时才会被触发，而主页或第一个评论页是不会麻烦到硬盘上的数据库了。
>  **2、删除与过滤**
>  我们可以使用LREM来删除评论。如果删除操作非常少，另一个选择是直接跳过评论条目的入口，报告说该评论已经不存在。
>  有些时候你想要给不同的列表附加上不同的过滤器。如果过滤器的数量受到限制，你可以简单的为每个不同的过滤器使用不同的Redis列表。毕竟每个列表只有5000条项目，但Redis却能够使用非常少的内存来处理几百万条项目。
>  **3、排行榜相关**
>  ==另一个很普遍的需求是各种数据库的数据并非存储在内存中，因此在按得分排序以及实时更新这些几乎每秒钟都需要更新的功能上数据库的性能不够理想。==
>  典型的比如那些在线游戏的排行榜，比如一个Facebook的游戏，根据得分你通常想要：
>  – 列出前100名高分选手
>  – 列出某用户当前的全球排名
>  这些操作对于Redis来说小菜一碟，即使你有几百万个用户，每分钟都会有几百万个新的得分。
>  模式是这样的，每次获得新得分时，我们用这样的代码：`ZADD leaderboard`
>  ****你可能用userID来取代username，这取决于你是怎么设计的。**
> **得到前100名高分用户很简单： `ZREVRANGE leaderboard 0 99`。**
>  **用户的全球排名也相似，只需要： `ZRANK leaderboard`。**
> **4、按照用户投票和时间排序**
>  排行榜的一种常见变体模式就像Reddit或Hacker News用的那样，新闻按照类似下面的公式根据得分来排序：
>  `score = points / time^alpha`
>  因此用户的投票会相应的把新闻挖出来，但时间会按照一定的指数将新闻埋下去。下面是我们的模式，当然算法由你决定。
>  模式是这样的，开始时先观察那些可能是最新的项目，例如首页上的1000条新闻都是候选者，因此我们先忽视掉其他的，这实现起来很简单。
>  每次新的新闻贴上来后，我们将ID添加到列表中，使用 `LPUSH + LTRIM`，确保只取出最新的1000条项目。
>  有一项后台任务获取这个列表，并且持续的计算这1000条新闻中每条新闻的最终得分。计算结果由ZADD命令按照新的顺序填充生成列表，老新闻则被清除。这里的关键思路是排序工作是由后台任务来完成的。
>  **5、处理过期项目**
>  另一种常用的项目排序是按照时间排序。我们使用unix时间作为得分即可。
>  模式如下：
>  – 每次有新项目添加到我们的非Redis数据库时，我们把它加入到排序集合中。这时我们用的是时间属性，current_time和time_to_live。
>  – 另一项后台任务使用ZRANGE…SCORES查询排序集合，取出最新的10个项目。如果发现unix时间已经过期，则在数据库中删除条目。
>  **6、计数**
>  Redis是一个很好的计数器，这要感谢INCRBY和其他相似命令。
>  我相信你曾许多次想要给数据库加上新的计数器，用来获取统计或显示新信息，但是最后却由于写入敏感而不得不放弃它们。
>  好了，现在使用Redis就不需要再担心了。有了原子递增(atomic increment)，你可以放心的加上各种计数，用GETSET重置，或者是让它们过期。
>  例如这样操作：
>
> ```
> INCR user: EXPIRE
> user: 60
> ```
>
> 你可以计算出最近用户在页面间停顿不超过60秒的页面浏览量，当计数达到比如20时，就可以显示出某些条幅提示，或是其它你想显示的东西。
>  **7、特定时间内的特定项目**
>  另一项对于其他数据库很难，但Redis做起来却轻而易举的事就是统计在某段特点时间里有多少特定用户访问了某个特定资源。比如我想要知道某些特定的注册用户或IP地址，他们到底有多少访问了某篇文章。
>  每次我获得一次新的页面浏览时我只需要这样做：
>  `SADD page:day1:`
>  当然你可能想用unix时间替换day1，比如time()-(time()%3600*24)等等。
>  想知道特定用户的数量吗?只需要使`用SCARD page:day1:`。
>  需要测试某个特定用户是否访问了这个页面?SISMEMBER page:day1: 。
>  **8、实时分析正在发生的情况，用于数据统计与防止垃圾邮件等**
>  我们只做了几个例子，但如果你研究Redis的命令集，并且组合一下，就能获得大量的实时分析方法，有效而且非常省力。使用Redis原语命令，更容易实施垃圾邮件过滤系统或其他实时跟踪系统。
>
> **9、Pub/Sub**
>  Redis的Pub/Sub非常非常简单，运行稳定并且快速。支持模式匹配，能够实时订阅与取消频道。
>  **10、队列**
>  你应该已经注意到像list push和list pop这样的Redis命令能够很方便的执行队列操作了，但能做的可不止这些：比如Redis还有list pop的变体命令，能够在列表为空时阻塞队列。
>  现代的互联网应用大量地使用了消息队列(Messaging)。消息队列不仅被用于系统内部组件之间的通信，同时也被用于系统跟其它服务之间的交互。消息队列的使用可以增加系统的可扩展性、灵活性和用户体验。非基于消息队列的系统，其运行速度取决于系统中最慢的组件的速度(注：短板效应)。而基于消息队列可以将系统中各组件解除耦合，这样系统就不再受最慢组件的束缚，各组件可以异步运行从而得以更快的速度完成各自的工作。
>  此外，当服务器处在高并发操作的时候，比如频繁地写入日志文件。可以利用消息队列实现异步处理。从而实现高性能的并发操作。

参照：[《聊聊 Redis 使用场景》](http://blog.720ui.com/2017/redis_core_use/)

- [《Redis 常见的应用场景解析》](https://zhuanlan.zhihu.com/p/29665317)









参照：[芋道源码](http://svip.iocoder.cn/Redis/Interview/)