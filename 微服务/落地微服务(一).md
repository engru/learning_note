# 一、服务发布和引用的实践

​	下面将以XML配置方式为例，来看看服务发布和引用的具体实践以及可能会遇到的问题。首先我们一起来看下XML配置方式，服务发布和引用的具体流程是什么样的。

## XML配置方式的服务发布和引用流程

### 1.服务提供者定义接口

​	**服务提供者发布服务之前首先要定义接口，声明接口名、传递参数以及返回值类型，然后把接口打包成JAR包发布出去**。

​	比如下面这段代码，声明了接口UserLastStatusService，包含两个方法getLastStatusId和getLastStatusIds，传递参数一个是long值、一个是long数组，返回值一个是long值、一个是map。

```java
package com.weibo.api.common.status.service;

public interface UserLastStatusService {
     * @param uids
     * @return
     */
    public long getLastStatusId(long uid);

    /**
     *
     * @param uids
     * @return
     */
    public Map<Long, Long> getLastStatusIds(long[] uids);
}
```

### 2.服务提供者发布接口

​	服务提供者发布的接口是通过在服务发布配置文件中定义接口来实现的。下面以一个具体的服务发布配置文件
user-last-status.xml进行展示说明，它定义了要发布的接口userLastStatusLocalService，对外暴露的协议是Motan协议，端口是8882。**并且针对两个方法getLastStatusId和getLastStatusIds，通过requestTimeout=300单独定义了超时时间是300ms，通过retries=0单独定义了调用失败后重试次数为0，也就是不重试。**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
      xmlns:context="http://www.springframework.org/schema/context"
      xmlns:aop="http://www.springframework.org/schema/aop" 
     xsi:schemaLocation="http://www.springframework.org/schema/context
            http://www.springframework.org/schema/context/spring-context-2.5.xsd
http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd
http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.5.xsd
">

   <motan:service ref="userLastStatusLocalService"
            requestTimeout="50" retries="2"    interface="com.weibo.api.common.status.service.UserLastStatusService"
            basicService="serviceBasicConfig" export="motan:8882">
   <motan:method name="getLastStatusId" requestTimeout="300"
              retries="0" />
   <motan:method name="getLastStatusIds" requestTimeout="300"
              retries="0" />
</motan:service>
</beans>
```

​	然后服务发布者在进程启动的时候，会加载配置文件user-last-status.xml，把接口对外暴露出去。

### 3.服务消费者引用接口

​	**服务消费者引用接口是通过在服务引用配置文件中定义要引用的接口，并把包含接口定义的JAR包引入到代码依赖中。**
​	下面以一个具体的服务引用配置文件user-last-status-client.xml来进行说明，它定义服务消费者引用了接口commonUserLastStatusService，接口通信协议是Motan。

```xml
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
      xmlns:context="http://www.springframework.org/schema/context"
      xmlns:aop="http://www.springframework.org/schema/aop" 
     xsi:schemaLocation="http://www.springframework.org/schema/context
            http://www.springframework.org/schema/context/spring-context-2.5.xsd
http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd
http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.5.xsd
">
   <motan:protocol name="motan" default="true" loadbalance="${service.loadbalance.name}" />
<motan:basicReferer id="userLastStatusServiceClientBasicConfig"
               protocol="motan"  />

<!-- 导出接口 -->
<motan:referer id="commonUserLastStatusService" interface="com.weibo.api.common.status.service.UserLastStatusService"
            basicReferer="userLastStatusServiceClientBasicConfig" />
</beans>
```

​	然后服务消费者在进程启动时，会加载配置文件user-last-status-client.xml来完成服务引用。

> 上面所列举的服务发布和引用流程看似比较简单，但在实际使用过程中，还是有很多坑的，比如在实际项目中经常会遇到这个问题：一个服务包含了多个接口，可能有上行接口也可能有下行接口，每个接口都有超时控制以及是否重试等配置，如果有多个服务消费者引用这个服务，是不是每个服务消费者都必须在服务引用配置文件中定义？

## 服务发布和引用的那些坑

​	在一个服务被多个服务消费者引用的情况下，由于业务经验的参差不齐，可能不同的服务消费者对服务的认知水平不一，比如某个服务可能调用超时了，最好可以重试来提供调用成功率。但可能有的服务消费者会忽视这一点，并没有在服务引用配置文件中配置接口调用超时重试的次数，因此最好是可以在服务发布的配置文件中预定义好类似超时重试次数，即使服务消费者没有在服务引用配置文件中定义，也能继承服务提供者的定义。这就是下面要讲的服务发布预定义配置。

### 1.服务发布预定义配置

​	以下面的服务发布配置文件server.xml为例，它提供了一个服务contentSliceRPCService，并且明确了其中三个方法的调用超时时间为500ms以及超时重试次数为3。

```xml
<motan:service ref="contentSliceRPCService"       interface="cn.sina.api.data.service.ContentSliceRPCService"
            basicService="serviceBasicConfig" export="motan:8882" >
   <motan:method name="saveContent" requestTimeout="500"
              retries="3" />
   <motan:method name="deleteContent" requestTimeout="500"
              retries="3" />
   <motan:method name="updateContent" requestTimeout="500"
              retries="3" />
</motan:service>
```

​	假设服务引用的配置文件client.xml的内容如下，那么**服务消费者就会默认继承服务发布配置文件中设置的方法调用的超时时间以及超时重试次数。**

```xml
<motan:referer id="contentSliceRPCService" interface="cn.sina.api.data.service.ContentSliceRPCService"     basicReferer="contentSliceClientBasicConfig" >
</motan:referer>
```

​	上面通过服务发布预定义配置可以解决多个服务消费者引用服务可能带来的配置复杂的问题，但可能还有这种情况：一个服务提供者发布的服务有上百个方法，并且每个方法都有各自的超时时间、重试次数等信息。服务消费者引用服务时，完全继承了服务发布预定义的各项配置。这种情况下，服务提供者所发布服务的详细配置信息都需要存储在注册中心中，这样服务消费者才能在实际引用时从服务发布预定义配置中继承各种配置。

​	这里就存在一种风险，**当服务提供者发生节点变更，尤其是在网络频繁抖动的情况下，所有的服务消费者都会从注册中心拉取最新的服务节点信息，就包括了服务发布配置中预定的各项接口信息，这个信息不加限制的话可能达到1M以上，如果同时有上百个服务消费者从注册中心拉取服务节点信息，在注册中心机器部署为百兆带宽的情况下，很有可能会导致网络带宽打满的情况发生。**

​	面对这种情况，最好的办法是==把服务发布端的详细服务配置信息转移到服务引用端，这样的话注册中心中就不需要存储服务提供者发布的详细服务配置信息了==。

### 2.服务引用定义配置

​	以下面的**服务发布**配置文件为例，它详细定义了服务userInfoService的各个方法的配置信息，比如超时时间和重试次数等。

```xml
<motan:service ref="userInfoService" requestTimeout="50" retries="2"                   interface="cn.sina.api.user.service.UserInfoService" basicService="serviceBasicConfig">
<motan:method name="addUserInfo" requestTimeout="300" retries="0"/>
    <motan:method name="updateUserPortrait" requestTimeout="300" retries="0"/>
    <motan:method name="modifyUserInfo" requestTimeout="300" retries="0"/>
    <motan:method name="addUserTags" requestTimeout="300" retries="0"/>
    <motan:method name="delUserTags" requestTimeout="300" retries="0"/>
    <motan:method name="processUserCacheByNewMyTriggerQ" requestTimeout="300" retries="0"/>
    <motan:method name="modifyObjectUserInfo" requestTimeout="300" retries="0"/>
    <motan:method name="addObjectUserInfo" requestTimeout="300" retries="0"/>
    <motan:method name="updateObjectUserPortrait" requestTimeout="300" retries="0"/>
    <motan:method name="updateObjectManager" requestTimeout="300" retries="0"/>
    <motan:method name="add" requestTimeout="300" retries="0"/>
    <motan:method name="deleteObjectManager" requestTimeout="300" retries="0"/>
    <motan:method name="getUserAttr" requestTimeout="300" retries="1" />
    <motan:method name="getUserAttrList" requestTimeout="300" retries="1" />
    <motan:method name="getAllUserAttr" requestTimeout="300" retries="1" />
    <motan:method name="getUserAttr2" requestTimeout="300" retries="1" />
</motan:service>
```

可以像下面一样，把服务userInfoService的详细配置信息转移到**服务引用**配置文件中。

```xml
<motan:referer id="userInfoService" interface="cn.sina.api.user.service.UserInfoService" basicReferer="userClientBasicConfig">
    <motan:method name="addUserInfo" requestTimeout="300" retries="0"/>
    <motan:method name="updateUserPortrait" requestTimeout="300" retries="0"/>
    <motan:method name="modifyUserInfo" requestTimeout="300" retries="0"/>
    <motan:method name="addUserTags" requestTimeout="300" retries="0"/>
    <motan:method name="delUserTags" requestTimeout="300" retries="0"/>
    <motan:method name="processUserCacheByNewMyTriggerQ" requestTimeout="300" retries="0"/>
    <motan:method name="modifyObjectUserInfo" requestTimeout="300" retries="0"/>
    <motan:method name="addObjectUserInfo" requestTimeout="300" retries="0"/>
    <motan:method name="updateObjectUserPortrait" requestTimeout="300" retries="0"/>
    <motan:method name="updateObjectManager" requestTimeout="300" retries="0"/>
    <motan:method name="add" requestTimeout="300" retries="0"/>
    <motan:method name="deleteObjectManager" requestTimeout="300" retries="0"/>
    <motan:method name="getUserAttr" requestTimeout="300" retries="1" />
    <motan:method name="getUserAttrList" requestTimeout="300" retries="1" />
    <motan:method name="getAllUserAttr" requestTimeout="300" retries="1" />
    <motan:method name="getUserAttr2" requestTimeout="300" retries="1" />
</motan:referer>
```

这样的话，**服务发布**配置文件可以简化为下面这段代码，信息精简了许多。

```xml
<motan:service ref="userInfoService" requestTimeout="50" retries="2"                   interface="cn.sina.api.user.service.UserInfoService" basicService="serviceBasicConfig">
</motan:service>
```

在进行类似的服务详细信息配置，由服务发布配置文件迁移到服务引用配置文件的过程时，尤其要注意迁移步骤问题。

### 3.服务配置升级

​	当引用服务的服务消费者众多，并且涉及多个部门，升级步骤就显得异常重要，通常可以按照下面步骤操作：

- 各个服务消费者在服务引用配置文件中添加服务详细信息。
- 服务提供者升级两台服务器，在服务发布配置文件中删除服务详细信息，并观察是否所有的服务消费者引用时都包含服务详细信息。
- 如果都包含，说明所有服务消费者均完成升级，那么服务提供者就可以删除服务发布配置中的服务详细信息。
- 如果有不包含服务详细信息的服务消费者，排查出相应的业务方进行升级，直至所有业务方完成升级。

## 总结

​	XML配置方式的服务发布和引用的具体流程，简单来说就是**服务提供者定义好接口，并且在服务发布配置文件中配置要发布的接口名，在进程启动时加载服务发布配置文件就可以对外提供服务了。而服务消费者通过在服务引用配置文件中定义相同的接口名，并且在服务引用配置文件中配置要引用的接口名，在进程启动时加载服务引用配置文件就可以引用服务了。**

​	在业务具体实践过程中可能会遇到引用服务的服务消费者众多，对业务的敏感度参差不齐的问题，所以在服务发布的时候，最好==预定义好接口的各种配置。在服务规模不大，业务比较简单的时候，这样做比较合适。但是对于复杂业务，虽然服务发布时预定义好接口的各种配置，但在引用的服务消费者众多且同时访问的时候，可能会引起网络风暴==。这种情况下，比较保险的方式是，把接口的各种配置放在服务引用配置文件里。

在进行服务配置升级过程时，要考虑好步骤，在所有服务消费者完成升级之前，服务提供者还不能把服务的详细信息去掉，否则可能会导致没有升级的服务消费者引用异常。

# 二、注册中心落地

​	在落地注册中心的过程中，需要解决一系列的问题，包括如何存储服务信息、如何注册节点、如何反注册、如何查询节点信息以及如何订阅服务变更等。

## 注册中心如何存储服务信息

​	注册中心是用来存储服务信息的，服务信息除了包含节点信息（IP和端口号）以外，还包含其他一些信息，比如请求失败时重试的次数、请求结果是否压缩等信息。因此**服务信息通常用JSON字符串来存储，包含多个字段，每个字段代表不同的含义**。除此之外，服务一般会分成多个不同的分组，每个分组的目的不同。一般来说有下面几种分组方式：

- 核心与非核心，从业务的核心程度来分。
- 机房，从机房的维度来分。
- 线上环境与测试环境，从业务场景维度来区分。

所以==注册中心存储的服务信息一般包含三部分内容：分组、服务名以及节点信息，节点信息又包括节点地址和节点其他信息。==从注册中心中获取的信息结构大致如下图所示。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/faef4be8f5d42f5e67f300d4b20158d8.png)

具体存储的时候，一般是按照“服务-分组-节点信息”三层结构来存储，可以用下图来描述。Service代表服务的具体分组，Cluster代表服务的接口名，节点信息用KV存储。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/1f8da1497fdf18d75bdcc13315ddcc46.jpg)

搞清楚了注册中心存储服务信息的原理后，再来看下注册中心具体是如何工作的，包括四个流程：

- 服务提供者注册流程。
- 服务提供者反注册流程。
- 服务消费者查询流程。
- 服务消费者订阅变更流程。

## 注册中心是如何工作的  

### 1、如何注册节点

​	服务注册流程可以用下面这张流程图来描述。

![img](https://static001.geekbang.org/resource/image/26/e6/26719c9b542a6dc0a8e9e4656489c2e6.png)

​	服务注册流程主要有下面几个步骤：

- 首先查看要注册的节点是否在白名单内？如果不在就抛出异常，在的话继续下一步。
- 其次要查看注册的Cluster（服务的接口名）是否存在？如果不存在就抛出异常，存在的话继续下一步。
- 然后要检查Service（服务的分组）是否存在？如果不存在则抛出异常，存在的话继续下一步。
- **最后将节点信息添加到对应的Service和Cluster下面的存储中。**

### 2、如何反注册

​	再来看下服务提供者节点反注册的流程，可以用下面这张流程图来描述。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/6d49ee407b74881ebaded01ef6181fff.png)

​	一般来说，节点反注册流程主要包含下面几个步骤：

- 查看Service（服务的分组）是否存在，不存在就抛出异常，存在就继续下一步。
- 查看Cluster（服务的接口名）是否存在，不存在就抛出异常，存在就继续下一步。
- 删除存储中Service和Cluster下对应的节点信息。
- 更新Cluster的sign值。

### 3、如何查询节点信息

​	关于服务消费者是如何从注册中心查询服务提供者的节点信息，可以用下面这张流程图来描述。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/2af5590e0a6f57c51905522b81263085.png)

​	服务消费者查询节点信息主要分为下面几个步骤：

- ==首先从localcache（本机内存）中查找==，如果没有就继续下一步。因为服务节点信息并不总是时刻变化的，并不需要每一次服务调用都要调用注册中心获取最新的节点信息，只需要在本机内存中保留最新的服务提供者的节点列表就可以，所以服务消费者要把服务信息存在本机内存。
- ==接着从snapshot（本地快照）中查找==，如果没有就继续下一步。因为服务消费者同注册中心之间的网络不一定总是可靠的，服务消费者重启时，本机内存中还不存在服务提供者的节点信息，如果此时调用注册中心失败，那么服务消费者就拿不到服务节点信息了，也就没法调用了。本地快照就是为了防止这种情况的发生，即使服务消费者重启后请求注册中心失败，依然可以读取本地快照，获取到服务节点信息，所以服务消费者要在本地磁盘存储一份服务提供者的节点信息的快照

### 4、如何订阅服务变更

​	服务消费者订阅服务提供者的变更信息可以用下面这张流程图来描述。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/d6db90f412fbc9b89a0cf94cda474af1.png)

主要分为下面几个步骤：

- 服务消费者从注册中心获取了服务的信息后，就订阅了服务的变化，会在本地保留Cluster的sign值。
- 服务消费者每隔一段时间，调用getSign()函数，从注册中心获取服务端该Cluster的sign值，并与本地保留的sign值做对比，如果不一致，就从服务端拉取新的节点信息，并更新localcache和snapshot。

> 以上就是服务注册和反注册、服务查询和服务订阅变更的基本流程。

## 注册与发现的几个问题

### 1、多注册中心

​	理论上对于一个服务消费者来说，同一个注册中心交互是最简单的。但是不可避免的是，服务消费者可能订阅了多个服务，多个服务可能是由多个业务部门提供的，而且每个业务部门都有自己的注册中心，提供的服务只在自己的注册中心里有记录。这样的话， **就要求服务消费者要具备在启动时，能够从多个注册中心订阅服务的能力。**

​	一般来说，还有一种情况是，一个服务提供者提供了某个服务，可能作为静态服务对外提供，有可能又作为动态服务对外提供，这两个服务部署在不同的注册中心，所以要求服务提供者在启动的时候，要能够同时向多个注册中心注册服务。

也就是说，对于服务消费者来说，要能够同时从多个注册中心订阅服务；对于服务提供者来说，要能够同时向多个注册中心注册服务。

### 2、并行订阅服务

​	通常一个服务消费者订阅了不止一个服务，可能一个服务消费者订阅了几十个不同的服务，每个服务都有自己的方法列表以及节点列表。服务消费者在服务启动时，会加载订阅的服务配置，调用注册中心的订阅接口，获取每个服务的节点列表并初始化连接。

​	如果采用了串行订阅的方式，每订阅一个服务，服务消费者调用一次注册中心的订阅接口，获取这个服务的节点列表并初始化连接，总共需要执行几十次这样的过程。在某些服务节点的初始化连接过程中，出现连接超时的情况，后续所有的服务节点的初始化连接都需要等待它完成，导致服务消费者启动变慢，最后耗费了将近五分钟时间来完成所有服务节点的初始化连接过程。

​	但是改成了并行订阅的方式，**每订阅一个服务就单独用一个线程来处理**，这样的话即使遇到个别服务节点连接超时，其他服务节点的初始化连接也不受影响，最慢也就是这个服务节点的初始化连接耗费的时间，最终所有服务节点的初始化连接耗时控制在了30秒以内。

### 3、批量反注册服务

​	**通常一个服务提供者节点提供不止一个服务，所以注册和反注册都需要多次调用注册中心。**在与注册中心的多次交互中，可能由于网络抖动、注册中心集群异常等原因，导致个别调用失败。对于注册中心来说，偶发的注册调用失败对服务调用基本没有影响，其结果顶多就是某一个服务少了一个可用的节点。**但偶发的反注册调用失败会导致不可用的节点残留在注册中心中，变成“僵尸节点”，但服务消费者端还会把它当成“活节点”，继续发起调用，最终导致调用失败。**

​	所以需要定时去清理注册中心中的“僵尸节点”。可以通过优化反注册逻辑，对于下线机器、节点销毁的场景，通过调用注册中心提供的批量反注册接口，一次调用就可以把该节点上提供的所有服务同时反注册掉，从而避了“僵尸节点”的出现。

### 4、服务变更信息增量更新

​	==服务消费者端启动时，除了会查询订阅服务的可用节点列表做初始化连接，还会订阅服务的变更，每隔一段时间从注册中心获取最新的服务节点信息标记sign，并与本地保存的sign值作比对，如果不一样，就会调用注册中心获取最新的服务节点信息。==

​	一般情况下，按照这个过程是没问题的，但是在网络频繁抖动时，服务提供者上报给注册中心的心跳可能会一会儿失败一会儿成功，这时候注册中心就会频繁更新服务的可用节点信息，导致服务消费者频繁从注册中心拉取最新的服务可用节点信息，严重时可能产生网络风暴，导致注册中心带宽被打满。**为了减少服务消费者从注册中心中拉取的服务可用节点信息的数据量，这个时候可以通过增量更新的方式，注册中心只返回变化的那部分节点信息，尤其在只有少数节点信息变更时，此举可以大大减少服务消费者从注册中心拉取的数据量，从而最大程度避免产生网络风暴。**

# 三、开源服务注册中心选型

​	当下主流的服务注册与发现的解决方案，主要有两种：

- 应用内注册与发现：注册中心提供服务端和客户端的SDK，业务应用通过引入注册中心提供的SDK，通过SDK与注册中心交互，来实现服务的注册和发现。
- 应用外注册与发现：业务应用本身不需要通过SDK与注册中心打交道，而是通过其他方式与注册中心交互，间接完成服务注册与发现。

## 两种典型的注册中心实现

### 1.应用内

​	采用应用内注册与发现的方式，最典型的案例要属Netflix开源的Eureka，官方架构图如下。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/d220f8970c8d7a4f4ea4677ec2cbd61c.jpg)

Eureka的架构主要由三个重要的组件组成：

- Eureka Server：注册中心的服务端，实现了服务信息注册、存储以及查询等功能。
- 服务端的Eureka Client：集成在服务端的注册中心SDK，服务提供者通过调用SDK，实现服务注册、反注册等功能。
- 客户端的Eureka Client：集成在客户端的注册中心SDK，服务消费者通过调用SDK，实现服务订阅、服务更新等功能。

### 2.应用外

​	采用应用外方式实现服务注册和发现，最典型的案例是开源注册中心Consul，它的架构图如下。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/da82d0cba1c49252e1ae48f91fcb543f.png)

​	可以看出来使用Consul实现应用外服务注册和发现主要依靠三个重要的组件：

- Consul：注册中心的服务端，实现服务注册信息的存储，并提供注册和发现服务。
- Registrator：一个开源的第三方服务管理器项目，它通过监听服务部署的Docker实例是否存活，来负责服务提供者的注册和销毁。
- Consul Template：定时从注册中心服务端获取最新的服务提供者节点列表并刷新LB配置（比如Nginx的upstream），这样服务消费者就通过访问Nginx就可以获取最新的服务提供者信息。

> ### 小结
>
> ​	这两种解决方案的不同之处在于应用场景，==应用内的解决方案一般适用于服务提供者和服务消费者同
> 属于一个技术体系；应用外的解决方案一般适合服务提供者和服务消费者采用了不同技术体系的业务场景，比如服务提供者提供的是C++服务，而服务消费者是一个Java应用，这时候采用应用外的解决方案就不依赖于具体一个技术体系。==**同时，对于容器化后的云应用来说，一般不适合采用应用内SDK的解决方案，因为这样会侵入业务，而应用外的解决方案正好能够解决这个问题。**

## 注册中心选型考虑的两个问题

​	在选择注册中心解决方案的时候，除了要考虑是采用应用内注册还是应用外注册的方式以外，还有两个最值得关注的问题，**一个是高可用性，一个是数据一致性。**

### 1.高可用性

​	注册中心作为服务提供者和服务消费者之间沟通的纽带，它的高可用性十分重要。试想，如果注册中心不可用了，那么服务提供者就无法对外暴露自己的服务，而服务消费者也无法知道自己想要调用的服务的具体地址，后果将不堪设想。实现高可用性的方法主要有两种：

- 集群部署，顾名思义就是通过部署多个实例组成集群来保证高可用性，这样的话即使有部分机器宕机，将访问迁移到正常的机器上就可以保证服务的正常访问。
- 多IDC部署，就是部署在不止一个机房，这样能保证即使一个机房因为断电或者光缆被挖断等不可抗力因素不可用时，仍然可以通过把请求迁移到其他机房来保证服务的正常访问。

> 以Consul为例，来看看它是如何通过这两种方法来保证注册中心的高可用性。
>
> ​	从下面的官方架构图中可以看到，==一方面，在每个数据中心（DATACENTER）内都有多个注册中心Server节点可供访问；另一方面还可以部署在多个数据中心来保证多机房高可用性。==
>
> ![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/c0661d7687e29927fdcecc0f140fb5ab.png)

### 2.数据一致性

​	为了保证注册中心的高可用性，注册中心的部署往往都采用集群部署，并且还通常部署在不止一个数据中心，这样的话就会引出另一个问题，多个数据中心之间如何保证数据一致？如何确保访问数据中心中任何一台机器都能得到正确的数据？

​	**这里就涉及分布式系统中著名的CAP理论，即同时满足一致性、可用性、分区容错性这三者是不可能的，其中C（Consistency）代表一致性，A（Availability）代表可用性，P（Partition Tolerance）代表分区容错性。**

> 在一个分布式系统里面，包含了多个节点，节点之间通过网络连通在一起。正常情况下，通过网络，从一个节点可以访问任何别的节点上的数据。但是有可能出现网络故障，导致整个网络被分成了互不连通的区域，这就叫作分区。
>
> 一旦出现分区，那么一个区域内的节点就没法访问其他节点上的数据了，最好的办法是把数据复制到其他区域内的节点，这样即使出现分区，也能访问任意区域内节点上的数据，这就是分区容错性。
>
> 但是把数据复制到多个节点就可能出现数据不一致的情况，这就是一致性。
>
> 要保证一致，就必须等待所有节点上的数据都更新成功才可用，这就是可用性。
>
> ==总的来说，就是数据节点越多，分区容错性越高，但数据一致性越难保证。为了保证数据一致性，又会带来可用性的问题。==

而注册中心一般采用分布式集群部署，也面临着CAP的问题，根据CAP不能同时满足，所以不同的注册中心解决方案选择的方向也就不同，大致可分为两种：

- **CP型注册中心，牺牲可用性来保证数据强一致性，最典型的例子就是ZooKeeper，etcd，Consul了。**ZooKeeper集群内只有一个Leader，而且在Leader无法使用的时候通过Paxos算法选举出一个新的Leader。这个Leader的目的就是保证写信息的时候只向这个Leader写入，Leader会同步信息到Followers，这个过程就可以保证数据的强一致性。但如果多个ZooKeeper之间网络出现问题，造成出现多个Leader，发生脑裂的话，注册中心就不可用了。而etcd和Consul集群内都是通过raft协议来保证强一致性，如果出现脑裂的话， 注册中心也不可用。
- **AP型注册中心，牺牲一致性来保证可用性，最典型的例子就是Eureka了。**对比下Zookeeper，Eureka不用选举一个Leader，每个Eureka服务器单独保存服务注册地址，因此有可能出现数据信息不一致的情况。但是当网络出现问题的时候，每台服务器都可以完成独立的服务。

而对于注册中心来说，最主要的功能是服务的注册和发现，在网络出现问题的时候，可用性的需求要远远高于数据一致性。即使因为数据不一致，注册中心内引入了不可用的服务节点，也可以通过其他措施来避免，比如客户端的快速失败机制等，只要实现最终一致性，对于注册中心来说就足够了。因此，**选择AP型注册中心，一般更加适。**

## 总结

​	总的来说，在选择开源注册中心解决方案的时候，要看业务的具体场景。如果你的业务体系都采用Java语言的话，Netflix开源的Eureka是一个不错的选择，并且它作为服务注册与发现解决方案，能够最大程度的保证可用性，即使出现了网络问题导致不同节点间数据不一致，你仍然能够访问Eureka获取数据。如果你的业务体系语言比较复杂，Eureka也提供了**Sidecar**的解决方案；也可以考虑使用Consul，它支持了多种语言接入，包括Go、Python、PHP、Scala、Java，Erlang、Ruby、Node.js、.NET、Perl等。如果你的业务已经是云原生的应用，可以考虑使用Consul，搭配Registrator和Consul Template来实现应用外的服务注册与发现。

> ==Sidecar模式是一种将应用功能从应用本身剥离出来作为单独进程的方式。该模式允许我们向应用无侵入添加多种功能，避免了为满足第三方组件需求而向应用添加额外的配置代码。==

# 四、开源RPC框架选型

​	**一个完整的RPC框架主要有三部分组成：通信框架、通信协议、序列化和反序列化格式。**目前业界应用比较广泛的开源RPC框架简单划分的话，主要分为两类：**一类是跟某种特定语言平台绑定的，另一类是与语言无关即跨语言平台的**。跟语言平台绑定的开源RPC框架主要有下面几种：

- Dubbo：国内最早开源的RPC框架，由阿里巴巴公司开发并于2011年末对外开源，仅支持Java语言。
- Motan：微博内部使用的RPC框架，于2016年对外开源，仅支持Java语言。
- Tars：腾讯内部使用的RPC框架，于2017年对外开源，仅支持C++语言。
- Spring Cloud：国外Pivotal公司2014年对外开源的RPC框架，仅支持Java语言，最近几年生态发展得比较好，是比较火的RPC框架。

而跨语言平台的开源RPC框架主要有以下几种：

- gRPC：Google于2015年对外开源的跨语言RPC框架，支持常用的C++、Java、Python、Go、Ruby、PHP、Android Java、Objective-C等多种语言。
- Thrift：最初是由Facebook开发的内部系统跨语言的RPC框架，2007年贡献给了Apache基金，成为Apache开源项目之一，支持常用的C++、Java、PHP、Python、Ruby、Erlang等多种语言。

所以很明显，**如果你的业务场景仅仅局限于一种语言的话，可以选择跟语言绑定的RPC框架中的一种；如果涉及多个语言平台之间的相互调用，就应该选择跨语言平台的RPC框架，**下面分别来看看几种比较常用的框架。

## 限定语言平台的开源RPC框架

### ==1.Dubbo==

​	Dubbo可以说是国内开源最早的RPC框架了，目前只支持Java语言，它的架构可以用下面这张图展示：

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/7114e779d5e8a20ad9986b8ebc52f2f3.jpg)

从图中你可以看到，**Dubbo的架构主要包含四个角色，其中Consumer是服务消费者，Provider是服务提供者，Registry是注册中心，Monitor是监控系统。**

​	==具体的交互流程是Consumer一端通过注册中心获取到Provider节点后，通过Dubbo的客户端SDK与Provider建立连接，并发起调用。Provider一端通过Dubbo的服务端SDK接收到Consumer的请求，处理后再把结果返回给Consumer。==

​	可以看出服务消费者和服务提供者都需要引入Dubbo的SDK才来完成RPC调用，因为Dubbo本身是采用Java语言实现的，所以要求服务消费者和服务提供者也都必须采用Java语言实现才可以应用，下面再来看下Dubbo的调用框架是如何实现的。

- 通信框架方面，Dubbo默认采用了Netty作为通信框架。
- 通信协议方面，Dubbo除了支持私有的Dubbo协议外，还支持RMI协议、Hession协议、HTTP协议、Thrift协议等。
- 序列化格式方面，Dubbo 支持多种序列化格式，比如 Dubbbo、Hession、JSON、Kryo、FST 等。

### ==2.Motan==

​	Motan是国内另外一个比较有名的开源的RPC框架，同样也只支持Java语言实现，它的架构可以用下面这张图描述。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/08044dcbdbaaedb30222695be29bc119.jpg)

Motan与Dubbo的架构类似，都需要在Client端（服务消费者）和Server端（服务提供者）引入SDK，其中Motan框架主要包含下面几个功能模块：

- register：用来和注册中心交互，包括注册服务、订阅服务、服务变更通知、服务心跳发送等功能。Server端会在系统初始化时通过register模块注册服务，Client端会在系统初始化时通过register模块订阅到具体提供服务的Server列表，当Server列表发生变更时也由register模块通知Client。
- protocol：用来进行RPC服务的描述和RPC服务的配置管理，这一层还可以添加不同功能的filter用来完成统计、并发限制等功能。
- serialize：将RPC请求中的参数、结果等对象进行序列化与反序列化，即进行对象与字节流的互相转换，默认使用对Java更友好的Hessian  2进行序列化。
- transport：用来进行远程通信，默认使用Netty NIO的TCP长链接方式。
- cluster：Client端使用的模块，cluster是一组可用的Server在逻辑上的封装，包含若干可以提供RPC服务的Server，实际请求时会根据不同的高可用与负载均衡策略选择一个可用的Server发起远程调用。

### 3.Tars

​	Tars是腾讯根据内部多年使用微服务架构的实践，总结而成的开源项目，仅支持C++语言，它的架构图如下。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/e207486467e03ded669380f39aadf098.png)

​	Tars的架构交互主要包括以下几个流程：

- 服务发布流程：在web系统上传server的发布包到patch，上传成功后，在web上提交发布server请求，由registry服务传达到node，然后node拉取server的发布包到本地，拉起server服务。
- 管理命令流程：web系统上的可以提交管理server服务命令请求，由registry服务传达到node服务，然后由node向server发送管理命令。
- 心跳上报流程：server服务运行后，会定期上报心跳到node，node然后把服务心跳信息上报到registry服务，由registry进行统一管理。
- 信息上报流程：server服务运行后，会定期上报统计信息到stat，打印远程日志到log，定期上报属性信息到
  prop、上报异常信息到notify、从config拉取服务配置信息。
- client访问server流程：client可以通过server的对象名Obj间接访问server，client会从registry上拉取server的路由信息（如IP、Port信息），然后根据具体的业务特性（同步或者异步，TCP或者UDP方式）访问server（当然client也可以通过IP/Port直接访问server）。

### 4.Spring Cloud

​	Spring Cloud是为了解决微服务架构中服务治理而提供的一系列功能的开发框架，它是完全基于Spring Boot
进行开发的，Spring Cloud利用Spring Boot特性整合了开源行业中优秀的组件，整体对外提供了一套在微服务架构中服务治理的解决方案。因为Spring Boot是用Java语言编写的，所以目前Spring Cloud也只支持Java语言平台，它的架构图可以用下面这张图来描述。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/d71df127a2c40acf06b3fba6deb42501.png)

由此可见，Spring Cloud微服务架构是由多个组件一起组成的，各个组件的交互流程如下：

- 请求统一通过API网关Zuul来访问内部服务，先经过Token进行安全认证。
- 通过安全认证后，网关Zuul从注册中心Eureka获取可用服务节点列表。
- 从可用服务节点中选取一个可用节点，然后把请求分发到这个节点。
- 整个请求过程中，Hystrix组件负责处理服务超时熔断，Turbine组件负责监控服务间的调用和熔断相关指标，Sleuth组件负责调用链监控，ELK负责日志分析。

### 5.对比选型

​	如果你的语言平台是C++，那么只能选择Tars；而如果是Java的话，可以选择Dubbo、Motan或者Spring Cloud。

​	仔细分析，可以看出Spring Cloud不仅提供了基本的RPC框架功能，还提供了服务注册组件、配置中心组件、负载均衡组件、断路器组件、分布式消息追踪组件等一系列组件。如果你不想自己实现以上这些功能，那么Spring Cloud基本可以满足你的全部需求。而Dubbo、Motan基本上只提供了最基础的RPC框架的功能，其他微服务组件都需要自己去实现。

​	**不过由于Spring Cloud的RPC通信采用了HTTP协议，相比Dubbo和Motan所采用的私有协议来说，在高并发的通信场景下，性能相对要差一些，所以对性能有苛刻要求的情况下，可以考虑Dubbo和Motan。**

## 跨语言平台的开源RPC框架

### 1.gRPC

​	先来看下**gRPC，它的原理是通过IDL（Interface Definition Language）文件定义服务接口的参数和返回值类型，然后通过代码生成程序生成服务端和客户端的具体实现代码，这样在gRPC里，客户端应用可以像调用本地对象一样调用另一台服务器上对应的方法。**

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/d9acfb00d5e98adbd65306e6a4e761f9.png)

​	它的主要特性包括三个方面：

- 通信协议采用了HTTP/2，因为HTTP/2提供了连接复用、双向流、服务器推送、请求优先级、首部压缩等机制，所以在通信过程中可以节省带宽、降低TCP连接次数、节省CPU，尤其对于移动端应用来说，可以帮助延长电池寿命。
- IDL使用了ProtoBuf，**ProtoBuf是由Google开发的一种数据序列化协议，它的压缩和传输效率极高，语法也简单，所以被广泛应用在数据存储和通信协议上。**
- 多语言支持，能够基于多种语言自动生成对应语言的客户端和服务端的代码。

### 2.Thrift

​	Thrift是一种轻量级的跨语言RPC通信方案，支持多达25种编程语言。为了支持多种语言，跟gRPC一样，Thrift也有一套自己的接口定义语言IDL，可以通过代码生成器，生成各种编程语言的Client端和Server端的SDK代码，这样就保证了不同语言之间可以相互通信。它的架构图可以用下图来描述。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/d5c959122758f1915d6ae4f89247e062.png)

从这张图上可以看出Thrift RPC框架的特性：

- 支持多种序列化格式：如Binary、Compact、JSON、Multiplexed等。
- 支持多种通信方式：如Socket、Framed、File、Memory、zlib等。
- 服务端支持多种处理方式：如Simple 、Thread Pool、Non-Blocking等。

### 3.对比选型

​	从成熟度上来讲，Thrift因为诞生的时间要早于gRPC，所以使用的范围要高于gRPC，在HBase、Hadoop、Scribe、Cassandra等许多开源组件中都得到了广泛地应用。而且Thrift支持多达25种语言，这要比gRPC支持的语言更多，所以如果遇到gRPC不支持的语言场景下，选择Thrift更合适。

​	但gRPC作为后起之秀，因为采用了HTTP/2作为通信协议、ProtoBuf作为数据序列化格式，在移动端设备的应用以及对传输带宽比较敏感的场景下具有很大的优势，而且开发文档丰富，根据ProtoBuf文件生成的代码要比Thrift更简洁一些，从使用难易程度上更占优势，所以如果使用的语言平台gRPC支持的话，建议还是采用gRPC比较好。

## 总结

​	从长远来看，支持多语言是RPC框架未来的发展趋势。正是基于此判断，**各个RPC框架都提供了Sidecar组件来支持多语言平台之间的RPC调用。**

​	所以未来语言不会成为使用上面这几种RPC框架的约束，而gRPC和Thrift虽然支持跨语言的RPC调用，但是因为它们只提供了最基本的RPC框架功能，缺乏一系列配套的服务化组件和服务治理功能的支撑，所以**使用它们作为跨语言调用的RPC框架，就需要自己考虑注册中心、熔断、限流、监控、分布式追踪等功能的实现，**不过好在大多数功能都有开源实现，可以直接采用。

> [Sidecar模式：下一代微服务架构的关键](https://blog.csdn.net/zyqduron/article/details/81281327)

# 五、搭建监控系统

​	**一个监控系统的组成主要涉及四个环节：数据收集、数据传输、数据处理和数据展示。**不同的监控系统实现方案，在这四个环节所使用的技术方案不同，适合的业务场景也不一样。目前，比较流行的开源监控系统实现方案主要有两种：以ELK为代表的集中式日志解决方案，以及以Graphite、TICK和Prometheus等为代表的时序数据库解决方案。

## ELK

​	ELK是Elasticsearch、Logstash、Kibana三个开源软件产品首字母的缩写，它们三个通常配合使用，所以被称为ELK Stack，它的架构可以用下面的图片来描述。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/cd8d76c0ab3a17bf16c19f973e92bb9a.png)

这三个软件的功能也各不相同。

- Logstash负责数据收集和传输，它支持动态地从各种数据源收集数据，并对数据进行过滤、分析、格式化等，然后存储到指定的位置。
- Elasticsearch负责数据处理，它是一个开源分布式搜索和分析引擎，具有可伸缩、高可靠和易管理等特点，基于Apache Lucene构建，能对大容量的数据进行接近实时的存储、搜索和分析操作，通常被用作基础搜索引擎。
- Kibana负责数据展示，也是一个开源和免费的工具，通常和Elasticsearch搭配使用，对其中的数据进行搜索、分析并且以图表的方式展示。

这种架构因为需要在各个服务器上部署Logstash来从不同的数据源收集数据，所以比较消耗CPU和内存资源，容易造成服务器性能下降，因此后来又在Elasticsearch、Logstash、Kibana之外引入了Beats作为数据收集器。相比于Logstash，Beats所占系统的CPU和内存几乎可以忽略不计，可以安装在每台服务器上做轻量型代理，从成百上千或成千上万台机器向Logstash或者直接向Elasticsearch发送数据。其中，Beats支持多种数据源，主要包括：

- Packetbeat，用来收集网络流量数据。
- Topbeat，用来收集系统、进程的CPU和内存使用情况等数据。
- Filebeat，用来收集文件数据。Winlogbeat，用来收集Windows事件日志收据。

Beats将收集到的数据发送到Logstash，经过Logstash解析、过滤后，再将数据发送到Elasticsearch，最后由Kibana展示，架构就变成下面这张图里描述的了。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/e6ebce07db63a7f0d6e4c03cb458eaef.png)

## Graphite

​	**Graphite的组成主要包括三部分：Carbon、Whisper、Graphite-Web**，它的架构可以用下图来描述。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/fc78b78efe3c2cb52f478e61a9ebbc11.png)

- Carbon：主要作用是接收被监控节点的连接，收集各个指标的数据，将这些数据写入carbon-cache并最终持久化到Whisper存储文件中去。
- Whisper：**一个简单的时序数据库，主要作用是存储时间序列数据**，可以按照不同的时间粒度来存储数据，比如1分钟1个点、5分钟1个点、15分钟1个点三个精度来存储监控数据。
- Graphite-Web：一个Web App，其主要功能绘制报表与展示，即数据展示。为了保证Graphite-Web能及时绘制出图形，Carbon在将数据写入Whisper存储的同时，会在carbon-cache中同时写入一份数据，Graphite-Web会先查询carbon-cache，如果没有再查询Whisper存储。

也就是说==Carbon负责数据处理，Whisper负责数据存储，Graphite-Web负责数据展示==，可见Graphite自身并不包含数据采集组件，但可以接入StatsD等开源数据采集组件来采集数据，再传送给Carbon。

其中Carbon对写入的数据格式有一定的要求，比如：

```
servers.www01.cpuUsage 42 1286269200
products.snake-oil.salesPerMinute 123 1286269200
[one minute passes]
servers.www01.cpuUsageUser 44 1286269260
products.snake-oil.salesPerMinute 119 1286269260
```

其中“servers.www01.cpuUsage 42 1286269200”是“key”  +  空格分隔符  +  “value  +  时间戳”的数据格式，“servers.www01.cpuUsage”是以“.”分割的key，代表具体的路径信息，“42”是具体的值，“1286269200”是当前的Unix时间戳。

Graphite-Web对外提供了HTTP API可以查询某个key的数据以绘图展示，查询方式如下：

```
http://graphite.example.com/render?target=servers.www01.cpuUsage&
width=500&height=300&from=-24h
```

这个HTTP请求意思是查询key“servers.www01.cpuUsage”在过去24小时的数据，并且要求返回500*300大小的数据图。*

除此之外，Graphite-Web还支持丰富的函数，比如：`target=sumSeries(products.*.salesPerMinute)`代表了查询匹配规则“products.*.salesPerMinute”的所有key的数据之和。

## TICK

​	TICK是Telegraf、InfluxDB、Chronograf、Kapacitor四个软件首字母的缩写，是由InfluxData开发的一套开源监控工具栈，因此也叫作TICK Stack，它的架构可以看用下面这张图来描述。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/6e5c85e68f0eff409f70f17f846d5335.png)

从这张图可以看出，其中**Telegraf负责数据收集，InfluxDB负责数据存储，Chronograf负责数据展示，Kapacitor负责数据告警。**这里面，InfluxDB对写入的数据格式要求如下。

```
<measurement>[,<tag-key>=<tag-value>...] <field-key>=<field-value>[,<field2-key>=<field2-value>...] [unix-nano-timestamp]
```

下面用一个具体示例来说明它的格式，如：`cpu,host=serverA,region=us_west value=0.64 1434067467100293230`。其中，“cpu,host=serverA，region=us_west value=0.64 1434067467100293230”
代表了host为serverA、region为us_west的服务器CPU的值是0.64，时间戳是1434067467100293230，时间精确到nano。

## Prometheus

​	还有一种比较有名的时间序数据库解决方案Prometheus，它是一套开源的系统监控报警框架，受Google的集群监控系统Borgmon启发，由工作在SoundCloud的Google前员工在2012年创建，后来作为社区开源项目进行开发，并于2015年正式发布，2016年正式加入CNCF（Cloud Native Computing Foundation），成为受欢迎程度
仅次于Kubernetes的项目，它的架构可以用下图来描述。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/a42d15cb006b41fecc82575b566dbc71.png)

从这张图可以看出，Prometheus主要包含下面几个组件：

- Prometheus Server：用于拉取metrics信息并将数据存储在时间序列数据库。
- Jobs/exporters：用于暴露已有的第三方服务的metrics给Prometheus Server，比如StatsD、Graphite等，负责数据收集。
- Pushgateway：主要用于短期jobs，由于这类jobs存在时间短，可能在Prometheus Server来拉取metrics信息之前就消失了，所以这类的jobs可以直接向
- Prometheus Server推送它们的metrics信息。Alertmanager：用于数据报警。Prometheus web UI：负责数据展示。

它的工作流程大致是：

- Prometheus Server定期从配置好的jobs或者exporters中拉取metrics信息，或者接收来自Pushgateway发过来的metrics信息。
- Prometheus Server把收集到的metrics信息存储到时间序列数据库中，并运行已经定义好的alert.rules，向Alertmanager推送警报。
- Alertmanager根据配置文件，对接收的警报进行处理，发出告警。
- 通过Prometheus web UI进行可视化展示。

Prometheus存储数据也是用的时间序列数据库，格式如：`<metric name>{<label name>=<label value>, …}`。比如下面这段代码代表了位于集群cluster1上，节点IP为1.1.1.1，端口为80，访问路径为“/a”的http请求的总数为100：`http_requests_total{instance="1.1.1.1:80",job="cluster1",location="/a"} 100`

## 选型对比

我们从监控系统的四个环节来分别对比。

### 1.数据收集

​	ELK是通过在每台服务器上部署Beats代理来采集数据；Graphite本身没有收据采集组件，需要配合使用开源收据采集组件，比如StatsD；TICK使用了Telegraf作为数据采集组件；Prometheus通过jobs/exporters组件来获取StatsD等采集过来的metrics信息。

### 2.数据传输

ELK是Beats采集的数据传输给Logstash，经过Logstash清洗后再传输给Elasticsearch；Graphite是通过第三方采集组件采集的数据，传输给Carbon；TICK是Telegraf采集的数据，传输给InfluxDB；而Prometheus是Prometheus Server隔一段时间定期去从jobs/exporters拉取数据。

可见前三种都是采用“推数据”的方式，而Prometheus是采取拉数据的方式，因此Prometheus的解决方案对服务端的侵入最小，不需要在服务端部署数据采集代理。

### 3.数据处理

ELK可以对日志的任意字段索引，适合多维度的数据查询，在存储时间序列数据方面与时间序列数据库相比会有额外的性能和存储开销。除此之外，时间序列数据库的几种解决方案都支持多种功能的数据查询处理，功能也更强大。

- Graphite通过Graphite-Web支持正则表达式匹配、sumSeries求和、alias给监控项重新命名等函数功能，同时还支持这些功能的组合，比如下面这个表达式的意思是，要查询所有匹配路径
  “stats.open.profile.*.API._comments_flow”的监控项之和，并且把监控项重命名为Total QPS。

  > ```
  > alias(sumSeries(stats.openapi.profile.*.API._comments_flow.total_count,"Total QPS")
  > ```

- InfluxDB通过类似SQL语言的InfluxQL，能对监控数据进行复杂操作，比如查询一分钟CPU的使用率，用InfluxDB实现的示例是：`SELECT 100 - usage_idel FROM "autogen"."cpu" WHERE time > now() - 1m and "cpu"='cpu0'`

- Prometheus通过私有的PromQL查询语言，如果要和上面InfluxDB实现同样的功能，PromQL语句如下，看起来更加简洁：`100 - (node_cpu{job="node",mode="idle"}[1m]) `

### 4.数据展示

Graphite、TICK和Prometheus自带的展示功能都比较弱，界面也不好看，不过好在它们都支持Grafana来做数据展示。Grafana是一个开源的仪表盘工具，它支持多种数据源比如Graphite、InfluxDB、Prometheus以及Elasticsearch等。ELK采用了Kibana做数据展示，Kibana包含的数据展示功能比较强大，但只支Elasticsearch，而且界面展示UI效果不如Grafana美观。

## 总结

​	以上几种监控系统实现方式，所采用的技术均为开源的，其中：

- ELK的技术栈比较成熟，应用范围也比较广，除了可用作监控系统外，还可以用作日志查询和分析。
- Graphite是基于时间序列数据库存储的监控系统，并且提供了功能强大的各种聚合函数比如sum、average、top5等可用于监控分析，而且对外提供了API也可以接入其他图形化监控系统如Grafana。
- TICK的核心在于其时间序列数据库InfluxDB的存储功能强大，且支持类似SQL语言的复杂数据处理操作。
- Prometheus的独特之处在于它采用了拉数据的方式，对业务影响较小，同时也采用了时间序列数据库存储，而且支持独有的PromQL查询语言，功能强大而且简洁。

**从对实时性要求角度考虑，时间序列数据库的实时性要好于ELK，通常可以做到10s级别内的延迟，如果对实时性敏感的话，建议选择时间序列数据库解决方案。**

从使用的灵活性角度考虑，几种时间序列数据库的监控处理功能都要比ELK更加丰富，使用更灵活也更现代化。所以如果要搭建一套新的监控系统，建议可以考虑采用Graphite、TICK或者Prometheus其中之一。不过Graphite还需要搭配数据采集系统比如StatsD或者Collectd使用，而且界面展示建议使用Grafana接入Graphite的数据源，它的效果要比Graphite Web本身提供的界面美观很多。TICK提供了完整的监控系统框架，包括从数据采集、数据传输、数据处理再到数据展示，不过在数据展示方面同样也建议用Grafana替换掉TICK默认的数据展示组件Chronograf，这样展示效果更好。Prometheus因为采用拉数据的方式，所以对业务的侵入性最小，比较适合Docker封装好的云原生应用，比如Kubernetes默认就采用了Prometheus作为监控系统。

# 六、搭建服务追踪系统

​	服务追踪系统的实现，主要包括三个部分：

- 埋点数据收集，负责在服务端进行埋点，来收集服务调用的上下文数据；
- 实时数据处理，负责对收集到的链路信息，按照traceId和spanId进行串联和存储。
- 数据链路展示，把处理后的服务调用数据，按照调用链的形式展示出来。

> 如果要自己从0开始实现一个服务追踪系统，首先需要在业务代码的框架层开发调用拦截程序，在调用的前后收集相关信息，把信息传输给到一个统一的处理中心。然后处理中心需要实时处理收集到链路信息，并按照traceId和spanId进行串联，处理完以后再存到合适的存储中。最后还要能把存储中存储的信息，以调用链路图或者调用拓扑图的形式对外展示。

​	业界比较有名的服务追踪系统实现有阿里的鹰眼、Twitter开源的OpenZipkin，还有Naver开源的Pinpoint，它们都是受Google发布的Dapper论文启发而实现的。下面主要介绍下开源实现方案OpenZipkin和Pinpoint，再看看它们有什么区别。

## OpenZipkin

​	OpenZipkin是Twitter开源的服务追踪系统，下面这张图展示了它的架构设计。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/699916c60cd31a2b8d7ab0335038cf33.png)

从图中看，OpenZipkin主要由四个核心部分组成：

- Collector：负责收集探针Reporter埋点采集的数据，经过验证处理并建立索引。
- Storage：存储服务调用的链路数据，默认使用的是Cassandra，是因为Twitter内部大量使用了Cassandra，也可以替换成Elasticsearch或者MySQL。
- API：将格式化和建立索引的链路数据以API的方式对外提供服务，比如被UI调用。
- UI：以图形化的方式展示服务调用的链路数据。

它的工作原理可以用下面这张图来描述。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/4c036659e0d14176215686f1a1129ed9.png)

具体流程是，通过在业务的HTTP Client前后引入服务追踪代码，这样在HTTP方法“/foo”调用前，生成trace信息：TraceId：aa、SpanId：6b、annotation：GET /foo，以及当前时刻的timestamp：1483945573944000，然后调用结果返回后，记录下耗时duration，之后再把这些trace信息和duration异步上传给Zipkin Collector。

## Pinpoint

​	Pinpoint是Naver开源的一款深度支持Java语言的服务追踪系统，下面这张图是它的架构设计。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/d8b526a56b633c34364924a2d00905a4.png)

Pinpoint主要也由四个部分组成：

- Pinpoint Agent：通过Java字节码注入的方式，来收集JVM中的调用数据，通过UDP协议传递给Collector，数据采用Thrift协议进行编码。
- Pinpoint Collector：收集Agent传过来的数据，然后写到HBase Storgage。
- HBase Storage：采用HBase集群存储服务调用的链路信息。
- Pinpoint Web UI：通过Web UI展示服务调用的详细链路信息。

它的工作原理你可以看这张图：

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/8730864e70d666267e40e1cc4d622195.png)

具体来看，就是请求进入TomcatA，然后生成TraceId：TomcatA^ TIME ^ 1、SpanId：10、pSpanId：-1（代表是根请求），接着TomatA调用TomcatB的hello方法，TomcatB生成TraceId：TomcatA^ TIME ^1、新的SpanId：20、pSpanId：10（代表是TomcatA的请求），返回调用结果后将trace信息发给Collector，TomcatA收到调用结果后，将trace信息也发给Collector。**Collector把trace信息写入到HBase中，Rowkey就是traceId，SpanId和pSpanId都是列。然后就可以通过UI查询调用链路信息了。**

## 选型对比

​	考察服务追踪系统主要从下面这几个方面。

### 1.埋点探针支持平台的广泛性

​	OpenZipkin提供了不同语言的Library，不同语言实现时需要引入不同版本的Library。官方提供了C#、Go、Java、JavaScript、Ruby、Scala、PHP等主流语言版本的Library，而且开源社区还提供了更丰富的不同语言版本的Library，详细的可以点击这里查看；而Pinpoint目前只支持Java语言。所以从探针支持的语言平台广泛性上来看，OpenZipkin比Pinpoint的使用范围要广，而且开源社区很活跃，生命力更强。

### 2.系统集成难易程度 

​	以OpenZipkin的Java探针Brave为例，它只提供了基本的操作API，如果系统要想集成Brave，必须在配置里手动里添加相应的配置文件并且增加trace业务代码。具体来讲，**就是需要先修改工程的POM依赖，以引入Brave相关的JAR包。**

```xml
<dependencyManagement>
    <dependencies>
      <dependency>
        <groupId>io.zipkin.brave</groupId>
        <artifactId>brave-bom</artifactId>
        <version>${brave.version}</version>
        <type>pom</type>
        <scope>import</scope>
      </dependency>
    </dependencies>
  </dependencyManagement>
```

然后假如你想收集每一次HTTP调用的信息，你就可以使用Brave在Apache Httpclient基础上封装的httpClient，它会记录每一次HTTP调用的信息，并上报给OpenZipkin。

`httpclient =TracingHttpClientBuilder.create(tracing).build();`

而Pinpoint是通过字节码注入的方式来实现拦截服务调用，从而收集trace信息的，所以不需要代码做任何改动。Java字节码注入的大致原理你可以参考下图。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/4a27448c52515020c1f687e8e3567875.png)

​	**就是JVM在加载class二进制文件时，动态地修改加载的class文件，在方法的前后执行拦截器的before()和after()方法，在before()和after()方法里记录trace()信息。**而应用不需要修改业务代码，只需要在JVM启动时，添加类似下面的启动参数就可以了。

```
-javaagent:$AGENT_PATH/pinpoint-bootstrap-$VERSION.jar
-Dpinpoint.agentId=<Agent's UniqueId>
-Dpinpoint.applicationName=<The name indicating a same service (AgentId collection)
```

所以从系统集成难易程度上看，Pinpoint要比OpenZipkin简单。

### 3.调用链路数据的精确度

从下面这张OpenZipkin的调用链路图可以看出，OpenZipkin收集到的数据只到接口级别，进一步的信息就没有了。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/33c924c5563be070416d8133e255af23.jpg)

再来看下Pinpoint，因为Pinpoint采用了字节码注入的方式实现trace信息收集，所以它能拿到的信息比OpenZipkin多得多。从下面这张图可以看出，它不仅能够查看接口级别的链路调用信息，还能深入到调用所关联的数据库信息。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/5f365d3c49cdb113bf6b08f5e3b36e3e.jpg)

同理在绘制链路拓扑图时，OpenZipkin只能绘制服务与服务之间的调用链路拓扑图，比如下面这张示意图。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/a7575c0826b77d236ddffe92d4d3c1e9.jpg)而Pinpoint不仅能够绘制服务与服务之间，还能绘制与DB之间的调用链路拓扑图，比如下图。

![img](https://raw.githubusercontent.com/JDawnF/learning_note/master/images/e59d46aa62e542246732ab9a985d281e.jpg)

所以，从调用链路数据的精确度上看，Pinpoint要比OpenZipkin精确得多。

## 总结

​	从选型的角度来讲，如果你的业务采用的是Java语言，那么采用Pinpoint是个不错的选择，因为它不需要业务改动一行代码就可以实现trace信息的收集。除此之外，Pinpoint不仅能看到服务与服务之间的链路调用，还能看到服务内部与资源层的链路调用，功能更为强大，如果你有这方面的需求，Pinpoint正好能满足。如果你的业务不是Java语言实现，或者采用了多种语言，那毫无疑问应该选择OpenZipkin，并且，由于其开源社区很活跃，基本上各种语言平台都能找到对应的解决方案。不过想要使用OpenZipkin，还需要做一些额外的代码开发工作，以引入OpenZipkin提供的Library到你的系统中。除了OpenZipkin和Pinpoint，业界还有其他开源追踪系统实现，比如Uber开源的Jaeger，以及国内的一款开源服务追踪系统SkyWalking。

# 七、识别服务节点是否存活

​	**ZooKeeper判断注册中心节点存活的机制其实就是注册中心摘除机制，服务消费者以注册中心中的数据为准，当服务端节点有变更时，注册中心就会把变更通知给服务消费者，服务消费者就会调用注册中心来拉取最新的节点信息。**
​	这种机制在大部分情况下都可以工作得很好，但是在网络频繁抖动时，服务提供者向注册中心汇报心跳信息可能会失败，如果在规定的时间内，注册中心都没有收到服务提供者的心跳信息，就会把这个节点从可用节点列表中移除。更糟糕的是，在服务池拥有上百个节点的的时候，每个节点都可能会被移除，导致注册中心可用节点的状态一直在变化，这个时候应该如何处理呢？一般有以下几种解决方案：

## 心跳开关保护机制

​	在网络频繁抖动的情况下，注册中心中可用的节点会不断变化，这时候**服务消费者会频繁收到服务提供者节点变更的信息，于是就不断地请求注册中心来拉取最新的可用服务节点信息。当有成百上千个服务消费者，同时请求注册中心获取最新的服务提供者的节点信息时，可能会把注册中心的带宽给占满**，尤其是注册中心是百兆网卡的情况下。所以针对这种情况，需要一种保护机制，即使在网络频繁抖动的时候，服务消费者也不至于同时去请求注册中心获取最新的服务节点信息。

​	==一个可行的解决方案就是给注册中心设置一个开关，当开关打开时，即使网络频繁抖动，注册中心也不会通知所有的服务消费者有服务节点信息变更，比如只给10%的服务消费者返回变更，这样的话就能将注册中心的请求量减少到原来的1/10。==当然打开这个开关也是有一定代价的，它会导致服务消费者感知最新的服务节点信息延迟，原先可能在10s内就能感知到服务提供者节点信息的变更，现在可能会延迟到几分钟，所以在网络正常的情况下，开关并不适合打开；可以作为一个紧急措施，在网络频繁抖动的时候，才打开这个开关。

## 服务节点摘除保护机制

​	服务提供者在进程启动时，会注册服务到注册中心，并每隔一段时间，汇报心跳给注册中心，以标识自己的存活状态。如果隔了一段固定时间后，服务提供者仍然没有汇报心跳给注册中心，注册中心就会认为该节点已经处于“dead”状态，于是从服务的可用节点信息中移除出去。如果遇到网络问题，大批服务提供者节点汇报给注册中心的心跳信息都可能会传达失败，注册中心就会把它们都从可用节点列表中移除出去，造成剩下的可用节点难以承受所有的调用，引起“雪崩”。

​	但是这种情况下，可能大部分服务提供者节点是可用的，仅仅因为网络原因无法汇报心跳给注册中心就被“无情”的摘除了。这个时候就需要根据实际业务的情况，设定一个阈值比例，即使遇到刚才说的这种情况，注册中心也不能摘除超过这个阈值比例的节点。这个阈值比例可以根据实际业务的冗余度来确定，一般可以设定在20%，就是说注册中心不能摘除超过20%的节点。因为大部分情况下，节点的变化不会这么频繁，只有在网络抖动或者业务明确要下线大批量节点的情况下才有可能发生。而业务明确要下线大批量节点的情况是可以预知的，这种情况下可以关闭阈值保护；而正常情况下，应该打开阈值保护，以防止网络抖动时，大批量可用的服务节点被摘除。

> ### 小结
>
> 心跳开关保护机制，是为了防止服务提供者节点频繁变更导致的服务消费者同时去注册中心获取最新服务节点信息；服务节点摘除保护机制，是为了防止服务提供者节点被大量摘除引起服务消费者可以调用的节点不足。
>
> 可见，无论是心跳开关保护机制还是服务节点摘除保护机制，都是因为注册中心里的节点信息是随时可能发生变化的，所以也可以把注册中心叫作**动态注册中心**。

​	**服务消费者并不严格以注册中心中的服务节点信息为准，而是更多的以服务消费者实际调用信息来判断服务提供者节点是否可用。**所以还有下面这种机制。

## 静态注册中心

​	前面讲过心跳机制能保证在服务提供者出现异常时，注册中心可以及时把不可用的服务提供者从可用节点列表中移除出去，正常情况下这是个很好的机制。但是其实服务提供者是向服务消费者提供服务的，是否可用服务消费者应该比注册中心更清楚，因此可以直接在服务消费者端根据调用服务提供者是否成功来判定服务提供者是否可用。

​	==如果服务消费者调用某一个服务提供者节点连续失败超过一定次数，可以在本地内存中将这个节点标记为不可用。并且每隔一段固定时间，服务消费者都要向标记为不可用的节点发起保活探测，如果探测成功了，就将标记为不可用的节点再恢复为可用状态，重新发起调用。==这样的话，服务提供者节点就不需要向注册中心汇报心跳信息，注册中心中的服务节点信息也不会动态变化，也可以称之为静态注册中心。

​	一开始采用了动态注册中心，后来考虑到网络的复杂性，心跳机制不一定是可靠的，而后开始改为采用服务消费者端的保活机制，事实证明这种机制足以应对网络频繁抖动等复杂的场景。**当然静态注册中心中的服务节点信息并不是一直不变，当在业务上线或者运维人工增加或者删除服务节点这种预先感知的情况下，还是有必要去修改注册中心中的服务节点信息。**比如在业务上线过程中，需要把正在部署的服务节点从注册中心中移除，等到服务部署完毕，完全可用的时候，再加入到注册中心。还有就是在业务新增或者下线服务节点的时候，需要调用注册中心提供的接口，添加节点信息或者删除节点。这个时候静态注册中心有点退化到配置中心的意思，只不过这个时候配置中心里存储的不是某一项配置，而是某个服务的可用节点信息。

## 总结

​	动态注册中心在实际线上业务运行时，如果遇到网络不可靠等因素，可能会带来的两个问题，**一个是服务消费者同时并发访问注册中心获取最新服务信息导致注册中心带宽被打满；另一个是服务提供者节点被大量摘除导致服务消费者没有足够的节点可以调用。**对应有两个解决方案：心跳开关保护机制和服务节点摘除保护机制都是在实践中应用过的，并且被证明是行之有效的。而静态注册中心的思路，是在斟酌注册中心的本质之后，引入的另外一个解决方案，相比于动态注册中心更加简单，并且基于服务消费者本身调用来判断服务节点是否可用，更加直接也更加准确，尤其在注册中心或者网络出现问题的时候，这种方案基本不受影响。



参照：[从0开始学微服务](https://time.geekbang.org/column/article/14222)