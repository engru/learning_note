# JVM(2)

# 六、虚拟机字节码执行引擎

## 1 概述

​	**执行引擎是java虚拟机最核心的组成部件之一。**虚拟机的执行引擎由自己实现，所以可以自行定制指令集与执行引擎的结构体系，并且能够执行那些不被硬件直接支持的指令集格式。

​	所有的Java虚拟机的执行引擎都是一致的：==**输入的是字节码文件，处理过程是字节码解析的等效过程，输出的是执行结果**==。本节将主要从概念模型的角度来讲解**虚拟机的方法调用和字节码执行**。

## 2 运行时栈帧结构

​	**栈帧（Stack Frame）** 是用于支持虚拟机方法调用和方法执行的数据结构，它是虚拟机运行时数据区中**虚拟机栈（Virtual Machine Stack）的栈元素**。

​	==栈帧存储了方法的局部变量表、操作数栈、动态连接和方法返回地址等信息。每一个方法从调用开始至执行完成的过程，都对应着一个栈帧在虚拟机栈里面从入栈到出栈的过程。==

​	**在编译程序代码的时候，栈帧中需要多大的局部变量表，多深的操作数栈都已经完全确定了，并且写入到方法表的Code属性之中，因此一个栈帧需要分配多少内存，不会受到程序运行期变量数据的影响，而仅仅取决于具体的虚拟机实现**。一个线程中的方法调用链可能会很长，很多方法都同时处于执行状态。==对于执行引擎来说，在活动线程中，只有位于栈顶的栈帧才是有效的，称为当前栈帧（Current StackFrame），与这个栈帧相关联的方法称为当前方法（Current Method）。==

**典型的栈帧概念结构如下图所示：**![image-20190107181515443](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190107181515443-6856115.png)

### 2.1 局部变量表

​	**局部变量表是一组变量值存储空间，用于存放方法参数和方法内定义的局部变量。 局部变量表的容量以变量槽（Variable Slot）为最小单位。** 一个Slot可以存放一个32位以内（boolean、byte、char、short、int、float、reference和returnAddress）的数据类型，reference类型表示一个对象实例的引用，returnAddress已经很少见了，可以忽略。

​	**对于64位的数据类型（Java语言中明确的64位数据类型只有long和double），虚拟机会以==高位对齐==的方式为其分配两个连续的Slot空间。**

​	**虚拟机通过索引定位的方式使用局部变量表**，**索引值的范围从0开始至局部变量表最大的Slot数量**。==访问的是32位数据类型的变量，索引n就代表了使用第n个Slot,如果是64位数据类型，就代表会同时使用n和n+1这两个Slot。==对于两个相邻的共同存放一个64位数据的两个Slot，不允许采用任何方式单独访问其中的某一个，Java虚拟机规范中明确要求了如果遇到进行这种操作的字节码序列，虚拟机应该在类加载的校验阶段抛出异常。

​	**在方法执行时，虚拟机是使用局部变量表完成参数值到参数变量列表的传递过程的，如果执行的是实例方法（非static的方法），那局部变量表中第0位索引的Slot默认是用于传递方法所属对象实例的引用，在方法中可以通过关键字“this”来访问到这个隐含的参数。**其余参数则按照参数表顺序排列，占用从1开始的局部变量Slot，参数表分配完毕后，再根据方法体内部定义的变量顺序和作用域分配其余的Slot。

​	**为了节省栈帧空间，局部变量Slot可以重用**，方法体中定义的变量，其作用域并不一定会覆盖整个方法体。如果当前字节码PC计数器的值超出了某个变量的作用域，那么这个变量的Slot就可以交给其他变量使用。这样的设计会带来一些额外的副作用，比如：在某些情况下，Slot的复用会直接影响到系统的收集行为。

### 2.2 操作数栈

​	**操作数栈（Operand Stack）** 也常称为操作栈，它是一个**后入先出栈**。当一个方法执行开始时，这个方法的操作数栈是空的，==在方法执行过程中，会有各种字节码指令往操作数栈中写入和提取内容，也就是 **出栈/入栈**操作。==

​	**操作数栈中元素的数据类型必须与字节码指令的序列严格匹配，在编译程序代码的时候，编译器要严格保证这一点，在类校验阶段的数据流分析中还要再次验证这一点。**再以上面的iadd指令为例，这个指令用于整型数加法，它在执行时，最接近栈顶的两个元素的数据类型必须为int型，不能出现一个long和一个float使用iadd命令相加的情况。

![image-20190107181742516](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190107181742516-6856262.png)

​	**在概念模型中，一个活动线程中两个栈帧是相互独立的。**但大多数虚拟机实现都会做一些优化处理：**==让下一个栈帧的部分操作数栈与上一个栈帧的部分局部变量表重叠在一起==，这样的好处是方法调用时可以共享一部分数据，而无须进行额外的参数复制传递。**

### 2.3 动态连接

​	==每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的**动态连接**；==

​	**字节码中方法调用指令是以常量池中的指向方法的符号引用为参数的，**有一部分符号引用会在类加载阶段或第一次使用的时候转化为直接引用，这种转化称为 **静态解析**，另外一部分在每次的运行期间转化为直接引用，这部分称为**动态连接**。

### 2.4 方法返回地址

当一个方法被执行后，有两种方式退出这个方法：

- 第一种是执行引擎遇到任意一个方法返回的字节码指令，这时候可能会有返回值传递给上层的方法调用者（调用当前方法的方法称为调用者），**是否有返回值和返回值的类型将根据遇到何种方法返回指令来决定，**这种退出方法的方式称为**正常完成出口（Normal Method Invocation Completion）**。
- 另外一种是在方法执行过程中遇到了异常，并且这个异常没有在方法体内得到处理（即本方法异常处理表中没有匹配的异常处理器），就会导致方法退出，这种退出方式称为**异常完成出口（Abrupt Method Invocation Completion）**。 ==注意：这种退出方式不会给上层调用者产生任何返回值。==

**无论采用何种退出方式，在方法退出后，都需要返回到方法被调用的位置，程序才能继续执行**，方法返回时可能需要在栈帧中保存一些信息，用来帮助恢复它的上层方法的执行状态。一般来说，方法正常退出时，调用者的PC计数器的值可以作为返回地址，栈帧中很可能会保存这个计数器值。而方法异常退出时，返回地址是通过异常处理器表来确定的，栈帧中一般不会保存这部分信息。

​	**方法退出的过程实际上等同于把当前栈帧出栈，因此退出时可能执行的操作有：恢复上层方法的局部变量表和操作数栈，把返回值（如果有的话）压入调用者栈帧的操作数栈中，调整PC计数器的值以指向方法调用指令后面的一条指令等。**

### 2.5 附加信息

​	虚拟机规范允许虚拟机实现向栈帧中添加一些自定义的附加信息，例如与调试相关的信息等。

## 3 方法调用

​	方法调用阶段的目的：**确定被调用方法的版本（哪一个方法），不涉及方法内部的具体运行过程**，在程序运行时，进行方法调用是最普遍、最频繁的操作。

​	**==一切方法调用在Class文件里存储的都只是符号引用，这是需要在类加载期间或者是运行期间，才能确定为方法在实际 运行时内存布局中的入口地址（相当于之前说的直接引用）==**。

### 3.1 解析

​	所有方法调用中的目标方法在Class文件里面都是一个常量池中的符号引用，在类加载的解析阶段，会将其中的一部分符号引用转化为直接引用，这种解析能成立的前提是：方法在程序真正运行之前就有一个可确定的调用版本，并且这个方法的调用版本在运行期是不可改变的。换句话说，**==调用目标在程序代码写好、编译器进行编译时就必须确定下来。这类方法的调用称为解析（Resolution）。==**

​	**“编译期可知，运行期不可变”的方法（静态方法和私有方法），在类加载的解析阶段，会将其符号引用转化为直接引用（入口地址）。**这类方法的调用称为“**解析（Resolution）**”。

​	**只要能被invokestatic和invokespecial指令调用的方法，都可以在解析阶段中确定唯一的调用版本，符合这个条件的有静态方法、私有方法、实例构造器、父类方法4类，它们在类加载的时候就会把符号引用解析为该方法的直接引用。这些方法可以称为非虚方法，与之相反，其他方法称为虚方法**（除去final方法，后文会提到）。

在Java虚拟机中提供了5条方法调用字节码指令：

- **invokestatic** : 调用静态方法
- **invokespecial**:调用实例构造器方法、私有方法、父类方法
- **invokevirtual**:调用所有的虚方法
- **invokeinterface**:调用接口方法，会在运行时在确定一个实现此接口的对象
- **invokedynamic**:先在运行时动态解析出点限定符所引用的方法，然后再执行该方法，在此之前的4条调用命令的分派逻辑是固化在Java虚拟机内部的，而invokedynamic指令的分派逻辑是由用户所设定的引导方法决定的。

​	**解析调用一定是个静态的过程，在编译期间就完全确定，在类装载的解析阶段就会把涉及的符号引用全部转变为可确定的直接引用，不会延迟到运行期再去完成。**而分派（Dispatch）调用则可能是静态的也可能是动态的，根据分派依据的宗量数可分为单分派和多分派。**这两类分派方式的两两组合就构成了静态单分派、静态多分派、动态单分派、动态多分派4种分派组合情况，**下面我们再看看虚拟机中的方法分派是如何进行的。

### 3.2 分派

​	**分派调用过程将会揭示多态性特征的一些最基本的体现，如“重载”和“重写”在Java虚拟中是如何实现的。**

#### **1 静态分派**

​	**==所有依赖静态类型来定位方法执行版本的分派动作，都称为静态分派。静态分派发生在编译阶段。==**

静态分派最典型的应用就是方法重载。

```Java
package jvm8_3_2;
public class StaticDispatch {
	static abstract class Human {
	}
	static class Man extends Human {
	}
	static class Woman extends Human {
	}
	public void sayhello(Human guy) {
		System.out.println("Human guy");
	}
	public void sayhello(Man guy) {
		System.out.println("Man guy");
	}
	public void sayhello(Woman guy) {
		System.out.println("Woman guy");
	}
	public static void main(String[] args) {
		Human man = new Man();
		Human woman = new Woman();
		StaticDispatch staticDispatch = new StaticDispatch();
		staticDispatch.sayhello(man);// Human guy
		staticDispatch.sayhello(woman);// Human guy
	}
}
```

**为什么会出现这样的结果呢？**

​	Human man = new Man();其中的Human称为变量的**静态类型（Static Type）**,Man称为变量的**实际类型（Actual Type）**。 **两者的区别是**：==静态类型在编译器可知，而实际类型到运行期才确定下来。== 在重载时通过参数的静态类型而不是实际类型作为判定依据，因此，**在编译阶段，Javac编译器会根据参数的静态类型决定使用哪个重载版本。**所以选择了sayhello(Human)作为调用目标，并把这个方法的符号引用写到main()方法里的两条invokevirtual指令的参数中。

#### **2 动态分派**

​	**==在运行期根据实际类型确定方法执行版本的分派过程称为动态分派。最典型的应用就是方法重写。==**

```java 
package jvm8_3_2;
public class DynamicDisptch {
	static abstract class Human {
		abstract void sayhello();
	}
	static class Man extends Human {
		@Override
		void sayhello() {
			System.out.println("man");
		}
	}
	static class Woman extends Human {
		@Override
		void sayhello() {
			System.out.println("woman");
		}
	}
	public static void main(String[] args) {
		Human man = new Man();
		Human woman = new Woman();
		man.sayhello();
		woman.sayhello();
		man = new Woman();
		man.sayhello();
	}
}
```

运行结果：

man

woman

woman

##### invokevirtual指令的运行时解析过程大致分为以下几个步骤：

​	1）找到操作数栈顶的第一个元素所指向的对象的实际类型，记作C。

​	2）如果在类型C中找到与常量中的描述符和简单名称都相符的方法，则进行访问权限校验，如果通过则返回这个方法的直接引用，查找过程结束；如果不通过，则返回java.lang.IllegalAccessError异常。

​	3）否则，按照继承关系从下往上依次对C的各个父类进行第2步的搜索和验证过程。

​	4）如果始终没有找到合适的方法，则抛出java.lang.AbstractMethodError异常。

#### **3 单分派和多分派**

​	方法的接收者、方法的参数都可以称为方法的宗量。根据分批基于多少种宗量，可以将分派划分为单分派和多分派。**单分派是根据一个宗量对目标方法进行选择的，多分派是根据多于一个的宗量对目标方法进行选择的。**

```java
/***单分派、多分派演示*@author zzm*/
public class Dispatch{
	static class QQ{
	}
	static class_360{
	}
	public static class Father{
		public void hardChoice（QQ arg）{
			System.out.println（"father choose qq"）；
		}
		public void hardChoice（_360 arg）{
			System.out.println（"father choose 360"）；
		}
	}
	public static class Son extends Father{
		public void hardChoice（QQ arg）{
			System.out.println（"son choose qq"）；
		}
		public void hardChoice（_360 arg）{
			System.out.println（"son choose 360"）；
		}
	}
	public static void main（String[]args）{
		Father father=new Father（）；
        Father son=new Son（）；
        father.hardChoice（new_360（））；
		son.hardChoice（new QQ（））；}}
```

​	输出结果：father choose 360

​			   son choose qq

​	Java在进行静态分派时，选择目标方法要依据两点：**一是变量的静态类型是哪个类型，二是方法参数是什么类型。**因为要根据两个宗量进行选择，所以Java语言的静态分派属于多分派类型。

​	运行时阶段的动态分派过程，由于编译器已经确定了目标方法的签名（包括方法参数），运行时虚拟机只需要确定方法的接收者的实际类型，就可以分派。因为是根据一个宗量作为选择依据，所以Java语言的动态分派属于单分派类型。

注：到JDK1.7时，Java语言还是静态多分派、动态单分派的语言，未来有可能支持动态多分派。

#### **4 虚拟机动态分派的实现**

​	由于动态分派是非常频繁的动作，而动态分派在方法版本选择过程中又需要在方法元数据中搜索合适的目标方法，虚拟机实现出于性能的考虑，通常不直接进行如此频繁的搜索，而是采用优化方法。

​	其中一种“稳定优化”手段是：在类的方法区中建立一个==**虚方法表**==（Virtual Method Table, 也称vtable, 与此对应，也存在接口方法表——Interface Method Table，也称itable）。**使用虚方法表索引来代替元数据查找以提高性能。其原理与C++的虚函数表类似。**

##### 下图是第三点单分派和多分派代码中的方法表结构：![image-20190108110929296](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190108110929296-6916969.png)

​	**虚方法表中存放的是各个方法的实际入口地址。如果某个方法在子类中没有被重写，那子类的虚方法表里面的地址入口和父类中该方法相同，都指向父类的实现入口。虚方法表一般在类加载的连接阶段进行初始化。如果子类中重写了这个方法，子类方法表中的地址将会替换为指向子类实现版本的入口地址。**

​	上图中，Son重写了来自Father的全部方法，因此Son的方法表没有指向Father类型数据的箭头。但是Son和Father都没有重写来自Object的方法，所以它们的方法表中所有从Object继承来的方法都指向了Object的数据类型。

### 3.3 动态类型语言的支持

JDK新增加了invokedynamic指令来是实现“动态类型语言”。

##### **静态语言和动态语言的区别：**

- **静态语言（强类型语言）**： 静态语言是在编译时变量的数据类型即可确定的语言，多数静态类型语言要求在使用变量之前必须声明数据类型。  例如：C++、Java、Delphi、C#等。
- **动态语言（弱类型语言）** ： 动态语言是在运行时确定数据类型的语言。变量使用之前不需要类型声明，通常变量的类型是被赋值的那个值的类型。  例如PHP/ASP/Ruby/Python/Perl/ABAP/SQL/JavaScript/Unix Shell等等。
- **强类型定义语言** ： 强制数据类型定义的语言。也就是说，一旦一个变量被指定了某个数据类型，如果不经过强制转换，那么它就永远是这个数据类型了。举个例子：如果你定义了一个整型变量a,那么程序根本不可能将a当作字符串类型处理。强类型定义语言是类型安全的语言。
- **弱类型定义语言** ： 数据类型可以被忽略的语言。它与强类型定义语言相反, 一个变量可以赋不同数据类型的值。强类型定义语言在速度上可能略逊色于弱类型定义语言，但是强类型定义语言带来的严谨性能够有效的避免许多错误。

## 4 基于栈的字节码解释执行引擎

​	虚拟机如何调用方法的内容已经讲解完毕，现在我们来探讨虚拟机是如何执行方法中的字节码指令。

### 4.1 解释执行

​	Java语言经常被人们定位为 **“解释执行”语言**，在Java初生的JDK1.0时代，这种定义还比较准确的，但当主流的虚拟机中都包含了即时编译后，Class文件中的代码到底会被解释执行还是编译执行，就成了只有虚拟机自己才能准确判断的事情。再后来，Java也发展出来了直接生成本地代码的编译器[如何GCJ（GNU Compiler for the Java）]，而C/C++也出现了通过解释器执行的版本（如CINT），这时候再笼统的说“解释执行”，对于整个Java语言来说就成了几乎没有任何意义的概念，**只有确定了谈论对象是某种具体的Java实现版本和执行引擎运行模式时，谈解释执行还是编译执行才会比较确切**。![image-20190107182530203](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190107182530203-6856730.png)

​	**Java语言中，javac编译器完成了程序代码经过词法分析、语法分析到抽象语法树，再遍历语法树生成线性的字节码指令流的过程，因为这一部分动作是在Java虚拟机之外进行的，而解释器在虚拟机内部，所以Java程序的编译就是半独立实现的。**

### 4.2 基于栈的指令集和基于寄存器的指令集

​	Java编译器输出的指令流，基本上是一种**基于栈的指令集架构（Instruction Set Architecture，ISA）**，**依赖操作数栈进行工作**。与之相对应的另一套常用的指令集架构是**基于寄存器的指令集**， **依赖寄存器进行工作**。

那么，**基于栈的指令集和基于寄存器的指令集这两者有什么不同呢？**

举个简单例子，分别使用这两种指令计算1+1的结果，**基于栈的指令集会是这个样子：**

```
iconst_1
iconst_1
iadd
istore_0
```

​	两条iconst_1指令连续把两个常量1压入栈后，iadd指令把栈顶的两个值出栈、相加，然后将结果放回栈顶，最后istore_0把栈顶的值放到局部变量表中的第0个Slot中。

**如果基于寄存器的指令集，那程序可能会是这个样子：**

```
mov eax, 1
add eax, 1
```

​	mov指令把EAX寄存器的值设置为1，然后add指令再把这个值加1，将结果就保存在EAX寄存器里面。

**基于栈的指令集主要的优点就是可移植，寄存器是由硬件直接提供，程序直接依赖这些硬件寄存器则不可避免地要受到硬件的约束。**

**栈架构的指令集还有一些其他的优点，如代码相对更加紧凑，编译器实现更加简单等。 栈架构指令集的主要缺点是执行速度相对来说会稍微慢一些。**

# 七、早期（编译期）优化

## 1 概述

​	Java语言的“编译期”其实是一段“不确定”的操作过程，因为它可能是指一个前端编译器（其实叫“编译器的前端”更准确一些）把***.java文件转变成*.class文件的过程**；也可能是指虚拟机的后端运行期编译器（JIT编译器，Just In Time Compiler）**把字节码转变成机器码的过程**；还可能是指使用静态提前编译器（AOT编译器，Ahead Of Time Compiler）**直接把*.java文件编译成本地机器代码的过程。**

## 2.javac编译器

### 2.1 Javac的源码与调试

**从SunJavac的代码来看，编译过程大致可以分为3个过程，分别是：**

- 解析与填充符号表过程。
- 插入式注解处理器的注解处理过程。
- 分析与字节码生成过程。

![image-20190114102843650](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190114102843650-7432923.png)

​	**Javac编译动作的入口是com.sun.tools.javac.main.JavaCompiler类，**上述3个过程的代码逻辑集中在这个类的compile（）和compile2（）方法中，其中主体代码如图10-5所示，整个编译最关键的处理就由图中标注的8个方法来完成，下面我们具体看一下这8个方法实现了什么功能。![image-20190114103311103](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190114103311103-7433191.png)

### 2.2 解析与填充符号表

​	解析步骤由图10-5中的parseFiles（）方法（图10-5中的过程1.1）完成，**解析步骤包括了经典程序编译原理中的词法分析和语法分析两个过程。**

#### 	1.词法、语法分析

​	词法分析是将源代码的字符流转变为标记（Token）集合，单个字符是程序编写过程的最小元素，而标记则是编译过程的最小元素，关键字、变量名、字面量、运算符都可以成为标记，如“int a=b+2”这句代码包含了6个标记，分别是int、a、=、b、+、2，虽然关键字int由3个字符构成，但是它只是一个Token，不可再拆分。在Javac的源码中，词法分析过程由com.sun.tools.javac.parser.Scanner类来实现。

​	语法分析是根据Token序列构造抽象语法树的过程，==抽象语法树（Abstract SyntaxTree,AST）是一种用来描述程序代码语法结构的树形表示方式，语法树的每一个节点都代表着程序代码中的一个语法结构（Construct），例如包、类型、修饰符、运算符、接口、返回值甚至代码注释等都可以是一个语法结构。==![image-20190114104744206](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190114104744206-7434064.png)

#### 	2.填充符号表

​	完成了语法分析和词法分析之后，下一步就是填充符号表的过程，也就是图10-5中enterTrees（）方法（图10-5中的过程1.2）所做的事情。符号表（Symbol Table）是由一组符号地址和符号信息构成的表格，可以把它想象成哈希表中K-V值对的形式（实际上符号表不一定是哈希表实现，可以是有序符号表、树状符号表、栈结构符号表等）。符号表中所登记的信息在编译的不同阶段都要用到。在语义分析中，符号表所登记的内容将用于语义检查（如检查一个名字的使用和原先的说明是否一致）和产生中间代码。在目标代码生成阶段，当对符号名进行地址分配时，符号表是地址分配的依据。

​	在Javac源代码中，填充符号表的过程由com.sun.tools.javac.comp.Enter类实现，此过程的出口是一个待处理列表（To Do List），包含了每一个编译单元的抽象语法树的顶级节点，以及package-info.java（如果存在的话）的顶级节点。

### 2.3 注解处理器

​	在JDK 1.5之后，Java语言提供了对注解（Annotation）的支持，这些注解与普通的Java代码一样，是在运行期间发挥作用的。在JDK 1.6中实现了JSR-269规范，提供了一组**插入式注解处理器**的标准API在编译期间对注解进行处理，**我们可以把它看做是一组编译器的插件，在这些插件里面，可以读取、修改、添加抽象语法树中的任意元素。**==如果这些插件在处理注解期间对语法树进行了修改，编译器将回到解析及填充符号表的过程重新处理，直到所有插入式注解处理器都没有再对语法树进行修改为止，每一次循环称为一个Round==，也就是javac编译过程图中的回环过程。

​	有了编译器注解处理的标准API后，我们的代码才有可能干涉编译器的行为，由于语法树中的任意元素，甚至包括代码注释都可以在插件之中访问到，所以通过插入式注解处理器实现的插件在功能上有很大的发挥空间。在Javac源码中，**插入式注解处理器的初始化过程是在initPorcessAnnotations（）方法中完成的，而它的执行过程则是在processAnnotations（）方法中完成的，**这个方法判断是否还有新的注解处理器需要执行，如果有的话，通过com.sun.tools.javac.processing.JavacProcessingEnvironment类的doProcessing（）方法生成一个新的JavaCompiler对象对编译的后续步骤进行处理。

### 2.4 语义分析与字节码生成

​	**语法分析之后，编译器获得了程序代码的抽象语法树表示，**语法树能表示一个结构正确的源程序的抽象，但无法保证源程序是符合逻辑的。而语**义分析的主要任务是对结构上正确的源程序进行上下文有关性质的审查，如进行类型审查。**举个例子，假设有如下的3个变量定义语句：

```
int a=1；boolean b=false；char c=2；
```

后续可能出现的赋值运算：

```
int d=a+c；int d=b+c；char d=a+c；
```

​	后续代码中如果出现了如上3种赋值运算的话，那它们都能构成结构正确的语法树，但是只有第1种的写法在语义上是没有问题的，能够通过编译，其余两种在Java语言中是不合逻辑的，无法编译（是**否合乎语义逻辑必须限定在具体的语言与具体的上下文环境之中才有意义。**如在C语言中，a、b、c的上下文定义不变，第2、3种写法都是可以正确编译）。

#### 1.标注检查

​	==Javac的编译过程中，语义分析过程分为标注检查以及数据及控制流分析两个步骤==，分别由javac编译过程的主体代码图中所示的attribute（）和flow（）方法（分别对应图中的过程3.1和过程3.2）完成。**标注检查步骤检查的内容包括诸如变量使用前是否已被声明、变量与赋值之间的数据类型是否能够匹配等。**在标注检查步骤中，还有一个重要的动作称为常量折叠，如果我们在代码中写了如下定义：	int a=1+2;

​	那么在语法树上仍然能看到字面量“1”、“2”以及操作符“+”，但是在经过常量折叠之后，它们将会被折叠为字面量“3”，如下图所示，**这个插入式表达式（Infix Expression）的值已经在语法树上标注出来了**（ConstantExpressionValue：3）。==由于编译期间进行了常量折叠，所以在代码里面定义“a=1+2”比起直接定义“a=3”，并不会增加程序运行期哪怕仅仅一个CPU指令的运算量。==![image-20190114110215575](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190114110215575-7434935.png)

​	标注检查步骤在Javac源码中的实现类是com.sun.tools.javac.comp.Attr类和com.sun.tools.javac.comp.Check类。

#### 2.数据及控制流分析

​	**数据及控制流分析是对程序上下文逻辑更进一步的验证，它可以检查出诸如程序局部变量在使用前是否有赋值、方法的每条路径是否都有返回值、是否所有的受查异常都被正确处理了等问题。**编译时期的数据及控制流分析与类加载时的数据及控制流分析的目的基本上是一致的，但校验范围有所区别，==有一些校验项只有在编译期或运行期才能进行。==看下面的例子：

```Java
//方法一带有final修饰
public void foo（final int arg）{
	final int var=0；
	//do something
}
//方法二没有final修饰
public void foo（int arg）{
	int var=0；
	//do something
}
```

​	在这两个foo（）方法中，第一种方法的参数和局部变量定义使用了final修饰符，而第二种方法则没有，在代码编写时程序肯定会受到final修饰符的影响，不能再改变arg和var变量的值，但是==这两段代码编译出来的Class文件是没有任何一点区别的==。局部变量与字段（实例变量、类变量）是有区别的，它在常量池中没有CONSTANT_Fieldref__info的符号引用，自然就没有访问标志（Access_Flags）的信息，甚至可能连名称都不会保留下来（取决于编译时的选项），自然在Class文件中不可能知道一个局部变量是不是声明为final了。**因此，将局部变量声明为final，对运行期是没有影响的，变量的不变性仅仅由编译器在编译期间保障。**在Javac的源码中，数据及控制流分析的入口是图10-5中的flow（）方法（对应图10-5中的过程3.2），具体操作由com.sun.tools.javac.comp.Flow类来完成。

#### 3.解语法糖

​	Java中最常用的语法糖主要是前面提到过的泛型（泛型并不一定都是语法糖实现，如C#的泛型就是直接由CLR支持的）、变长参数、自动装箱/拆箱等，虚拟机运行时不支持这些语法，它们在编译阶段还原回简单的基础语法结构，这个过程称为解语法糖。

​	在Javac的源码中，解语法糖的过程由desugar（）方法触发，在com.sun.tools.javac.comp.TransTypes类和com.sun.tools.javac.comp.Lower类中完成。

#### 4.字节码生成

​	==字节码生成是Javac编译过程的最后一个阶段，在Javac源码里面由com.sun.tools.javac.jvm.Gen类来完成==。字节码生成阶段不仅仅是把前面各个步骤所生成的信息（语法树、符号表）转化成字节码写到磁盘中，编译器还进行了少量的代码添加和转换工作。

​	例如，**前面章节中多次提到的实例构造器＜init＞（）方法和类构造器＜clinit＞（）方法就是在这个阶段添加到语法树之中的**（注意，这里的实例构造器并不是指默认构造函数，如果用户代码中没有提供任何构造函数，那编译器将会添加一个没有参数的、访问性（public、protected或private）与当前类一致的默认构造函数，这个工作在填充符号表阶段就已经完成），这两个构造器的产生过程实际上是一个代码收敛的过程，编译器会把语句块（对于实例构造器而言是“{}”块，对于类构造器而言是“static{}”块）、变量初始化（实例变量和类变量）、调用父类的实例构造器（仅仅是实例构造器，＜clinit＞（）方法中无须调用父类的＜clinit＞（）方法，虚拟机会自动保证父类构造器的执行，但在＜clinit＞（）方法中经常会生成调用java.lang.Object的＜init＞（）方法的代码）等操作收敛到＜init＞（）和＜clinit＞（）方法之中，并且保证一定是按先执行父类的实例构造器，然后初始化变量，最后执行语句块的顺序进行，上面所述的动作由Gen.normalizeDefs（）方法来实现。除了生成构造器以外，还有其他的一些代码替换工作用于优化程序的实现逻辑，如把字符串的加操作替换为StringBuffer或StringBuilder（取决于目标代码的版本是否大于或等于JDK 1.5）的append（）操作等。

​	**完成了对语法树的遍历和调整之后，就会把填充了所有所需信息的符号表交给com.sun.tools.javac.jvm.ClassWriter类，由这个类的writeClass（）方法输出字节码，生成最终的Class文件，到此为止整个编译过程宣告结束。**

## 3 Java语法糖的味道

### 3.1 泛型与类型

​	擦除泛型是JDK 1.5的一项新增特性，**它的本质是参数化类型（Parametersized Type）的应用，也就是说所操作的数据类型被指定为一个参数。**这种参数类型可以用在类、接口和方法的创建中，分别称为泛型类、泛型接口和泛型方法。

​	泛型技术在C#和Java之中的使用方式看似相同，但实现上却有着根本性的分歧，C#里面泛型无论在程序源码中、编译后的IL中（Intermediate Language，中间语言，这时候泛型是一个占位符），或是运行期的CLR中，都是切实存在的，List＜int＞与List＜String＞就是两个不同的类型，它们在系统运行期生成，有自己的虚方法表和类型数据，这种实现称为类型膨胀，基于这种方法实现的泛型称为真实泛型。**Java语言中的泛型则不一样，它只在程序源码中存在，在编译后的字节码文件中，就已经替换为原来的原生类型（Raw Type，也称为裸类型）了，并且在相应的地方插入了强制转型代码，因此，对于运行期的Java语言来说，ArrayList＜int＞与ArrayList＜String＞就是同一个类，所以泛型技术实际上是Java语言的一颗语法糖，Java语言中的泛型实现方法称为类型擦除，基于这种方法实现的泛型称为伪泛型。**

看个例子：

```Java
//泛型擦除前
public static void main（String[]args）{
	Map＜String,String＞map=new HashMap＜String,String＞（）；
	map.put（"hello"，"你好"）；
	map.put（"how are you?"，"吃了没？"）；
    System.out.println（map.get（"hello"））；
    System.out.println（map.get（"how are you?"））；}
	
//泛型擦除后
public static void main（String[]args）{
	Map map=new HashMap（）；
	Map map=new HasMap（）；
	map.put（"hello"，"你好"）；
	map.put（"how are you?"，"吃了没？"）；
    System.out.println（（String）map.get（"hello"））；
    System.out.println（（String）map.get（"how are you?"））；}
```

#### 泛型与重载：

```Java
public class GenericTypes{
	public static void method（List＜String＞list）{
		System.out.println（"invoke method（List＜String＞list）"）；
	}
	public static void method（List＜Integer＞list）{
		System.out.println（"invoke method（List＜Integer＞list）"）；
	}
}
```

​	上面这个类是不能通过编译的，因为这两个method经过类型擦除后，都会变成List<E>类型，所以显然不符合重载的语法。**但只能说泛型擦除成相同的原生类型只是无法重载的其中一部分原因。**

看这个例子：

```Java
public class GenericTypes{
	public static String method（List＜String＞list）{
		System.out.println（"invoke method（List＜String＞list）"）；
		return ""；
	}
	public static int method（List＜Integer＞list）{
		System.out.println（"invoke method（List＜Integer＞list）"）；
		return 1；
	}
	public static void main（String[]args）{
		method（new ArrayList＜String＞（））；
		method（new ArrayList＜Integer＞（））；
		}
}

//执行结果：
invoke method（List＜String＞list）
invoke method（List＜Integer＞list）
```

​	上面这个重载例子执行成功了，是因为**两个method（）方法加入了不同的返回值后才能共存在一个Class文件之中。**前面介绍Class文件方法表（method__info）的数据结构时曾经提到过，**方法重载要求方法具备不同的特征签名，返回值并不包含在方法的特征签名之中，所以返回值不参与重载选择，但是在Class文件格式之中，只要描述符不是完全一致的两个方法就可以共存。**也就是说，==两个方法如果有相同的名称和特征签名，但返回值不同，那它们也是可以合法地共存于一个Class文件中的。==

### 3.2 自动装箱、拆箱与遍历循环

​	先看个例子：

```Java
public static void main（String[]args）{
	List＜Integer＞list=Arrays.asList（1，2，3，4）；
	//如果在JDK 1.7中，还有另外一颗语法糖能让上面这句代码进一步简写成
	//List＜Integer＞list=[1，2，3，4]；
	int sum=0；
	for（int i：list）{
		sum+=i；
	}
	System.out.println（sum）；
}

//编译后
public static void main（String[] args）{
	List list = Arrays.asList（new Integer[]{
        Integer.valueOf（1），
        Integer.valueOf（2），
        Integer.valueOf（3），
        Integer.valueOf（4）}）；
        int sum = 0；
        for（Iterator localIterator = list.iterator（）；localIterator.hasNext（）；）{
                int i =（（Integer）localIterator.next（））.intValue（）；
                 sum += i；
   	} 
    System.out.println（sum）；
}
```

​	上面的例子一共包含了泛型、自动装箱、自动拆箱、遍历循环与变长参数5种语法糖。**自动装箱、拆箱在编译之后被转化成了对应的包装和还原方法，**如本例中的Integer.valueOf（）与Integer.intValue（）方法，而**遍历循环则把代码还原成了迭代器的实现，这也是为何遍历循环需要被遍历的类实现Iterable接口的原因。**最后再看看变长参数，它在调用的时候变成了一个数组类型的参数，在变长参数出现之前，程序员就是使用数组来完成类似功能的。

### 3.3 条件编译

​	在Java语言之中并没有使用预处理器，因为Java语言天然的编译方式（编译器并非一个个地编译Java文件，而是将所有编译单元的语法树顶级节点输入到待处理列表后再进行编译，因此各个文件之间能够互相提供符号信息）无须使用预处理器。

​	Java语言当然也可以进行条件编译，方法就是**使用条件为常量的if语句**。

举个例子：

```java
public static void main（String[]args）{
	if（true）{
		System.out.println（"block 1"）；
		}else{
		System.out.println（"block 2"）；
		}
	}
	//反编译结果：
	public static void main（String[]args）{
		System.out.println（"block 1"）；
		}
```

​	这里的if语句不同于其他Java代码，它在编译阶段就会被“运行”，生成的字节码之中只包括“System.out.println（"block 1"）；”一条语句，并不会包含if语句及另外一个分子中的“System.out.println（"block 2"）；”

​	只能使用条件为常量的if语句才能达到上述效果，如果使用常量与其他带有条件判断能力的语句搭配，则可能在控制流分析中提示错误，被拒绝编译。	

​	Java语言中条件编译的实现，也是Java语言的一颗语法糖，根据布尔常量值的真假，**编译器将会把分支中不成立的代码块消除掉，这一工作将在编译器解除语法糖阶段（com.sun.tools.javac.comp.Lower类中）完成。**由于这种条件编译的实现方式使用了if语句，所以它必须遵循最基本的Java语法，只能写在方法体内部，因此它只能实现语句基本块（Block）级别的条件编译，而没有办法实现根据条件调整整个Java类的结构。

# 八、晚期（运行期）优化

## 1 概述

​	在部分的商用虚拟机（Sun HotSpot、IBM J9）中，Java程序最初是通过解释器（Interpreter）进行解释执行的，当虚拟机发现某个方法或代码块的运行特别频繁时，就会把这些代码认定为**“热点代码”**（Hot Spot Code）。为了提高热点代码的执行效率，在运行时，虚拟机将会把这些代码编译成与本地平台相关的机器码，并进行各种层次的优化，完成这个任务的编译器称为即时编译器（Just In Time Compiler，下文中简称JIT编译器）。

## 2 HotSpot虚拟机内的即时编译器

### 2.1 解释器与编译器

​	解释器与编译器两者各有优势：**当程序需要迅速启动和执行的时候，解释器可以首先发挥作用，省去编译的时间，立即执行。在程序运行后，随着时间的推移，编译器逐渐发挥作用，把越来越多的代码编译成本地代码之后，可以获取更高的执行效率。**当程序运行环境中内存资源限制较大（如部分嵌入式系统中），可以使用解释执行节约内存，反之可以使用编译执行来提升效率。同时，解释器还可以作为编译器激进优化时的一个“逃生门”，让编译器根据概率选择一些大多数时候都能提升运行速度的优化手段，当激进优化的假设不成立，如加载了新类后类型继承结构出现变化、出现“罕见陷阱”（Uncommon Trap）时可以通过逆优化（Deoptimization）退回到解释状态继续执行（部分没有解释器的虚拟机中也会采用不进行激进优化的C1编译器担任“逃生门”的角色），因此，在整个虚拟机执行架构中，解释器与编译器经常配合工作，如图：![image-20190115102542963](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190115102542963-7519143.png)





​	HotSpot虚拟机中内置了两个即时编译器，分别称为Client Compiler和Server Compiler，或者简称为C1编译器和C2编译器（也叫Opto编译器）。client模式和server模式

### 2.2 编译对象与触发条件

​	“热点代码”有两类：被多次调用的方法和被多次执行的循环体。

​	对于第一种情况，由于是由方法调用触发的编译，因此编译器理所当然地会以整个方法作为编译对象，这种编译也是虚拟机中标准的JIT编译方式。而对于后一种情况，尽管编译动作是由循环体所触发的，但编译器依然会以整个方法（而不是单独的循环体）作为编译对象。这种编译方式因为编译发生在方法执行过程之中，因此形象地称之为**栈上替换（OnStack Replacement，简称为OSR编译，即方法栈帧还在栈上，方法就被替换了）。**

​	热点代码的探测目前主要有两种方式：

**基于采样的热点探测**（Sample Based Hot Spot Detection）：采用这种方法的虚拟机会周期性地检查各个线程的栈顶，如果发现某个（或某些）方法经常出现在栈顶，那这个方法就是“热点方法”。**基于采样的热点探测的好处是实现简单、高效，还可以很容易地获取方法调用关系（将调用堆栈展开即可），缺点是很难精确地确认一个方法的热度，容易因为受到线程阻塞或别的外界因素的影响而扰乱热点探测。**

**基于计数器的热点探测**（Counter Based Hot Spot Detection）：采用这种方法的虚拟机会为每个方法（甚至是代码块）建立计数器，统计方法的执行次数，如果执行次数超过一定的阈值就认为它是“热点方法”。这种统计方法实现起来麻烦一些，需要为每个方法建立并维护计数器，而且不能直接获取到方法的调用关系，但是它的统计结果相对来说更加精确和严谨。

​	在HotSpot虚拟机中使用的是第二种——基于计数器的热点探测方法，因此它为每个方法准备了==两类计数器：方法调用计数器（Invocation Counter）和回边计数器（Back EdgeCounter）==。在确定虚拟机运行参数的前提下，这两个计数器都有一个确定的阈值，当计数器超过阈值溢出了，就会触发JIT编译。

​	顾名思义，方法调用计数器就用于统计方法被调用的次数，它的**默认阈值在Client模式下是1500次，在Server模式下是10 000次，这个阈值可以通过虚拟机参数-XX：CompileThreshold来人为设定。**==当一个方法被调用时，会先检查该方法是否存在被JIT编译过的版本，如果存在，则优先使用编译后的本地代码来执行。如果不存在已被编译过的版本，则将此方法的调用计数器值加1，然后判断方法调用计数器与回边计数器值之和是否超过方法调用计数器的阈值。==如果已超过阈值，那么将会向即时编译器提交一个该方法的代码编译请求。如果不做任何设置，执行引擎并不会同步等待编译请求完成，而是继续进入解释器按照解释方式执行字节码，直到提交的请求被编译器编译完成。**当编译工作完成之后，这个方法的调用入口地址就会被系统自动改写成新的，下一次调用该方法时就会使用已编译的版本。**整个JIT编译的交互过程如图：![image-20190115103719283](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190115103719283-7519839.png)

​	如果不做任何设置，方法调用计数器统计的并不是方法被调用的绝对次数，而是一个相对的执行频率，即一段时间之内方法被调用的次数。当超过一定的时间限度，如果方法的调用次数仍然不足以让它提交给即时编译器编译，那这个方法的调用计数器就会被减少一半，这个过程称为方法调用计数器热度的衰减（Counter Decay），而这段时间就称为此方法统计的半衰周期（Counter Half Life Time）。进行热度衰减的动作是在虚拟机进行垃圾收集时顺便进行的，可以使用虚拟机参数-XX：-UseCounterDecay来关闭热度衰减，让方法计数器统计方法调用的绝对次数，这样，只要系统运行时间足够长，绝大部分方法都会被编译成本地代码。另外，可以使用-XX：CounterHalfLifeTime参数设置半衰周期的时间，单位是秒。

​	回边计数器，它的作用是统计一个方法中循环体代码执行的次数，在字节码中遇到控制流向后跳转的指令称为“回边”（Back Edge）。显然，**建立回边计数器统计的目的就是为了触发OSR编译。**

![image-20190115105234034](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190115105234034-7520754.png)

​	当解释器遇到一条回边指令时，会先查找将要执行的代码片段是否有已经编译好的版本，如果有，它将会优先执行已编译的代码，否则就把回边计数器的值加1，然后判断方法调用计数器与回边计数器值之和是否超过回边计数器的阈值。当超过阈值的时候，将会提交一个OSR编译请求，并且把回边计数器的值降低一些，以便继续在解释器中执行循环，等待编译器输出编译结果。

### 2.3 编译过程

# 九、Java内存模型与线程

## 1 概述

​	除了充分利用计算机处理器的能力外，一个服务端同时对多个客户端提供服务则是另一个更具体的并发应用场景。衡量一个服务性能的高低好坏，每秒事务处理数（TransactionsPer Second,TPS）是最重要的指标之一，它代表着一秒内服务端平均能响应的请求总数，而TPS值与程序的并发能力又有非常密切的关系。对于计算量相同的任务，程序线程并发协调得越有条不紊，效率自然就会越高；反之，线程之间频繁阻塞甚至死锁，将会大大降低程序的并发能力。

## 2 硬件的效率与一致性	

​	**由于计算机的存储设备与处理器的运算速度有几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲**：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了。

​	基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是也为计算机系统带来更高的复杂度，因为它引入了一个新的问题：缓存一致性（Cache Coherence）。在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（MainMemory），如图：![image-20190115113639489](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190115113639489-7523399.png)

​	除了增加高速缓存之外，为了使得处理器内部的运算单元能尽量被充分利用，**处理器可能会对输入代码进行乱序执行（Out-Of-Order Execution）优化，处理器会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一致的，**但并不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致，因此，==如果存在一个计算任务依赖另外一个计算任务的中间结果，那么其顺序性并不能靠代码的先后顺序来保证。与处理器的乱序执行优化类似，Java虚拟机的即时编译器中也有类似的指令重排序（Instruction Reorder）优化。==

## 3 Java内存模型

​	Java虚拟机规范中试图**定义一种Java内存模型（Java Memory Model,JMM）来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。**

### 3.1 主内存与工作内存

​	Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。**此处的变量（Variables）与Java编程中所说的变量有所区别，它包括了实例字段、静态字段和构成数组对象的元素，但不包括局部变量与方法参数，因为后者是线程私有的，不会被共享，自然就不会存在竞争问题。**

​	为了获得较好的执行效能，Java内存模型并没有限制执行引擎使用处理器的特定寄存器或缓存来和主内存进行交互，也没有限制即时编译器进行调整代码执行顺序这类优化措施。

​	**Java内存模型规定了所有的变量都存储在主内存（Main Memory）中（此处的主内存与介绍物理硬件时的主内存名字一样，两者也可以互相类比，但此处仅是虚拟机内存的一部分）。每条线程还有自己的工作内存（Working Memory，可与前面讲的处理器高速缓存类比），线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量。**

​	==不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成，线程、主内存、工作内存三者的交互关系如图==。这里所讲的主内存、工作内存与本书第2章所讲的Java内存区域中的Java堆、栈、方法区等并不是同一个层次的内存划分，这两者基本上是没有关系的，如果两者一定要勉强对应起来，那从变量、主内存、工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据部分，而工作内存则对应于虚拟机栈中的部分区域。从更低层次上说，主内存就直接对应于物理硬件的内存，而为了获取更好的运行速度，虚拟机（甚至是硬件系统本身的优化措施）可能会让工作内存优先存储于寄存器和高速缓存中，**因为程序运行时主要访问读写的是工作内存。**

![image-20190115120037249](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190115120037249-7524837.png)

##### 注意：

​	**如果局部变量是一个reference类型，它引用的对象在Java堆中可被各个线程共享，但是reference本身在Java栈的局部变量表中，它是线程私有的。**

### 3.2 内存间交互操作

​	关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节，Java内存模型中定义了以下8种操作来完成，虚拟机实现时必须保证下面提及的每一种操作都是原子的、不可再分的。

- lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。
- unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。
- read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。
- load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。
- use（使用）：**作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。**
- assign（赋值）：作用于工作内存的变量，**它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。**
- store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用。
- write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。

​	**如果要把一个变量从主内存复制到工作内存，那就要==顺序地执行read和load操作==，如果要把变量从工作内存同步回主内存，就要==顺序地执行store和write操作==。**==注意，Java内存模型只要求上述两个操作必须按顺序执行，而没有保证是连续执行==。也就是说，**read与load之间、store与write之间是可插入其他指令的**，如对主内存中的变量a、b进行访问时，一种可能出现顺序是read a、read b、load b、load a。

​	除此之外，Java内存模型还规定了在执行上述8种基本操作时必须满足如下规则：

- **不允许read和load、store和write操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或者从工作内存发起回写了但主内存不接受的情况出现。**
- ==不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。==
- 不允许一个线程无原因地（没有发生过任何assign操作）把数据从线程的工作内存同步回主内存中。
- 一个新的变量只能在主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量，换句话说，就是对一个变量实施use、store操作之前，必须先执行过了assign和load操作。
- ==一个变量在同一个时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。==
- 如果对一个变量执行lock操作，那将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值。
- 如果一个变量事先没有被lock操作锁定，那就不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定住的变量。
- 对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操作）。

### 3.3 对于volatile型变量的特殊规则

​	当一个变量定义为volatile之后，它将具备两种特性，**第一是保证此变量对所有线程的可见性，这里的“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。**而普通变量不能做到这一点，普通变量的值在线程间传递均需要通过主内存来完成，例如，线程A修改一个普通变量的值，然后向主内存进行回写，另外一条线程B在线程A回写完成了之后再从主内存进行读取操作，新变量值才会对线程B可见。

​	关于volatile变量的可见性，经常会被开发人员误解，认为以下描述成立：“volatile变量对所有线程是立即可见的，对volatile变量所有的写操作都能立刻反应到其他线程之中，换句话说，volatile变量在各个线程中是一致的，所以基于volatile变量的运算在并发下是安全的”。这句话的论据部分并没有错，但是其论据并不能得出“基于volatile变量的运算在并发下是安全的”这个结论。**volatile变量在各个线程的工作内存中不存在一致性问题（在各个线程的工作内存中，volatile变量也可以存在不一致的情况，但由于每次使用之前都要先刷新，执行引擎看不到不一致的情况，因此可以认为不存在一致性问题）**，但是Java里面的运算并非原子操作，导致volatile变量的运算在并发下一样是不安全的，如下面的例子：

```java
public class VolatileTest{
	public static volatile int race=0；
	public static void increase（）{
		race++；
		}
	private static final int THREADS_COUNT=20；
	public static void main（String[]args）{
		Thread[]threads=new Thread[THREADS_COUNT]；
		for（int i=0；i＜THREADS_COUNT；i++）{
			threads[i]=new Thread（new Runnable（）{
				@Override
				public void run（）{
					for（int i=0；i＜10000；i++）{
						increase（）；
						}
					}
				}）；
				threads[i].start（）；
				}
		//等待所有累加线程都结束
		while（Thread.activeCount（）＞1）
			Thread.yield（）；
		System.out.println（race）；
		}
	}

//javap反编译后得到的代码
public static void increase（）；
Code：
Stack=2，Locals=0，Args_size=0
0：getstatic#13；	//Field race：I
3：iconst_1
4：iadd
5：putstatic#13；//Field race：I
8：returnLineNumberTable：
line 14：0
line 15：8
```

​	这段代码发起了20个线程，每个线程对race变量进行10000次自增操作，如果这段代码能够正确并发的话，最后输出的结果应该是200000，但实际上结果都是小于200000的，这是因为自增运算“race++”之中，我们用Javap反编译这段代码后会得到如上代码，**发现只有一行代码的increase（）方法在Class文件中是由4条字节码指令构成的（return指令不是由race++产生的，这条指令可以不计算）**，从字节码层面上很容易就分析出并发失败的原因了：当getstatic指令把race的值取到操作栈顶时，==volatile关键字保证了race的值在此时是正确的==，但**是在执行iconst_1、iadd这些指令的时候，其他线程可能已经把race的值加大了，而在操作栈顶的值就变成了过期的数据，所以putstatic指令执行后就可能把较小的race值同步回主内存之中**。

由于volatile变量只能保证可见性，在不符合以下两条规则的运算场景中，我们仍然要通过加锁（使用synchronized或java.util.concurrent中的原子类）来保证原子性。

- 运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值。
- 变量不需要与其他的状态变量共同参与不变约束。

​	**使用volatile变量的第二个语义是禁止指令重排序优化，普通的变量仅仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。**因为在一个线程的方法执行过程中无法感知到这点，这也就是Java内存模型中描述的所谓的“线程内表现为串行的语义”。

下面举两个例子解释说明重排序为啥会干扰程序的并发执行：

```java
Map configOptions；
char[]configText；
//此变量必须定义为carcongText；
volatile boolean initialized=false；
//假设以下代码在线程A中执行
//模拟读取配置信息，当读取完成后将initialized设置为true以通知其他线程配置可用
configOptions=new HashMap（）；
configText=readConfigFile（fileName）；
processConfigOptions（configText,configOptions）；
initialized=true；
//假设以下代码在线程B中执行
//等待initialized为true，代表线程A已经把配置信息初始化完成
while（！initialized）{
	sleep（）；
}
//使用线程A中初始化好的配置信息
doSomethingWithConfig（）；
```

​	如果定义initialized变量时没有使用volatile修饰，就可能会由于指令重排序的优化，**导致位于线程A中最后一句的代码“initialized=true”被提前执行**（这里虽然使用Java作为伪代码，但所指的重排序优化是机器级的优化操作，提前执行是指这句话对应的汇编代码被提前执行），这样在线程B中使用配置信息的代码就可能出现错误，而volatile关键字则可以避免此类情况的发生。

下面这个例子是双重检验锁单例模式：

```java
public static class SingleTon7 {
        private volatile static SingleTon7 instance = null;

        private SingleTon7() {
        }

        public static SingleTon7 getInstance() {
            if (instance == null) {
                synchronized (SingleTon7.class) {
                    instance = new SingleTon7();
                }
            }
            return instance;
        }
    }

//编译后的字节码：
0x01a3de0f：mov$0x3375cdb0，%esi；……beb0cd75 33
;{oop（'Singleton'）}
0x01a3de14：mov%eax，0x150（%esi）；……89865001 0000
0x01a3de1a：shr$0x9，%esi；……c1ee09
0x01a3de1d：movb$0x0，0x1104800（%esi）；……c6860048 100100
0x01a3de24：lock addl$0x0，（%esp）；……f0830424 00 
;*putstatic instance 
;-
Singleton：getInstance@24
```

​	通过对比就会发现，关键变化在于有volatile修饰的变量，赋值后（前面mov%eax，0x150（%esi）这句便是赋值操作）多执行了一个“lock addl ＄0x0，（%esp）”操作，这个操作相当于一个==内存屏障（Memory Barrier或Memory Fence，指重排序时不能把后面的指令重排序到内存屏障之前的位置==），**只有一个CPU访问内存时，并不需要内存屏障；但如果有两个或更多CPU访问同一块内存，且其中有一个在观测另一个，就需要内存屏障来保证一致性了。**这句指令中的“addl ＄0x0，（%esp）”（把ESP寄存器的值加0）显然是一个空操作（采用这个空操作而不是空操作指令nop是因为IA32手册规定lock前缀不允许配合nop指令使用），关键在于lock前缀，查询IA32手册，**它的作用是使得本CPU的Cache写入了内存，该写入动作也会引起别的CPU或者别的内核无效化**（Invalidate）其Cache，这种操作相当于对Cache中的变量做了一次“store和write”操作。所以通过这样一个空操作，可让前面volatile变量的修改对其他CPU立即可见。

​	那为何说它禁止指令重排序呢？从硬件架构上讲，**指令重排序是指CPU采用了允许将多条指令不按程序规定的顺序分开发送给各相应电路单元处理。**但并不是说指令任意重排，CPU需要能正确处理指令依赖情况以保障程序能得出正确的执行结果。譬如指令1把地址A中的值加10，指令2把地址A中的值乘以2，指令3把地址B中的值减去3，这时指令1和指令2是有依赖的，它们之间的顺序不能重排——（A+10）*2与A*2+10显然不相等，但指令3可以重排到指令1、2之前或者中间，只要保证CPU执行后面依赖到A、B值的操作时能获取到正确的A和B值即可。所以在本内CPU中，重排序看起来依然是有序的。因此，lockaddl＄0x0，（%esp）指令把修改同步到内存时，意味着所有之前的操作都已经执行完成，这样便形成了“指令重排序无法越过内存屏障”的效果。

##### 	回顾Java内存模型中对volatile变量定义的特殊规则。

​	假定T表示一个线程，V和W分别表示两个volatile型变量，那么在进行read、load、use、assign、store和write操作时需要满足如下规则：

​	只有当线程T对变量V执行的前一个动作是load的时候，线程T才能对变量V执行use动作；并且，只有当线程T对变量V执行的后一个动作是use的时候，线程T才能对变量V执行load动作。**线程T对变量V的use动作可以认为是和线程T对变量V的load、read动作相关联，必须连续一起出现（这条规则要求在工作内存中，每次使用V前都必须先从主内存刷新最新的值，用于保证能看见其他线程对变量V所做的修改后的值）。**

​	只有当线程T对变量V执行的前一个动作是assign的时候，线程T才能对变量V执行store动作；并且，只有当线程T对变量V执行的后一个动作是store的时候，线程T才能对变量V执行assign动作。**线程T对变量V的assign动作可以认为是和线程T对变量V的store、write动作相关联，必须连续一起出现（这条规则要求在工作内存中，每次修改V后都必须立刻同步回主内存中，用于保证其他线程可以看到自己对变量V所做的修改）。**

​	假定动作A是线程T对变量V实施的use或assign动作，假定动作F是和动作A相关联的load或store动作，假定动作P是和动作F相应的对变量V的read或write动作；类似的，假定动作B是线程T对变量W实施的use或assign动作，假定动作G是和动作B相关联的load或store动作，假定动作Q是和动作G相应的对变量W的read或write动作。如果A先于B，那么P先于Q（这条规则要求volatile修饰的变量不会被指令重排序优化，保证代码的执行顺序与程序的顺序相同）。

### 3.4 对于long和double型变量的特殊规则

​	Java内存模型要求lock、unlock、read、load、assign、use、store、write这8个操作都具有原子性，但是对于64位的数据类型（long和double），在模型中特别定义了一条相对宽松的规定：**允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进行，即允许虚拟机实现选择可以不保证64位数据类型的load、store、read和write这4个操作的原子性，这点就是所谓的long和double的非原子性协定（Nonatomic Treatment ofdouble andlong Variables）。**

​	如果有多个线程共享一个并未声明为volatile的long或double类型的变量，并且同时对它们进行读取和修改操作，那么某些线程可能会读取到一个既非原值，也不是其他线程修改值的代表了“半个变量”的数值。

​	不过这种读取到“半个变量”的情况非常罕见（在目前商用Java虚拟机中不会出现），因为Java内存模型虽然允许虚拟机不把long和double变量的读写实现成原子操作，但允许虚拟机选择把这些操作实现为具有原子性的操作，而且还“强烈建议”虚拟机这样实现。在实际开发中，目前各种平台下的商用虚拟机几乎都选择把64位数据的读写操作作为原子操作来对待，因此我们在编写代码时一般不需要把用到的long和double变量专门声明为volatile。

### 3.5 原子性、可见性与有序性

##### 	Java内存模型的三大特性：

​	原子性（Atomicity）：**由Java内存模型来直接保证的原子性变量操作包括read、load、assign、use、store和write，我们大致可以认为基本数据类型的访问读写是具备原子性的**（例外就是long和double的非原子性协定，读者只要知道这件事情就可以了，无须太过在意这些几乎不会发生的例外情况）。

​	如果应用场景需要一个更大范围的原子性保证（经常会遇到），Java内存模型还提供了lock和unlock操作来满足这种需求，尽管虚拟机未把lock和unlock操作直接开放给用户使用，但是却提供了更高层次的字节码指令**monitorenter和monitorexit来隐式地使用这两个操作，这两个字节码指令反映到Java代码中就是同步块——synchronized关键字，因此在synchronized块之间的操作也具备原子性。**

​	可见性（Visibility）：可见性是指当一个线程修改了共享变量的值，其他线程能够立即得知这个修改。Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性的，无论是普通变量还是volatile变量都是如此，**普通变量与volatile变量的区别是，volatile的特殊规则保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。**因此，可以说volatile保证了多线程操作时变量的可见性，而普通变量则不能保证这一点。

​	除了volatile之外，Java还有两个关键字能实现可见性，即==synchronized和final==。**同步块的可见性是由“对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操作）”这条规则获得的，而final关键字的可见性是指：被final修饰的字段在构造器中一旦初始化完成，并且构造器没有把“this”的引用传递出去（this引用逃逸是一件很危险的事情，其他线程有可能通过这个引用访问到“初始化了一半”的对象），那在其他线程中就能看见final字段的值。**如下面的代码，变量i与j都具备可见性，它们无须同步就能被其他线程正确访问。

```Java
public static final int i；
public final int j；
static{
	i=0；
	//do something
}
{
//也可以选择在构造函数中初始化
	j=0；
	//do something
}
```

​	有序性（Ordering）：Java程序中天然的有序性可以总结为一句话：**如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句是指“线程内表现为串行的语义”（Within-Thread As-If-Serial Semantics），后半句是指“指令重排序”现象和“工作内存与主内存同步延迟”现象。**

​	==Java语言提供了volatile和synchronized两个关键字来保证线程之间操作的有序性，volatile关键字本身就包含了禁止指令重排序的语义，而synchronized则是由“一个变量在同一个时刻只允许一条线程对其进行lock操作”这条规则获得的，这条规则决定了持有同一个锁的两个同步块只能串行地进入。==

### 3.6 先行发生原则

​	如果Java内存模型中所有的有序性都仅仅靠volatile和synchronized来完成，那么有一些操作将会变得很烦琐，但是我们在编写Java并发代码的时候并没有感觉到这一点，这是因为Java语言中有一个“先行发生”（happens-before）的原则。这个原则非常重要，**它是判断数据是否存在竞争、线程是否安全的主要依据，**依靠这个原则，我们可以通过几条规则一揽子地解决并发环境下两个操作之间是否可能存在冲突的所有问题。

​	先行发生是Java内存模型中定义的两项操作之间的偏序关系，如果说操作A先行发生于操作B，其实就是说在发生操作B之前，操作A产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等。

​	下面是Java内存模型下一些“天然的”先行发生关系，这些先行发生关系无须任何同步器协助就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们随意地进行重排序。

- 程序次序规则（Program Order Rule）：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。
- 管程锁定规则（Monitor Lock Rule）：**一个unlock操作先行发生于后面对同一个锁的lock操作。**这里必须强调的是==同一个锁==，而“后面”是指时间上的先后顺序。
- volatile变量规则（Volatile Variable Rule）：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后顺序。
- 线程启动规则（Thread Start Rule）：Thread对象的start（）方法先行发生于此线程的每一个动作。
- 线程终止规则（Thread Termination Rule）：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread.join（）方法结束、Thread.isAlive（）的返回值等手段检测到线程已经终止执行。
- 线程中断规则（Thread Interruption Rule）：对线程interrupt（）方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted（）方法检测到是否有中断发生。
- 对象终结规则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize（）方法的开始。
- 传递性（Transitivity）：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。

​        **时间先后顺序与先行发生原则之间基本没有太大的关系，所以我们衡量并发安全问题的时候不要受到时间顺序的干扰，一切必须以先行发生原则为准。**

## 4 Java与线程

### 1.线程的实现

​	实现线程主要有3种方式：**使用内核线程实现、使用用户线程实现和使用用户线程加轻量级进程混合实现。**

1.使用内核线程实现

​	内核线程（Kernel-Level Thread,KLT）就是直接由操作系统内核（Kernel，下称内核）支持的线程，这种线程由内核来完成线程切换，**内核通过操纵调度器（Scheduler）对线程进行调度，并负责将线程的任务映射到各个处理器上。**每个内核线程可以视为内核的一个分身，这样操作系统就有能力同时处理多件事情，支持多线程的内核就叫做多线程内核（MultiThreads Kernel）。

​	程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口——轻量级进程（Light Weight Process,LWP）**，轻量级进程就是我们通常意义上所讲的线程，由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。**这种轻量级进程与内核线程之间1:1的关系称为一对一的线程模型，如图所示。

![image-20190115174648309](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190115174648309-7545608.png)

​	由于内核线程的支持，每个轻量级进程都成为一个独立的调度单元，即使有一个轻量级进程在系统调用中阻塞了，也不会影响整个进程继续工作，但是轻量级进程具有它的局限性：首先，由于是基于内核线程实现的，所以各种线程操作，如创建、析构及同步，都需要进行系统调用。而系统调用的代价相对较高，需要在用户态（User Mode）和内核态（KernelMode）中来回切换。其次，每个轻量级进程都需要有一个内核线程的支持，因此轻量级进程要消耗一定的内核资源（如内核线程的栈空间），因此一个系统支持轻量级进程的数量是有限的。

2.使用用户线程实现

​	从广义上来讲，一个线程只要不是内核线程，就可以认为是用户线程（UserThread,UT），因此，从这个定义上来讲，轻量级进程也属于用户线程，但轻量级进程的实现始终是建立在内核之上的，许多操作都要进行系统调用，效率会受到限制。

​	而狭义上的用户线程指的是完全建立在用户空间的线程库上，系统内核不能感知线程存在的实现。用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助。如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗的，也可以支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。这种进程与用户线程之间1：N的关系称为一对多的线程模型，如图

![image-20190115174859894](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190115174859894-7545740.png)

​	使用用户线程的优势在于不需要系统内核支援，劣势也在于没有系统内核的支援，所有的线程操作都需要用户程序自己处理。线程的创建、切换和调度都是需要考虑的问题，而且由于操作系统只把处理器资源分配到进程，那诸如“阻塞如何处理”、“多处理器系统中如何将线程映射到其他处理器上”这类问题解决起来将会异常困难，甚至不可能完成。因而使用用户线程实现的程序一般都比较复杂，除了以前在不支持多线程的操作系统中（如DOS）的多线程程序与少数有特殊需求的程序外，现在使用用户线程的程序越来越少了，Java、Ruby等语言都曾经使用过用户线程，最终又都放弃使用它。

3.使用用户线程加轻量级进程混合实现

​	线程除了依赖内核线程实现和完全由用户程序自己实现之外，还有一种将内核线程与用户线程一起使用的实现方式。在这种混合实现下，既存在用户线程，也存在轻量级进程。用户线程还是完全建立在用户空间中，因此用户线程的创建、切换、析构等操作依然廉价，并且可以支持大规模的用户线程并发。而操作系统提供支持的轻量级进程则作为用户线程和内核线程之间的桥梁，这样可以使用内核提供的线程调度功能及处理器映射，并且用户线程的系统调用要通过轻量级线程来完成，大大降低了整个进程被完全阻塞的风险。在这种混合模式中，用户线程与轻量级进程的数量比是不定的，即为N：M的关系，如图12-5所示，这种就是多对多的线程模型。许多UNIX系列的操作系统，如Solaris、HP-UX等都提供了N：M的线程模型实现。![image-20190115174951562](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190115174951562-7545791.png)

4.Java线程的实现

​	Java线程在JDK 1.2之前，是基于称为“绿色线程”（Green Threads）的用户线程实现的，而在JDK 1.2中，线程模型替换为基于操作系统原生线程模型来实现。因此，在目前的JDK版本中，操作系统支持怎样的线程模型，在很大程度上决定了Java虚拟机的线程是怎样映射的，这点在不同的平台上没有办法达成一致，虚拟机规范中也并未限定Java线程需要使用哪种线程模型来实现。线程模型只对线程的并发规模和操作成本产生影响，对Java程序的编码和运行过程来说，这些差异都是透明的。

​	对于Sun JDK来说，它的Windows版与Linux版都是使用一对一的线程模型实现的，一条Java线程就映射到一条轻量级进程之中，因为Windows和Linux系统提供的线程模型就是一对一的。

​	而在Solaris平台中，由于操作系统的线程特性可以同时支持一对一（通过Bound Threads或Alternate Libthread实现）及多对多（通过LWP/Thread Based Synchronization实现）的线程模型，因此在Solaris版的JDK中也对应提供了两个平台专有的虚拟机参数：-XX：+UseLWPSynchronization（默认值）和-XX：+UseBoundThreads来明确指定虚拟机使用哪种线程模型。

### 2.Java线程调度

​	**线程调度是指系统为线程分配处理器使用权的过程，主要调度方式有两种，分别是==协同式线程调度（Cooperative Threads-Scheduling）和抢占式线程调度（Preemptive ThreadsScheduling）。==**

​	**如果使用协同式调度的多线程系统，线程的执行时间由线程本身来控制，线程把自己的工作执行完了之后，要主动通知系统切换到另外一个线程上。**协同式多线程的==最大好处是实现简单，而且由于线程要把自己的事情干完后才会进行线程切换，切换操作对线程自己是可知的，所以没有什么线程同步的问题。==Lua语言中的“协同例程”就是这类实现。它的坏处也很明显：**线程执行时间不可控制，甚至如果一个线程编写有问题，一直不告知系统进行线程切换，那么程序就会一直阻塞在那里。**很久以前的Windows 3.x系统就是使用协同式来实现多进程多任务的，相当不稳定，一个进程坚持不让出CPU执行时间就可能会导致整个系统崩溃。

​	**如果使用抢占式调度的多线程系统，那么每个线程将由系统来分配执行时间，线程的切换不由线程本身来决定（在Java中，Thread.yield（）可以让出执行时间，但是要获取执行时间的话，线程本身是没有什么办法的）。**==在这种实现线程调度的方式下，线程的执行时间是系统可控的，也不会有一个线程导致整个进程阻塞的问题，Java使用的线程调度方式就是抢占式调度==。与前面所说的Windows 3.x的例子相对，在Windows 9x/NT内核中就是使用抢占式来实现多进程的，当一个进程出了问题，我们还可以使用任务管理器把这个进程“杀掉”，而不至于导致系统崩溃。

​	虽然Java线程调度是系统自动完成的，但是我们还是可以“建议”系统给某些线程多分配一点执行时间，另外的一些线程则可以少分配一点——这项操作可以通过设置线程优先级来完成。Java语言一共设置了10个级别的线程优先级（Thread.MIN_N_PRIORITY至Thread.MAX_X_PRIORITY），在两个线程同时处于Ready状态时，优先级越高的线程越容易被系统选择执行。

​	不过，线程优先级并不是太靠谱，**==原因是Java的线程是通过映射到系统的原生线程上来实现的，所以线程调度最终还是取决于操作系统==**，虽然现在很多操作系统都提供线程优先级的概念，但是并不见得能与Java线程的优先级一一对应，如Solaris中有2147483648（232）种优先级，但Windows中就只有7种，比Java线程优先级多的系统还好说，中间留下一点空位就可以了，但比Java线程优先级少的系统，就不得不出现几个优先级相同的情况了，表12-1显示了Java线程优先级与Windows线程优先级之间的对应关系，Windows平台的JDK中使用了除THREAD_PRIORITY_Y_IDLE之外的其余6种线程优先级。![image-20190115175933206](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190115175933206-7546373.png)

### 3 状态转换

​	Java语言定义了5种线程状态，**在任意一个时间点，一个线程只能有且只有其中的一种状态**，这5种状态分别如下。

新建（New）：创建后尚未启动的线程处于这种状态。

运行（Runable）：==Runable包括了操作系统线程状态中的Running和Ready，也就是处于此状态的线程有可能正在执行，也有可能正在等待着CPU为它分配执行时间。==

无限期等待（Waiting）：处于这种状态的线程不会被分配CPU执行时间，它们要等待被其他线程显式地唤醒。以下方法会让线程陷入无限期的等待状态：

​	●没有设置Timeout参数的Object.wait（）方法。

​	●没有设置Timeout参数的Thread.join（）方法。

​	●LockSupport.park（）方法。

限期等待（Timed Waiting）：处于这种状态的线程也不会被分配CPU执行时间，不过无须等待被其他线程显式地唤醒，在一定时间之后它们会由系统自动唤醒。以下方法会让线程进入限期等待状态：

​	●Thread.sleep（）方法。

​	●设置了Timeout参数的Object.wait（）方法。

​	●设置了Timeout参数的Thread.join（）方法。

​	●LockSupport.parkNanos（）方法。

​	●LockSupport.parkUntil（）方法。

阻塞（Blocked）：线程被阻塞了，**“阻塞状态”与“等待状态”的区别是**：**“阻塞状态”在等待着获取到一个排他锁，这个事件将在另外一个线程放弃这个锁的时候发生；**而“等待状态”则是在等待一段时间，或者唤醒动作的发生。在程序等待进入同步区域的时候，线程将进入这种状态。

结束（Terminated）：已终止线程的线程状态，线程已经结束执行。上述5种状态在遇到特定事件发生的时候将会互相转换，它们的转换关系如下图：![image-20190115180543615](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190115180543615-7546743.png)

# 十、线程安全与锁优化

## 1 Java语言中的线程安全

​	按照线程安全的“安全程度”由强至弱来排序，**我们可以将Java语言中各种操作共享的数据分为以下5类：不可变、绝对线程安全、相对线程安全、线程兼容和线程对立。**

#### 1.不可变

​	在Java语言中（特指JDK 1.5以后，即Java内存模型被修正之后的Java语言），不可变（Immutable）的对象一定是线程安全的，无论是对象的方法实现还是方法的调用者，都不需要再采取任何的线程安全保障措施，只要一个不可变的对象被正确地构建出来（**没有发生this引用逃逸的情况**），那其外部的可见状态永远也不会改变，永远也不会看到它在多个线程之中处于不一致的状态。“不可变”带来的安全性是最简单和最纯粹的。

​	**Java语言中，如果共享数据是一个基本数据类型，那么只要在定义时使用final关键字修饰它就可以保证它是不可变的。**如果共享数据是一个对象，那就需要保证对象的行为不会对其状态产生任何影响才行，比如java.lang.String类的对象，它是一个典型的不可变对象，我们调用它的substring（）、replace（）和concat（）这些方法都不会影响它原来的值，**只会返回一个新构造的字符串对象。**保证对象行为不影响自己状态的途径有很多种，其中最简单的就是==把对象中带有状态的变量都声明为final==，这样在构造函数结束之后，它就是不可变的。

​	在Java API中符合不可变要求的类型，除了上面提到的String之外，常用的还有枚举类型，以及java.lang.Number的部分子类，如Long和Double等数值包装类型(都是用final修饰了)，BigInteger和BigDecimal等大数据类型；但同为Number的子类型的原子类AtomicInteger和AtomicLong则并非不可变的，

#### 2.绝对线程安全

​	在Java API中标注自己是线程安全的类，大多数都不是绝对的线程安全。下面看一个线程安全的类Vector的例子，因为它的add（）、get（）和size（）这类方法都是被synchronized修饰的。

```java
private static Vector＜Integer＞vector=new Vector＜Integer＞（）；
public static void main（String[]args）{
	while（true）{
		for（int i=0；i＜10；i++）{
			vector.add（i）；
		}
Thread removeThread=new Thread（new Runnable（）{
	@Override
	public void run（）{
	//这里要加锁，否则调用的时候也是线程不安全的，synchronized(vector){}
		for（int i=0；i＜vector.size（）；i++）{
			vector.remove（i）；
			}
		}
	}）；
Thread printThread=new Thread（new Runnable（）{
@Override
public void run（）{
//这里要加锁，否则调用的时候也是线程不安全的，synchronized(vector){}
	for（int i=0；i＜vector.size（）；i++{
		System.out.println（（vector.get（i）））；
		}
	}
}）；
removeThread.start（）；
printThread.start（）；
//不要同时产生过多的线程，否则会导致操作系统假死
while（Thread.activeCount（）＞20）；
}
}
```

结果报错了：

```java
Exception in thread"Thread-132"java.lang.ArrayIndexOutOfBoundsException：
	Array index out of range：17
	at java.util.Vector.remove（Vector.java：777）
	at org.fenixsoft.mulithread.VectorTest$1.run（VectorTest.java：21）
	at java.lang.Thread.run（Thread.java：662）
```

​	尽管这里使用到的Vector的get（）、remove（）和size（）方法都是同步的，但是在多线程的环境中，如果不在方法调用端做额外的同步措施的话，使用这段代码仍然是不安全的，因为如果另一个线程恰好在错误的时间里删除了一个元素，导致序号i已经不再可用的话，再用i访问数组就会抛出一个ArrayIndexOutOfBoundsException。如果要保证这段代码能正确执行下去，要在run方法里面对vector加锁

#### 3.相对线程安全

​	相对的线程安全就是我们通常意义上所讲的线程安全**，它需要保证对这个对象单独的操作是线程安全的，我们在调用的时候不需要做额外的保障措施，**但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性。例如Vector、HashTable、Collections的synchronizedCollection（）方法包装的集合等。

#### 4.线程兼容

​	线程兼容是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用，我们平常说一个类不是线程安全的，绝大多数时候指的是这一种情况。Java API中大部分的类都是属于线程兼容的，如与前面的Vector和HashTable相对应的集合类ArrayList和HashMap等。

#### 5.线程对立

​	**线程对立是指无论调用端是否采取了同步措施，都无法在多线程环境中并发使用的代码。**由于Java语言天生就具备多线程特性，线程对立这种排斥多线程的代码是很少出现的，而且通常都是有害的，应当尽量避免。

​	一个线程对立的例子是Thread类的suspend（）和resume（）方法，如果有两个线程同时持有一个线程对象，一个尝试去中断线程，另一个尝试去恢复线程，如果并发进行的话，无论调用时是否进行了同步，目标线程都是存在死锁风险的，如果suspend（）中断的线程就是即将要执行resume（）的那个线程，那就肯定要产生死锁了。也正是由于这个原因，suspend（）和resume（）方法已经被JDK声明废弃（@Deprecated）了。常见的线程对立的操作还有System.setIn（）、Sytem.setOut（）和System.runFinalizersOnExit（）等。

## 2 线程安全的实现方法

### 1.互斥同步

​	互斥同步（Mutual Exclusion＆Synchronization）是常见的一种并发正确性保障手段。**同步是指在多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一个（或者是一些，使用信号量的时候）线程使用。**而互斥是实现同步的一种手段，临界区（CriticalSection）、互斥量（Mutex）和信号量（Semaphore）都是主要的互斥实现方式。因此，在这4个字里面，互斥是因，同步是果；互斥是方法，同步是目的。

​	在Java中，最基本的互斥同步手段就是synchronized关键字，==synchronized关键字经过编译之后，会在同步块的前后分别形成monitorenter和monitorexit这两个字节码指令，这两个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象。==**如果Java程序中的synchronized明确指定了对象参数，那就是这个对象的reference；如果没有明确指定，那就根据synchronized修饰的是实例方法还是类方法，去取对应的对象实例或Class对象来作为锁对象。**根据虚拟机规范的要求，**在执行monitorenter指令时，首先要尝试获取对象的锁。如果这个对象没被锁定，或者当前线程已经拥有了那个对象的锁，把锁的计数器加1，相应的，在执行monitorexit指令时会将锁计数器减1，当计数器为0时，锁就被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到对象锁被另外一个线程释放为止。**	

​	在虚拟机规范对monitorenter和monitorexit的行为描述中，有两点是需要特别注意的。首先，==synchronized同步块对同一条线程来说是可重入的，不会出现自己把自己锁死的问题。==其次，同步块在已进入的线程执行完之前，会阻塞后面其他线程的进入。J**ava的线程是映射到操作系统的原生线程之上的，如果要阻塞或唤醒一个线程，都需要操作系统来帮忙完成，这就需要从用户态转换到核心态中，因此状态转换需要耗费很多的处理器时间。**对于代码简单的同步块（如被synchronized修饰的getter（）或setter（）方法），状态转换消耗的时间有可能比用户代码执行的时间还要长。所以synchronized是Java语言中一个重量级（Heavyweight）的操作，而虚拟机本身也会进行一些优化，譬如在通知操作系统阻塞线程之前加入一段自旋等待过程，避免频繁地切入到核心态之中。

​	除了synchronized之外，我们还可以使用java.util.concurrent（下文称J.U.C）包中的重入锁（ReentrantLock）来实现同步，在基本用法上，ReentrantLock与synchronized很相似，他们都具备一样的线程重入特性，只是代码写法上有点区别，**一个表现为API层面的互斥锁（lock（）和unlock（）方法配合try/finally语句块来完成），另一个表现为原生语法层面的互斥锁**。不过，相比synchronized,==ReentrantLock增加了一些高级功能，主要有以下3项：等待可中断、可实现公平锁，以及锁可以绑定多个条件。==

- 等待可中断是指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情，可中断特性对处理执行时间非常长的同步块很有帮助。
- 公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而非公平锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。synchronized中的锁是非公平的，ReentrantLock默认情况下也是非公平的，**但可以通过带布尔值的构造函数要求使用公平锁。**
- 锁绑定多个条件是指一个ReentrantLock对象可以同时绑定多个Condition对象，而在synchronized中，锁对象的wait（）和notify（）或notifyAll（）方法可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外地添加一个锁，而ReentrantLock则无须这样做，只需要多次调用newCondition（）方法即可。

### 2.非阻塞同步

​	**互斥同步最主要的问题就是进行线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步（Blocking Synchronization）。**从处理问题的方式上说，**互斥同步属于一种悲观的并发策略**，总是认为只要不去做正确的同步措施（例如加锁），那就肯定会出现问题，无论共享数据是否真的会出现竞争，它都要进行==加锁==（这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁）、==用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒==等操作。随着硬件指令集的发展，我们有了另外一个选择：基于冲突检测的乐观并发策略，通俗地说，就是先进行操作，如果没有其他线程争用共享数据，那操作就成功了；如果共享数据有争用，产生了冲突，那就再采取其他的补偿措施（最常见的补偿措施就是不断地重试，直到成功为止），这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步操作称为非阻塞同步（Non-Blocking Synchronization）。

​	使用乐观并发策略需要“硬件指令集的发展”才能，因为我们需要**操作和冲突检测**这两个步骤具备原子性，这两个需要靠硬件来完成这件事情，**硬件保证一个从语义上看起来需要多次操作的行为只通过一条处理器指令就能完成**，这类指令常用的有：

- 测试并设置（Test-and-Set）。
- 获取并增加（Fetch-and-Increment）。
- 交换（Swap）。
- 比较并交换（Compare-and-Swap，下文称CAS）。
- 加载链接/条件存储（Load-Linked/Store-Conditional，下文称LL/SC）。

​	**CAS指令需要有3个操作数，分别是内存位置（在Java中可以简单理解为变量的内存地址，用V表示）、旧的预期值（用A表示）和新值（用B表示）。**CAS指令执行时，当且仅当V符合旧预期值A时，处理器用新值B更新V的值，否则它就不执行更新，但是无论是否更新了V的值，都会返回V的旧值，上述的处理过程是一个原子操作。

​	在JDK 1.5之后，Java程序中才可以使用CAS操作，该操作由sun.misc.Unsafe类里面的compareAndSwapInt（）和compareAndSwapLong（）等几个方法包装提供，**虚拟机在内部对这些方法做了特殊处理，即时编译出来的结果就是一条平台相关的处理器CAS指令，没有方法调用的过程，或者可以认为是无条件内联进去了**。

​	==由于Unsafe类不是提供给用户程序调用的类（Unsafe.getUnsafe（）的代码中限制了只有启动类加载器（Bootstrap ClassLoader）加载的Class才能访问它）==，因此，**如果不采用反射手段，我们只能通过其他的Java API来间接使用它，如J.U.C包里面的整数原子类，其中的compareAndSet（）和getAndIncrement（）等方法都使用了Unsafe类的CAS操作。**

如下面这个例子：

```java
/***Atomic变量自增运算测试**@author zzm*/
public class AtomicTest{
	public static AtomicInteger race=new AtomicInteger（0）；
	public static void increase（）{
		race.incrementAndGet（）；
	}
	private static final int THREADS_COUNT=20；
	public static void main（String[]args）throws Exception{
		Thread[]threads=new Thread[THREADS_COUNT]；
		for（int i=0；i＜THREADS_COUNT；i++）{
			threads[i]=new Thread（new Runnable（）{
			@Override
			public void run（）{
			for（int i=0；i＜10000；i++）{
			increase（）；
				}
			}
		}）；
		threads[i].start（）；
		}
		while（Thread.activeCount（）＞1）
			Thread.yield（）；
			System.out.println（race）；
			}
		}
```

运行结果：20000

​	使用AtomicInteger代替int后，程序输出了正确的结果，一切都要归功于incrementAndGet（）方法的原子性。接下来看看他的源码：

```java
//基于jdk1.7
	/**
     * Atomically increments by one the current value.
     *
     * @return the updated value
     */
    public final int incrementAndGet() {
        for (;;) {
            int current = get();
            int next = current + 1;
            if (compareAndSet(current, next))
                return next;
        }
    }
//基于jdk1.8
/**
     * Atomically increments by one the current value.
     *
     * @return the updated value
     */
    public final int incrementAndGet() {
        return unsafe.getAndAddInt(this, valueOffset, 1) + 1;
    }
//调用unsafe里面的方法
public final int getAndAddInt(Object var1, long var2, int var4) {
        int var5;
        do {
            var5 = this.getIntVolatile(var1, var2);
        } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));

        return var5;
    }
```

​	incrementAndGet（）方法在一个无限循环中，不断尝试将一个比当前值大1的新值赋给自己。如果失败了，那说明在执行“获取-设置”操作的时候值已经有了修改，于是再次循环进行下一次操作，直到设置成功为止。

​	其实CAS存在这样的一个逻辑漏洞：如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然为A值，不能说它的值没有被其他线程改变过，因为在这段期间它的值可能被改成了B，后来又被改回为A，那CAS操作就会误认为它从来没有被改变过。这个漏洞称为**CAS操作的“ABA”问题**。J.U.C包为了解决这个问题，提供了一个带有标记的原子引用类“**AtomicStampedReference**”，它可以通过==控制变量值的版==本来保证CAS的正确性。不过目前来说这个类比较“鸡肋”，大部分情况下ABA问题不会影响程序并发的正确性，如果需要解决ABA问题，改用传统的互斥同步可能会比原子类更高效。

### 3.无同步方案

​	要保证线程安全，并不是一定就要进行同步，两者没有因果关系。**同步只是保证共享数据争用时的正确性的手段，如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性，因此会有一些代码天生就是线程安全的，**

​	可重入代码（Reentrant Code）：这种代码也叫做纯代码（Pure Code），**可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误。**相对线程安全来说，可重入性是更基本的特性，它可以保证线程安全，即==所有的可重入的代码都是线程安全的，但是并非所有的线程安全的代码都是可重入的。==**可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。**

​	线程本地存储（Thread Local Storage）：如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行？如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。符合这种特点的应用并不少见，大部分使用消费队列的架构模式（如“生产者-消费者”模式）都会将产品的消费过程尽量在一个线程中消费完，其中最重要的一个应用实例就是经典Web交互模型中的“一个请求对应一个服务器线程”（Thread-per-Request）的处理方式，这种处理方式的广泛应用使得很多Web服务端应用都可以使用线程本地存储来解决线程安全问题。

​	**Java语言中，如果一个变量要被多线程访问，可以使用volatile关键字声明它为“易变的”；如果一个变量要被某个线程独享，Java可以通过java.lang.ThreadLocal类来实现线程本地存储的功能。**==每一个线程的Thread对象中都有一个ThreadLocalMap对象，这个对象存储了一组以ThreadLocal.threadLocalHashCode为键，以本地线程变量为值的K-V值对，ThreadLocal对象就是当前线程的ThreadLocalMap的访问入口，每一个ThreadLocal对象都包含了一个独一无二的threadLocalHashCode值，使用这个值就可以在线程K-V值对中找回对应的本地线程变量。==

## 3 锁优化

### 3.1 自旋锁与自适应自旋

​	**互斥同步对性能最大的影响是阻塞的实现，挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给系统的并发性能带来了很大的压力。**同时，虚拟机的开发团队也注意到在许多应用上，**共享数据的锁定状态只会持续很短的一段时间**，为了这段时间去挂起和恢复线程并不值得。如果物理机器有一个以上的处理器，能让两个或以上的线程同时并行执行，我们就可以让后面请求锁的那个线程“稍等一下”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需让线程执行一个忙循环（自旋），这项技术就是所谓的自旋锁。

​	自旋锁在JDK 1.6中默认开启。自旋等待不能代替阻塞，且先不说对处理器数量的要求，自**旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，因此，如果锁被占用的时间很短，自旋等待的效果就会非常好，反之，如果锁被占用的时间很长，那么自旋的线程只会白白消耗处理器资源，而不会做任何有用的工作，反而会带来性能上的浪费。**因此，==自旋等待的时间必须要有一定的限度，如果自旋超过了限定的次数仍然没有成功获得锁，就应当使用传统的方式去挂起线程了。自旋次数的默认值是10次，用户可以使用参数-XX：PreBlockSpin来更改。==

​	在JDK 1.6中引入了自适应的自旋锁。**自适应意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。**如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长的时间，比如100个循环。另外，如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。有了自适应自旋，随着程序运行和性能监控信息的不断完善，虚拟机对程序锁的状况预测就会越来越准确，虚拟机就会变得越来越“聪明”了。

### 3.2 锁消除

​	**锁消除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。**==锁消除的主要判定依据来源于逃逸分析的数据支持==，**如果判断在一段代码中，堆上的所有数据都不会逃逸出去从而被其他线程访问到，那就可以把它们当做栈上数据对待，认为它们是线程私有的，同步加锁自然就无须进行。**也许读者会有疑问，变量是否逃逸，对于虚拟机来说需要使用数据流分析来确定，但是程序员自己应该是很清楚的，怎么会在明知道不存在数据争用的情况下要求同步呢？答案是有许多同步措施并不是程序员自己加入的，同步的代码在Java程序中的普遍程度也许超过了大部分读者的想象。我们来看看代码清单13-6中的例子，这段非常简单的代码仅仅是输出3个字符串相加的结果，无论是源码字面上还是程序语义上都没有同步。

```java
public String concatString（String s1，String s2，String s3）{
	return s1+s2+s3；
}
```

​	由于String是一个不可变的类，对字符串的连接操作总是通过生成新的String对象来进行的，**因此Javac编译器会对String连接做自动优化。**在JDK 1.5之前，会转化为StringBuffer对象的连续append（）操作，在JDK 1.5及以后的版本中，会转化为StringBuilder对象的连续append（）操作，变成如下的代码：

```java
public String concatString（String s1，String s2，String s3）{
	StringBuffer sb=new StringBuffer（）；
	sb.append（s1）；
	sb.append（s2）；
	sb.append（s3）；
	return sb.toString（）；
	}
```

​	**每个StringBuffer.append（）方法中都有一个同步块(synchronized)**，锁就是sb对象。虚拟机观察变量sb，很快就会发现它的动态作用域被限制在concatString（）方法内部。也就是说，sb的所有引用永远不会“逃逸”到concatString（）方法之外，其他线程无法访问到它，因此，虽然这里有锁，但是可以被安全地消除掉，在即时编译之后，这段代码就会忽略掉所有的同步而直接执行了。

### 3.3 锁粗化

​	原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小——只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待锁的线程也能尽快拿到锁。大部分情况下，上面的原则都是正确的，但是如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。如果虚拟机探测到有这样一串零碎的操作都对同一个对象加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部。

### 3.4 轻量级锁

​	轻量级锁是JDK 1.6之中加入的新型锁机制，**“轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的，因此传统的锁机制就称为“重量级”锁。**首先需要强调一点的是，轻量级锁并不是用来代替重量级锁的，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。要理解轻量级锁，以及后面会讲到的偏向锁的原理和运作过程，必须从HotSpot虚拟机的对象（对象头部分）的内存布局开始介绍。==HotSpot虚拟机的对象头（Object Header）分为两部分信息，第一部分用于存储对象自身的运行时数据==，如哈希码（HashCode）、GC分代年龄（Generational GC Age）等，这部分数据的长度在32位和64位的虚拟机中分别为32bit和64bit，官方称它为“**Mark Word**”，它是实现轻量级锁和偏向锁的关键。==另外一部分用于存储指向方法区对象类型数据的指针==，如果是数组对象的话，还会有一个==额外的部分用于存储数组长度==。

​	**对象头信息是与对象自身定义的数据无关的==额外存储成本==**，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。例如，在32位的HotSpot虚拟机中对象未被锁定的状态下，**Mark Word的32bit空间中的25bit用于存储对象哈希码（HashCode），4bit用于存储对象分代年龄，2bit用于存储锁标志位，1bit固定为0，在其他状态（轻量级锁定、重量级锁定、GC标记、可偏向）下对象的存储内容见表**13-1。

![image-20190116142258413](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190116142258413-7619778.png)

​	简单地介绍了对象的内存布局后，我们来看看轻量级锁的执行过程。**在代码进入同步块的时候，如果此同步对象没有被锁定（锁标志位为“01”状态），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的MarkWord的拷贝（**官方把这份拷贝加了一个Displaced前缀，即Displaced Mark Word），这时候线程堆栈与对象头的状态如图13-3所示。

​	然后，==虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针==。如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位（Mark Word的最后2bit）将转变为“00”，即表示此对象处于轻量级锁定状态，这时候线程堆栈与对象头的状态如图13-4所示。![image-20190116142420387](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190116142420387-7619860.png)

​	如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果只说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程抢占了。**如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁，锁标志的状态值变为“10”，**Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。

​	上面描述的是轻量级锁的加锁过程，它的解锁过程也是通过CAS操作来进行的，**如果对象的Mark Word仍然指向着线程的锁记录，那就用CAS操作把对象当前的Mark Word和线程中复制的Displaced Mark Word替换回来，**如果替换成功，整个同步过程就完成了。**如果替换失败，说明有其他线程尝试过获取该锁，那就要在释放锁的同时，唤醒被挂起的线程。**

​	轻量级锁能提升程序同步性能的依据是“==对于绝大部分的锁，在整个同步周期内都是不存在竞争的==”，这是一个经验数据。如果没有竞争，轻量级锁使用CAS操作避免了使用互斥量的开销，但如果存在锁竞争，除了互斥量的开销外，还额外发生了CAS操作，因此在有竞争的情况下，轻量级锁会比传统的重量级锁更慢。

### 3.5 偏向锁

​	偏向锁也是JDK 1.6中引入的一项锁优化，它的目的是消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。如**果说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量，那偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS操作都不做了。**

​	**偏向锁的“偏”，就是偏心的“偏”、偏袒的“偏”，它的意思是这个锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。**

​	**启用偏向锁之后，当锁对象第一次被线程获取的时候，虚拟机将会把对象头中的标志位设为“01”，即偏向模式。同时使用CAS操作把获取到这个锁的线程的ID记录在对象的Mark Word之中，如果CAS操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作（例如Locking、Unlocking及对Mark Word的Update等）。**

​	==当有另外一个线程去尝试获取这个锁时，偏向模式就宣告结束。==根据锁对象目前是否处于被锁定的状态，撤销偏向（Revoke Bias）后恢复到未锁定（标志位为“01”）或轻量级锁定（标志位为“00”）的状态，后续的同步操作就如上面介绍的轻量级锁那样执行。偏向锁、轻量级锁的状态转化及对象Mark Word的关系如图13-5所示。

![image-20190116151213297](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20190116151213297-7622733.png)

​	偏向锁可以提高带有同步但无竞争的程序性能。它同样是一个带有效益权衡（TradeOff）性质的优化，也就是说，它并不一定总是对程序运行有利，如果程序中大多数的锁总是被多个不同的线程访问，那偏向模式就是多余的。在具体问题具体分析的前提下，有时候使用参数**-XX：-UseBiasedLocking来禁止偏向锁优化反而可以提升性能。**



参照：《深入理解Java虚拟机》