# 一、Redis 的线程模型

## 1.原理

​	Redis 内部使用文件事件处理器 `file event handler`，这个**文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型**。它采用 **IO 多路复用机制同时监听多个 socket**，根据 socket 上的事件来选择对应的事件处理器进行处理。

文件事件处理器的结构包含 4 个部分：

- 多个 socket
- IO 多路复用程序
- 文件事件分派器
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

> 多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。

来看客户端与 Redis 的一次通信过程：

![Redis-single-thread-model](/Users/jack/Desktop/md/images/01-0249933.png)

- 客户端 socket01 向 Redis 的 server socket 请求建立连接，此时 server socket 会产生一个 `AE_READABLE` 事件，**IO 多路复用程序监听到 server socket 产生的事件后，将该事件压入队列中。文件事件分派器从队列中获取该事件，交给`连接应答处理器`。**==连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 `AE_READABLE` 事件与命令请求处理器关联。==
- 假设此时客户端发送了一个 `set key value` 请求，此时 Redis 中的 **socket01** 会产生 `AE_READABLE` 事件，IO 多路复用程序将事件压入队列，此时事件分派器从队列中获取到该事件，由于前面 socket01 的 `AE_READABLE` 事件已经与命令请求处理器关联，因此**事件分派器将事件交给命令请求处理器来处理**。命令请求处理器读取 socket01 的 `key value` 并在自己内存中完成 `key value` 的设置。操作完成后，它会将 socket01 的 `AE_WRITABLE` 事件与令回复处理器关联。
- 如果此时客户端准备好接收返回结果了，那么 Redis 中的 socket01 会产生一个 `AE_WRITABLE` 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，**由命令回复处理器对 socket01 输入本次操作的一个结果，比如 `ok`，之后解除 socket01 的 `AE_WRITABLE` 事件与命令回复处理器的关联。**

## 2.效率高的原因

1、纯内存操作。

> Redis 为了达到最快的读写速度，将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以 Redis 具有快速和数据持久化的特征。
>
> 如果不将数据放在内存中，磁盘 I/O 速度为严重影响 Redis 的性能。

**2、核心是基于非阻塞的 IO 多路复用机制。**

3、单线程反而避免了多线程的频繁上下文切换问题。

> Redis 利用队列技术，将并发访问变为串行访问，消除了传统数据库串行控制的开销

4、Redis 全程使用 hash 结构，读取速度快，还有一些特殊的数据结构，对数据存储进行了优化，如压缩表，对短数据进行压缩存储，再如，跳表，使用有序的数据结构加快读取的速度。

​	可以在同一个服务器部署多个 Redis 的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果想使用多个 CPU ，可以考虑一下分区。

# 二、Redis持久化

Redis 提供了两种方式，实现数据的持久化到硬盘。

- 1、【全量】RDB 持久化，是指在指定的时间间隔内将内存中的**数据集快照**写入磁盘。实际操作过程是，fork 一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。
- 2、【增量】AOF持久化，以日志的形式记录服务器所处理的每一个**写、删除操作**，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。

## **RDB 优缺点**

① 优点

- **灵活设置备份频率和周期。**你可能打算每个小时归档一次最近 24 小时的数据，同时还要每天归档一次最近 30 天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。

- **非常适合冷备份，对于灾难恢复而言，RDB 是非常不错的选择。**因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。推荐，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说 Amazon 的 S3 云服务上去，在国内可以是阿里云的 OSS 分布式存储上。

- **性能最大化。**对于 Redis 的服务进程而言，在开始持久化时，它唯一需要做的只是 fork 出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行 IO 操作了。也就是说，RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis 保持高性能。

  > 一个进程，包括代码、数据和分配给进程的资源。fork（）函数通过系统调用创建一个与原来进程几乎完全相同的进程，也就是两个进程可以做完全相同的事，但如果初始参数或者传入的变量不同，两个进程也可以做不同的事。
  > 一个进程调用fork（）函数后，系统先给新的进程分配资源，例如存储数据和代码的空间。然后把原来的进程的所有值都复制到新的新进程中，只有少数值与原来的进程的值不同。相当于克隆了一个自己。

- **恢复更快。相比于 AOF 机制，RDB 的恢复速度更更快，更适合恢复数据，特别是在数据集非常大的情况。**

② 缺点

- 如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么 RDB 将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。

  > 所以，RDB 实际场景下，需要和 AOF 一起使用。

- 由于 RDB 是通过 fork 子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是 1 秒钟。

  > 所以，RDB 建议在业务低估，例如在半夜执行。

## **AOF 优缺点**

① 优点

- 该机制可以带来更高的数据安全性，即数据持久性。**Redis 中提供了 3 种同步策略，即每秒同步、每修改(执行一个命令)同步和不同步。**
  - 事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。
  - 每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。
  - 不同步，则每次发生的数据变化不会同时记录到磁盘。
- 由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。
  - 因为以 append-only 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高。
  - 另外，如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在 Redis 下一次启动之前，我们可以通过 Redis-check-aof 工具来帮助我们解决数据一致性的问题。
- ==如果日志过大，Redis可以自动启用 **rewrite** 机制。==即使出现后台重写操作，也不会影响客户端的读写。因为在 rewrite log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。再创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。
- AOF 包含一个格式清晰、易于理解的日志文件用于记录所有的**修改操作**。事实上，我们也可以通过该文件完成数据的重建。

② 缺点

- **对于相同数量的数据集而言，AOF 文件通常要大于 RDB 文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。**
- 根据同步策略的不同，AOF 在运行效率上往往会慢于 RDB 。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和 RDB 一样高效。
- 以前 AOF 发生过 bug ，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志/merge/回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug 。不过 AOF 就是为了避免 rewrite 过程导致的 bug ，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。

**如何选择**

- 不要仅仅使用 RDB，因为那样会导致你丢失很多数据

- 也不要仅仅使用 AOF，因为那样有两个问题，第一，你通过 AOF 做冷备，没有 RDB 做冷备，来的恢复速度更快; 第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug 。

- Redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。

  - 如果同时使用 RDB 和 AOF 两种持久化机制，那么在 Redis 重启的时候，会使用 **AOF** 来重新构建数据，因为 AOF 中的**数据更加完整**。

    > 一般来说， 如果想达到足以媲美 PostgreSQL 的数据安全性， 你应该同时使用两种持久化功能。如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用 RDB 持久化。
    >
    > 有很多用户都只使用 AOF 持久化，但并不推荐这种方式：因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外，使用 RDB 还可以避免之前提到的 AOF 程序的 bug。

在 Redis4.0 版本开始，允许你使用 RDB-AOF 混合持久化方式，详细可见 [《Redis4.0 之 RDB-AOF 混合持久化》](https://yq.aliyun.com/articles/193034) 。也因此，RDB 和 AOF 同时使用，是希望达到安全的持久化的推荐方式。

> - bgsave 做镜像全量持久化，AOF 做增量持久化。因为 bgsave 会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要 AOF 来配合使用。在 Redis 实例重启时，会使用 bgsave 持久化文件重新构建内存，再使用 AOF 重放近期的操作指令来实现完整恢复重启之前的状态。
> - 对方追问那如果突然机器掉电会怎样？取决于 AOF 日志 sync 属性的配置，如果不要求性能，在每条写指令时都 sync 一下磁盘，就不会丢失数据。但是在高性能的要求下每次都 sync 是不现实的，一般都使用定时 sync ，比如 1 秒 1 次，这个时候最多就会丢失 1 秒的数据。
> - 对方追问 bgsave 的原理是什么？你给出两个词汇就可以了，fork 和 cow 。fork 是指 Redis 通过创建子进程来进行 bgsave 操作。cow 指的是 copy on write ，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。这里 bgsave 操作后，会产生 RDB 快照文件。

为什么不建议在主 Redis 节点开启 RDB 功能呢？因为会带来一定时间的阻塞，特别是数据量大的时候。

> - 子进程/fork相关的阻塞：在bgsave的时候，Redis主进程会fork一个子进程，利用操作系统的写时复制技术，这个子进程在拷贝父进程的时候理论上是很快的，因为并不需要全拷贝，比如主进程虽然占了10g内存，但子进程拷贝他可能只要200毫秒，也就阻塞了200毫秒(此耗时基本跟主进程占用的内存是成正比的)，这个具体的时间可以通过统计项info stats 里的last_fork_usec查看。
> - cpu/单线程相关的阻塞：**Redis主进程是单线程跑在单核cpu上的，如果显示绑定了CPU，则子进程会与主进程共享一个CPU，而子进程进行持久化的时候是非常占CPU（强势90%），因此这种情况也可能导致提供服务的主进程发生阻塞（因此如果需要持久化功能，不建议绑定CPU）；**
> - 内存相关的阻塞：**虽然利用写时复制技术可以大大降低进程拷贝的内存消耗，但这也导致了父进程在处理写请求时需要维护修改的内存页，因此这部分内存过大的话（修改页数多或每页占空间大）也会导致父进程的写操作阻塞。**（而不巧的是，Linux中TransparentHugePage会将复制内存页面单位有4K变成2M，这对于Redis来说是比较不友好的，也是建议优化的，具体可度之）
> - 磁盘相关的阻塞：极端情况下，假设整个机器的内存已经所剩无几，触发了内存交换（SWAP），则整个Redis的效率将会非常低下（显然这不仅仅针对save/bgsave），因此，关注系统的io情况，也是定位阻塞问题的一种方法。

# 三、Redis的“过期”和“淘汰”策略

## 1.“过期”策略

Redis 的过期策略，就是指当 Redis 中缓存的 key 过期了，Redis 如何处理。

Redis 提供了 3 种数据过期策略：

- 被动删除：当读/写一个已经过期的 key 时，会触发惰性删除策略，直接删除掉这个过期 key 。

  > 只有key被操作时(如GET)，REDIS才会被动检查该key是否过期，如果过期则删除之并且返回NIL。
  >
  > 1、这种删除策略对CPU是友好的，删除操作只有在不得不的情况下才会进行，不会其他的expire key上浪费无谓的CPU时间。
  >
  > 2、但是这种策略对内存不友好，一个key已经过期，但是在它被操作之前不会被删除，仍然占据内存空间。如果有大量的过期键存在但是又很少被访问到，那会造成大量的内存空间浪费。expireIfNeeded(redisDb *db, robj *key)函数位于src/db.c。
  >
  > 但仅是这样是不够的，**因为可能存在一些key永远不会被再次访问到，这些设置了过期时间的key也是需要在过期后被删除的，我们甚至可以将这种情况看作是一种内存泄露----无用的垃圾数据占用了大量的内存，而服务器却不会自己去释放它们，这对于运行状态非常依赖于内存的Redis服务器来说，肯定不是一个好消息**

- 主动删除：由于惰性删除策略无法保证冷数据被及时删掉，所以 Redis 会定期主动淘汰一批已过期的 key 。

  > 先说一下时间事件，对于持续运行的服务器来说， 服务器需要定期对自身的资源和状态进行必要的检查和整理， 从而让服务器维持在一个健康稳定的状态， 这类操作被统称为常规操作（cron job）。
  >
  > 在 Redis 中， 常规操作由 `redis.c/serverCron` 实现， 它主要执行以下操作：
  >
  > - 更新服务器的各类统计信息，比如时间、内存占用、数据库占用情况等。
  > - 清理数据库中的过期键值对。
  > - 对不合理的数据库进行大小调整。
  > - 关闭和清理连接失效的客户端。
  > - 尝试进行 AOF 或 RDB 持久化操作。
  > - 如果服务器是主节点的话，对附属节点进行定期同步。
  > - 如果处于集群模式的话，对集群进行定期同步和连接测试。
  >
  > Redis 将 `serverCron` 作为时间事件来运行， 从而确保它每隔一段时间就会自动运行一次， 又因为 `serverCron` 需要在 Redis 服务器运行期间一直定期运行， 所以它是一个循环时间事件： `serverCron` 会一直定期执行，直到服务器关闭为止。
  >
  > 在 Redis 2.6 版本中， 程序规定 `serverCron` 每秒运行 `10` 次， 平均每 `100` 毫秒运行一次。 从 Redis 2.8 开始， 用户可以通过修改 `hz`选项来调整 `serverCron` 的每秒执行次数， 具体信息请参考 `redis.conf` 文件中关于 `hz` 选项的说明。

- maxmemory：当前已用内存超过 maxmemory 限定时，触发主动清理策略，即 [「数据“淘汰”策略」](http://svip.iocoder.cn/Redis/Interview/#) 。

  > 当前已用内存超过maxmemory限定时，触发**主动清理**策略：
  >
  > - volatile-lru：只对设置了过期时间的key进行LRU（默认值）
  > - allkeys-lru ： 删除lru算法的key
  > - volatile-random：随机删除即将过期key
  > - allkeys-random：随机删除
  > - volatile-ttl ： 删除即将过期的
  > - noeviction ： 永不过期，返回错误当mem_used内存已经超过maxmemory的设定，对于所有的读写请求，都会触发redis.c/freeMemoryIfNeeded(void)函数以清理超出的内存。注意这个清理过程是阻塞的，直到清理出足够的内存空间。所以如果在达到maxmemory并且调用方还在不断写入的情况下，可能会反复触发主动清理策略，导致请求会有一定的延迟。 
  >
  > 当mem_used内存已经超过maxmemory的设定，对于所有的读写请求，都会触发redis.c/freeMemoryIfNeeded(void)函数以清理超出的内存。注意这个清理过程是阻塞的，直到清理出足够的内存空间。所以如果在达到maxmemory并且调用方还在不断写入的情况下，可能会反复触发主动清理策略，导致请求会有一定的延迟。
  >
  > 清理时会根据用户配置的maxmemory-policy来做适当的清理（一般是LRU或TTL），这里的LRU或TTL策略并不是针对redis的所有key，而是以配置文件中的maxmemory-samples个key作为样本池进行抽样清理。
  >
  > maxmemory-samples在redis-3.0.0中的默认配置为5，如果增加，会提高LRU或TTL的精准度，redis作者测试的结果是当这个配置为10时已经非常接近全量LRU的精准度了，并且增加maxmemory-samples会导致在主动清理时消耗更多的CPU时间，建议：
  >
  > - 尽量不要触发maxmemory，最好在mem_used内存占用达到maxmemory的一定比例后，需要考虑调大hz以加快淘汰，或者进行集群扩容。
  > - 如果能够控制住内存，则可以不用修改maxmemory-samples配置；如果Redis本身就作为LRU cache服务（这种服务一般长时间处于maxmemory状态，由Redis自动做LRU淘汰），可以适当调大maxmemory-samples。

在 Redis 中，同时使用了上述 3 种策略，即它们**非互斥**的。

参照： [《关于 Redis 数据过期策略》](https://www.cnblogs.com/chenpingzhao/p/5022467.html)

## 2.“淘汰”策略

Redis 内存数据集大小上升到一定大小的时候，就会进行数据淘汰策略。

### 数据淘汰策略：

> **volatile-lru策略和volatile-random策略适合我们将一个Redis实例既应用于缓存和又应用于持久化存储的时候，然而我们也可以通过使用两个Redis实例来达到相同的效果，值得一提的是将key设置过期时间实际上会消耗更多的内存，因此我们建议使用allkeys-lru策略从而更有效率的使用内存。**

1. volatile-lru

   > 从已设置过期时间的数据集中挑选**最近最少使用的数据淘汰**。redis并不是保证取得所有数据集中最近最少使用的键值对，而只是随机挑选的几个键值对中的， 当内存达到限制的时候无法写入非过期时间的数据集。
   >
   > 

2. volatile-ttl

   > 从已设置过期时间的数据集中挑选**将要过期的数据淘汰**。redis 并不是保证取得所有数据集中最近将要过期的键值对，而只是随机挑选的几个键值对中的， 当内存达到限制的时候无法写入非过期时间的数据集。
   >
   > 这种策略使得我们可以向Redis提示哪些key更适合被eviction。

3. volatile-random

   > 从已设置过期时间的数据集中**任意选择数据淘汰**。当内存达到限制的时候无法写入非过期时间的数据集。

4. allkeys-lru

   > **从数据集中挑选最近最少使用的数据淘汰。**当内存达到限制的时候，对所有数据集挑选最近最少使用的数据淘汰，可写入新的数据集。
   >
   > ==如果我们的应用对缓存的访问符合幂律分布，也就是存在相对热点数据，或者我们不太清楚我们应用的缓存访问分布状况，我们可以选择allkeys-lru策略。==可保证热点数据不要被淘汰

5. allkeys-random

   > **从数据集中任意选择数据淘汰**，当内存达到限制的时候，对所有数据集挑选随机淘汰，可写入新的数据集。
   >
   > **如果我们的应用对于缓存key的访问概率相等，则可以使用这个策略。**

6. no-enviction

   > 当内存达到限制的时候，不淘汰任何数据，不可写入任何数据集，所有引起申请内存的命令会报错。

### 配置：

通过配置redis.conf中的maxmemory这个值来开启内存淘汰功能：# maxmemory ；值得注意的是，maxmemory为0的时候表示我们对Redis的内存使用没有限制。根据应用场景，选择淘汰策略：# maxmemory-policy noeviction。

### 内存淘汰的过程：

> 首先，客户端发起了需要申请更多内存的命令（如set）。
>
> 然后，Redis检查内存使用情况，如果已使用的内存大于maxmemory则开始根据用户配置的不同淘汰策略来淘汰内存（key），从而换取一定的内存。
>
> 最后，如果上面都没问题，则这个命令执行成功。

### 动态改配置命令

此外，redis支持动态改配置，无需重启。

设置最大内存

```
config set maxmemory 100000
```

设置淘汰策略

```
config set maxmemory-policy noeviction
```

参照： [《Redis实战（二） 内存淘汰机制》](http://blog.720ui.com/2016/redis_action_02_maxmemory_policy/)













参照：[芋道源码](http://svip.iocoder.cn/Redis/Interview/)