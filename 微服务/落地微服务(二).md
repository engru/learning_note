# 八、负载均衡算法

​	引入负载均衡算法主要有两个原因：**一个是要考虑调用的均匀性，也就是要让每个节点都接收到调用，发挥所有节点的作用；另一个是要考虑调用的性能，也就是哪个节点响应最快，优先调用哪个节点。**不同的负载均衡算法在这两个方面的考虑不同，下面来看看常见的负载均衡算法及其应用场景，常见的负载均衡算法：

## 随机算法

​	随机算法，顾名思义就是从可用的服务节点中，随机挑选一个节点来访问。在实现时，随机算法通常是通过生成一个随机数来实现，比如服务有10个节点，那么就每一次生成一个1～10之间的随机数，假设生成的是2，那么就访问编号为2的节点。**采用随机算法，在节点数量足够多，并且访问量比较大的情况下，各个节点被访问的概率是基本相同的。**

## 轮询算法

​	轮询算法，顾名思义就是**按照固定的顺序，把可用的服务节点，挨个访问一次。**在实现时，轮询算法通常是把所有可用节点放到一个数组里，然后按照数组编号，挨个访问。比如服务有10个节点，放到数组里就是一个大小为10的数组，这样的话就可以从序号为0的节点开始访问，访问后序号自动加1，下一次就会访问序号为1的节点，以此类推。轮询算法能够保证所有节点被访问到的概率是相同的。

## 加权轮询算法

​	轮询算法能够保证所有节点被访问的概率相同，而**加权轮询算法是在此基础上，给每个节点赋予一个权重，从而使每个节点被访问到的概率不同，权重大的节点被访问的概率就高，权重小的节点被访问的概率就小。**

​	在实现时，加权轮询算法是生成一个节点序列，该序列里有n个节点，n是所有节点的权重之和。在这个序列中，每个节点出现的次数，就是它的权重值。比如有三个节点：a、b、c，权重分别是3、2、1，那么生成的序列就是{a、a、b、c、b、a}，这样的话按照这个序列访问，前6次请求就会分别访问节点a三次，节点b两次，节点c一次。从第7个请求开始，又重新按照这个序列的顺序来访问节点。在应用加权轮询算法的时候，要尽可能保证生产的序列的均匀，如果生成的不均匀会造成节点访问失衡，比如刚才的例子，如果生成的序列是{a、a、a、b、b、c}，就会导致前3次访问的节点都是a。

## 最少活跃连接算法

​	最少活跃连接算法，顾名思义就是**每一次访问都选择连接数最少的节点。**因为不同节点处理请求的速度不同，使得同一个服务消费者同每一个节点的连接数都不相同。连接数大的节点，可以认为是处理请求慢，而连接数小的节点，可以认为是处理请求快。所以在挑选节点时，可以以连接数为依据，选择连接数最少的节点访问。在实现时，需要记录跟每一个节点的连接数，这样在选择节点时，才能比较出连接数最小的节点。

## 一致性hash算法

​	一致性hash算法，是通过某个hash函数，把同一个来源的请求都映射到同一个节点上。**一致性hash算法最大的特点就是同一个来源的请求，只会映射到同一个节点上，可以说是具有记忆功能。**只有当这个节点不可用时，请求才会被分配到相邻的可用节点上。

​	负载均衡算法的使用场景上面这五种负载均衡算法，它们的各自应用场景如下：

- 随机算法：实现比较简单，在请求量远超可用服务节点数量的情况下，各个服务节点被访问的概率基本相同，主要应用在各个服务节点的性能差异不大的情况下。
- 轮询算法：跟随机算法类似，各个服务节点被访问的概率也基本相同，也主要应用在各个服务节点性能差异不大的情况下。
- 加权轮询算法：在轮询算法基础上的改进，可以通过给每个节点设置不同的权重来控制访问的概率，因此主要被用在服务节点性能差异比较大的情况。比如经常会出现一种情况，因为采购时间的不同，新的服务节点的性能往往要高于旧的节点，这个时候可以给新的节点设置更高的权重，让它承担更多的请求，充分发挥新节点的性能优势。
- 最少活跃连接算法：与加权轮询算法预先定义好每个节点的访问权重不同，采用最少活跃连接算法，**客户端同服务端节点的连接数是在时刻变化的，理论上连接数越少代表此时服务端节点越空闲，选择最空闲的节点发起请求，能获取更快的响应速度。**尤其在服务端节点性能差异较大，而又不好做到预先定义权重时，采用最少活跃连接算法是比较好的选择。
- 一致性hash算法：因为它能够保证同一个客户端的请求始终访问同一个服务节点，所以适合服务端节点处理不同客户端请求差异较大的场景。比如服务端缓存里保存着客户端的请求结果，如果同一客户端一直访问一个
  服务节点，那么就可以一直从缓存中获取数据。

考虑这样一种场景：

- 服务节点数量众多，且性能差异比较大；
- 服务节点列表经常发生变化，增加节点或者减少节点时有发生；
- 客户端和服务节点之间的网络情况比较复杂，有些在一个数据中心，有些不在一个数据中心需要跨网访问，而且网络经常延迟或者抖动。

显然无论是随机算法还是轮询算法，第一个情况就不满足，加权轮询算法需要预先配置服务节点的权重，在节点列表经常变化的情况下不好维护，所以也不适合。而最少活跃连接算法是从客户端自身维度去判断的，在实际应用时，并不能直接反映出服务节点的请求量大小，尤其是在网络情况比较复杂的情况下，并不能做到动态的把请求发送给最合适的服务节点。至于一致性hash算法，显然不适合这种场景。针对上面这种场景，有一种算法更加适合，这种算法就是自适应最优选择算法。

## ==自适应最优选择算法==

​	这种算法的主要思路是==在客户端本地维护一份同每一个服务节点的性能统计快照，并且每隔一段时间去更新这个快照。在发起请求时，根据“二八原则”，把服务节点分成两部分，找出20%的那部分响应最慢的节点，然后降低权重。==这样的话，客户端就能够实时的根据自身访问每个节点性能的快慢，动态调整访问最慢的那些节点的权重，来减少访问量，从而可以优化长尾请求。由此可见，自适应最优选择算法是对加权轮询算法的改良，可以看作是一种动态加权轮询算法。

​	它的实现关键之处就在于两点：第一点是每隔一段时间获取客户端同每个服务节点之间调用的平均性能统计；第二点是按照这个性能统计对服务节点进行排序，对排在性能倒数20%的那部分节点赋予一个较低的权重，其余的节点赋予正常的权重。

​	在具体实现时，针对第一点，需要在内存中开辟一块空间记录客户端同每一个服务节点之间调用的平均性能，并每隔一段固定时间去更新。这个更新的时间间隔不能太短，太短的话很容易受瞬时的性能抖动影响，导致统计变化太快，没有参考性；同时也不能太长，太长的话时效性就会大打折扣，效果不佳。一般来说，1分钟的更新时间间隔是个比较合适的值。针对第二点，关键点是权重值的设定，即使服务节点之间的性能差异较大，也不适合把权重设置得差异太大，这样会导致性能较好的节点与性能较差的节点之间调用量相差太大，这样也不是一种合理的状态。在实际设定时，可以设置20%性能较差的节点权重为3，其余节点权重为5。

# 九、服务路由

​	上面的客户端负载均衡算法解决了服务消费者如何从众多可用的服务节点中选取一个最合适的节点发起调用的问题。但在业务中经常还会遇到这样的场景，比如服务A部署在北京、上海、广州三个数据中心，所有的服务节点按照所在的数据中心被分成了三组，那么服务A的消费者在发起调用时，就需要通过服务路由的解决。服务路由就是服务消费者在发起服务调用时，必须根据特定的规则来选择服务节点，从而满足某些特定的需求。

## 服务路由的应用场景

​	服务路由主要有以下几种应用场景：

- **分组调用**。一般来讲，为了保证服务的高可用性，实现异地多活的需求，一个服务往往不止部署在一个数据中心，而且出于节省成本等考虑，有些业务可能不仅在私有机房部署，还会采用公有云部署，甚至采用多家公有云部署。服务节点也会按照不同的数据中心分成不同的分组，这时对于服务消费者来说，选择哪一个分组调用，就必须有相应的路由规则。
- **灰度发布**。在服务上线发布的过程中，一般需要先在一小部分规模的服务节点上先发布服务，然后验证功能是否正常。如果正常的话就继续扩大发布范围；如果不正常的话，就需要排查问题，解决问题后继续发布。这个过程就叫作灰度发布，也叫金丝雀部署。
- **流量切换**。在业务线上运行过程中，经常会遇到一些不可抗力因素导致业务故障，比如某个机房的光缆被挖断，或者发生着火等事故导致整个机房的服务都不可用。这个时候就需要按照某个指令，能够把原来调用这个机房服务的流量切换到其他正常的机房。
- **读写分离**。对于大多数互联网业务来说都是读多写少，所以在进行服务部署的时候，可以把读写分开部署，所有写接口可以部署在一起，而读接口部署在另外的节点上。

服务路由主要有两种规则：一种是条件路由，一种是脚本路由。

### 1.条件路由

​	条件路由是基于条件表达式的路由规则，以下面的条件路由为例，我来给你详细讲解下它的用法。

```
condition://0.0.0.0/dubbo.test.interfaces.TestService?category=routers&dynamic=true&priority=2&enabled=true&rule=" + URL.encode(" host = 10.20.153.10=> host = 10.20.153.11")
```

这里面“condition://”代表了这是一段用条件表达式编写的路由规则，具体的规则是

`host = 10.20.153.10 => host = 10.20.153.11`

==分隔符"=>"前面是服务消费者的匹配条件，后面是服务提供者的过滤条件。==**当服务消费者节点满足匹配条件时，就对该服务消费者执行后面的过滤规则。**那么上面这段表达式表达的意义就是IP为“10.20.153.10”的服务消费者都调用IP为“10.20.153.11”的服务提供者节点。

==如果服务消费者的匹配条件为空，就表示对所有的服务消费者应用==，就像下面的表达式一样。

`=> host ！= 10.20.153.11`

==如果服务提供者的过滤条件为空，就表示禁止服务消费者访问==，就像下面的表达式一样。

`host = 10.20.153.10=>`

下面举一些Dubbo框架中的条件路由，看看条件路由的具体应用场景。

- 排除某个服务节点

`=> host != 172.22.3.91`   这里分隔符前面为空，则表示服务消费者的匹配条件为空。

一旦这条路由规则被应用到线上，所有的服务消费者都不会访问IP为172.22.3.91的服务节点，**这种路由规则一般应用在线上流量排除预发布机以及摘除某个故障节点的场景。**

- 白名单和黑名单功能

`host != 10.20.153.10,10.20.153.11 =>`    这里分隔符后面为空，则表示服务提供者的匹配条件为空。

这条路由规则意思是除了IP为10.20.153.10和10.20.153.11的服务消费者可以发起服务调用以外，其他服务消费者都不可以，主要用于白名单访问逻辑，比如某个后台服务只允许特定的几台机器才可以访问，这样的话可以机器控制访问权限。

`host = 10.20.153.10,10.20.153.11 =>`

同理，这条路由规则意思是除了IP为10.20.153.10和10.20.153.11的服务消费者不能发起服务调用以外，其他服务消费者都可以，也就是实现了黑名单功能，
比如线上经常会遇到某些调用方不管是出于有意还是无意的不合理调用，影响了服务的稳定性，这时候可以通过黑名单功能暂时予以封杀。

- 机房隔离    `host = 172.22.3.* => host = 172.22.3.*`

这条路由规则意思是IP网段为172.22.3.\*的服务消费者，才可以访问同网段的服务节点**，这种规则一般应用于服务部署在多个IDC，理论上同一个IDC内的调用性能要比跨IDC调用性能要好，应用这个规则是为了实现同IDC就近访问。**

- 读写分离  

`method = find*,list*,get*,is* => host =172.22.3.94,172.22.3.95
method != find*,list*,get*,is* => host = 172.22.3.97,172.22.3.98`

这条路由规则意思是find\*、get\*、is*等读方法调用IP为172.22.3.94和172.22.3.95的节点，除此以外的写方法调用IP为172.22.3.97和172.22.3.98的节点。对于大部分互联网业务来说，往往读请求要远远大于写请求，而写请求的重要性往往要远远高于读请求，所以需要把读写请求进行分离，以避免读请求异常影响到写请求，这时候就可以应用这种规则。

### 2.脚本路由

​	脚本路由是基于脚本语言的路由规则，常用的脚本语言比如JavaScript、Groovy、JRuby等。以下面的脚本路由规则为例。

```
"script://0.0.0.0/com.foo.BarService?category=routers&dynamic=false&rule=" + URL.encode("（function route(invokers) { ... } (invokers)）")
```

这里面“script://”就代表了这是一段脚本语言编写的路由规则，具体规则定义在脚本语言的route方法实现里，比如下面这段用JavaScript编写的route()方法表达的意思是，只有IP为10.20.153.10的服务消费者可以发起服务调用。

```JS
function route(invokers){
  var result = new java.util.ArrayList(invokers.size());
  for(i =0; i < invokers.size(); i ++){
    if("10.20.153.10".equals(invokers.get(i).getUrl().getHost())){ 
       result.add(invokers.get(i));
    } 
  }
  return result; 
 } (invokers)）;
```

## 服务路由的获取方式

​	服务路由的获取方式主要有三种：

- **本地配置**：顾名思义就是路由规则存储在服务消费者本地上。服务消费者发起调用时，从本地固定位置读取路由规则，然后按照路由规则选取一个服务节点发起调用。

- **配置中心管理**：这种方式下，所有的服务消费者都从配置中心获取路由规则，由配置中心来统一管理。
- **动态下发：**这种方式下，一般是运维人员或者开发人员，通过服务治理平台修改路由规则，服务治理平台调用配置中心接口，把修改后的路由规则持久化到配置中心。因为服务消费者订阅了路由规则的变更，于是就会从配置中心获取最新的路由规则，按照最新的路由规则来执行。

​	一般来讲，服务路由最好是存储在配置中心中，由配置中心来统一管理。这样的话，所有的服务消费者就不需要在本地管理服务路由，因为大部分的服务消费者并不关心服务路由的问题，或者说也不需要去了解其中的细节。通过配置中心，统一给各个服务消费者下发统一的服务路由，节省了沟通和管理成本。但也不排除某些服务消费者有特定的需求，需要定制自己的路由规则，这个时候就适合通过本地配置来定制。

​	而**动态下发可以理解为一种高级功能，它能够动态地修改路由规则，在某些业务场景下十分有用**。比如某个数据中心存在问题，需要把调用这个数据中心的服务消费者都切换到其他数据中心，这时就可以通过动态下发的方式，向配置中心下发一条路由规则，将所有调用这个数据中心的请求都迁移到别的地方。当然，==这三种方式也可以一起使用，这个时候服务消费者的判断优先级是本地配置&gt;动态下发&gt;配置中心管理。==

## 总结

​	服务路由的作用，简单来讲就是为了实现某些调用的特殊需求，比如分组调用、灰度发布、流量切换、读写分离等。在业务规模比较小的时候，可能所有的服务节点都部署在一起，也就不需要服务路由。但随着业务规模的扩大、服务节点增多，尤其是涉及多数据中心部署的情况，把服务节点按照数据中心进行分组，或者按照业务的核心程度进行分组，对提高服务的可用性是十分有用的。以微博业务为例，有的服务不仅进行了核心服务和非核心服务分组，还针对私有云和公有云所处的不同数据中心也进行了分组，这样的话就可以将服务之间的调用尽量都限定在同一个数据中心内部，最大限度避免跨数据中心的网络延迟、抖动等影响。

​	而服务路由具体是在本地配置，还是在配置中心统一管理，也是视具体业务需求而定的。如果没有定制化的需求，建议把路由规则都放到配置中心中统一存储管理。而动态下发路由规则对于服务治理十分有帮助，当数据中心出现故障的时候，可以实现动态切换流量，还可以摘除一些有故障的服务节点。



































































































































































































































































































































































参照：[从0开始学微服务](https://time.geekbang.org/column/article/14222)