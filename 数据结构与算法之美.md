# 数据结构与算法之美

# 一、时间复杂度

### 1.概述

​	**代码执行时间 T(n)=O(f(n))**

其中 T(n) 表示代码执行的时间，n 表示数据规模的大小，f(n) 表示每行代码执行的次数总和。

其中 大 O 时间复杂度实际上并不具体表示代码执行的时间，而是表示代码执行时间随数据规模增长的变化趋势，，所以，也叫渐近时间复杂度，简称时间复杂度。

1. **只关注执行循环最多的一段代码，总复杂度等于量级最大那段代码的复杂度**

2. 嵌套代码的复杂度等于嵌套内外代码复杂度的乘积。

​	时间复杂度表示的是一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间多大，我们都可以忽略掉。因为它本身对增长趋势并没有影响。

### 2.几种常见的复杂度：

常量阶 O(1)、对数阶 O(logn)、线性阶 O(n)、线性对数阶 O(nlogn)、平方阶 O(n^2)、立方阶 O(n^3)、K 次方阶 O(n^k)、指数阶 O(2^n)、阶乘阶 O(n!)

对这些复杂度量级，可以分为多项式量级和非多项式量级。其中非多项式量级只有指数阶和阶乘阶，这两个量级的算法问题又叫做 NP 难问题。

#### 1.O(1)

​	只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度我们都记作 O(1)。或者说，一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)。

#### 2. O(logn)、O(nlogn)

​	当已处理的数据规模呈等比数列级别时，代码的复杂度就是对数级别 O(logn)。而 O(nlogn) 和 O(logn) 联系其实很紧密，将 O(logn) 级别的代码执行 O(n) 级别的次数，就是 O(nlogn) 了。归并排序、快速排序的时间
复杂度都是 O(nlogn)。

#### 3.对 O(m+n)、 O(m*n) 的理解

​	之所以有两个参数，是因为代码的复杂度由两个数据的规模决定。因为无法实现知道 m 和 n 两个数据规模谁更大，所以只能都写出来。

![image-20190215170051760](/Users/jack/Desktop/md/images/image-20190215170051760.png)

### 3.复杂情况下的时间复杂度

​	为了表示代码在不同情况下的不同时间复杂度，我们需要引入三个概念**:最好情况时间复杂度、**
**最坏情况时间复杂度和平均情况时间复杂度。**

1.最坏情况时间复杂度:代码在最理想情况下执行的时间复杂度。
2.最好情况时间复杂度:代码在最坏情况下执行的时间复杂度。
3.平均时间复杂度:用代码在所有情况下执行的次数的加权平均值表示。
4.均摊时间复杂度:在代码执行的所有复杂度情况中绝大部分是低级别的复杂度，个别情况是
高级别复杂度且发生具有时序关系时，可以将个别高级别复杂度均摊到低级别复杂度上。基
本上均摊结果就等于低级别复杂度。

# 二、数组

## 概念

1. 数据是一种**线性表**数据结构，所谓线性表，就是数据排成像一条线一样的数据结构。
2. 这里数组用一组**连续的内存空间**，来存储**相同类型的数据**。

![image-20190215234850951](/Users/jack/Desktop/md/images/image-20190215234850951.png)

![image-20190215234905780](/Users/jack/Desktop/md/images/image-20190215234905780.png)

数组支持**随机访问**。这个特点也是因为它占有连续的内存空间。

我们拿一个长度为 10 的 int 类型的数组 int[] a = new int[10] 来举例。在我画的这个图中，计算机给数组 a[10]，分配了一块连续内存空间 1000~1039，其中，内存块的首地址为base_address = 1000。

![image-20190215235021439](/Users/jack/Desktop/md/images/image-20190215235021439.png)

​	计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址:

```
a[i]_address = base_address + i * data_type_size
```

​	其中 data_type_size 表示数组中每个元素的大小。我们举的这个例子里，数组中存储的是 int类型数据，所以 data_type_size 就为 4 个字节。

**二维数组内存寻址:**
对于 m * n 的数组，a [ i ][ j ] (i < m,j < n)的地址为:

```
address = base_address + ( i * n + j) * type_size
```

当面试时，我们不应该说数组的查找时间复杂度是 O(1)，排序好的数组，用二分查找，时间复杂度是 O(logn)。正确的表述是，根据下标随机访问的时间复杂度是 O(1)。

但是也是因为这个原因，数组的插入和删除非常“低效”。为了保持连续性，需要做大量的数据迁移工作。

## 插入

如果数据是有序的，每次插入到数组的第 k 个位置，需要把 k~n 这部分数据都往后移以为，若是在每个位置插入元素的概率是一样的，那么平均时间复杂度是 (1+2+...n)/n=O(n)。

若数据是无序的，数组只是一个存储数据的集合，这种情况下，要把数据插入到第 k 个位置，可以尝试把第 k 个元素移到数组的最后面，把新元素插入到第 k 个位置，这样在特定场景下，插入一个元素到第 k 个位置时间复杂度可以降为 O(1)。

## 删除

和插入一样，最好情况下时间复杂度是 O(1)，如果删除开头的数据，则是最坏情况时间复杂度 O(n)，平均情况下时间复杂度是 O(n)。

如果我们将多次删除操作集中在一起删除，就可以提高删除的效率，这也是 jvm 的标记清楚垃圾回收算法。

## 容器

ArrayList 相比数组，最大的优势就是将许多细节封装起来了，比如前面提到的数组插入、删除时需要搬移其他数据等。另外的优势就是自动扩容了。

但不是所有情况都需要用到 ArrayList。比如

1. ArrayList 无法存储基本类型。自动封箱拆箱需要性能消耗。
2. 有些操作较为简单，无需用到 ArrayList。
3. 定义多维数组时，若是用 ArrayList 看起来不直观。

![image-20190215235559326](/Users/jack/Desktop/md/images/image-20190215235559326.png)



















