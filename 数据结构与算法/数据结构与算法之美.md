# 数据结构与算法之美

# 一、时间复杂度

### 1.概述

​	**代码执行时间 T(n)=O(f(n))**

其中 T(n) 表示代码执行的时间，n 表示数据规模的大小，f(n) 表示每行代码执行的次数总和。

其中 大 O 时间复杂度实际上并不具体表示代码执行的时间，而是表示代码执行时间随数据规模增长的变化趋势，，所以，也叫渐近时间复杂度，简称时间复杂度。

1. **只关注执行循环最多的一段代码，总复杂度等于量级最大那段代码的复杂度**

2. 嵌套代码的复杂度等于嵌套内外代码复杂度的乘积。

​	时间复杂度表示的是一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间多大，我们都可以忽略掉。因为它本身对增长趋势并没有影响。

### 2.几种常见的复杂度：

常量阶 O(1)、对数阶 O(logn)、线性阶 O(n)、线性对数阶 O(nlogn)、平方阶 O(n^2)、立方阶 O(n^3)、K 次方阶 O(n^k)、指数阶 O(2^n)、阶乘阶 O(n!)

对这些复杂度量级，可以分为多项式量级和非多项式量级。其中非多项式量级只有指数阶和阶乘阶，这两个量级的算法问题又叫做 NP 难问题。

#### 1.O(1)

​	只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度我们都记作 O(1)。或者说，一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)。

#### 2. O(logn)、O(nlogn)

​	当已处理的数据规模呈等比数列级别时，代码的复杂度就是对数级别 O(logn)。而 O(nlogn) 和 O(logn) 联系其实很紧密，将 O(logn) 级别的代码执行 O(n) 级别的次数，就是 O(nlogn) 了。归并排序、快速排序的时间
复杂度都是 O(nlogn)。

#### 3.对 O(m+n)、 O(m*n) 的理解

​	之所以有两个参数，是因为代码的复杂度由两个数据的规模决定。因为无法实现知道 m 和 n 两个数据规模谁更大，所以只能都写出来。

![image-20190215170051760](/Users/jack/Desktop/md/images/image-20190215170051760.png)

### 3.复杂情况下的时间复杂度

​	为了表示代码在不同情况下的不同时间复杂度，我们需要引入三个概念**:最好情况时间复杂度、**
**最坏情况时间复杂度和平均情况时间复杂度。**

1.最坏情况时间复杂度:代码在最理想情况下执行的时间复杂度。
2.最好情况时间复杂度:代码在最坏情况下执行的时间复杂度。
3.平均时间复杂度:用代码在所有情况下执行的次数的加权平均值表示。
4.均摊时间复杂度:在代码执行的所有复杂度情况中绝大部分是低级别的复杂度，个别情况是
高级别复杂度且发生具有时序关系时，可以将个别高级别复杂度均摊到低级别复杂度上。基
本上均摊结果就等于低级别复杂度。

# 二、数组

## 概念

1. 数据是一种**线性表**数据结构，所谓线性表，就是数据排成像一条线一样的数据结构。
2. 这里数组用一组**连续的内存空间**，来存储**相同类型的数据**。

![image-20190215234850951](/Users/jack/Desktop/md/images/image-20190215234850951.png)

![image-20190215234905780](/Users/jack/Desktop/md/images/image-20190215234905780.png)

数组支持**随机访问**。这个特点也是因为它占有连续的内存空间。

我们拿一个长度为 10 的 int 类型的数组 int[] a = new int[10] 来举例。在我画的这个图中，计算机给数组 a[10]，分配了一块连续内存空间 1000~1039，其中，内存块的首地址为base_address = 1000。

![image-20190215235021439](/Users/jack/Desktop/md/images/image-20190215235021439.png)

​	计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址:

```
a[i]_address = base_address + i * data_type_size
```

​	其中 data_type_size 表示数组中每个元素的大小。我们举的这个例子里，数组中存储的是 int类型数据，所以 data_type_size 就为 4 个字节。

**二维数组内存寻址:**
对于 m * n 的数组，a [ i ][ j ] (i < m,j < n)的地址为:

```
address = base_address + ( i * n + j) * type_size
```

当面试时，我们不应该说数组的查找时间复杂度是 O(1)，排序好的数组，用二分查找，时间复杂度是 O(logn)。正确的表述是，根据下标随机访问的时间复杂度是 O(1)。

但是也是因为这个原因，数组的插入和删除非常“低效”。为了保持连续性，需要做大量的数据迁移工作。

## 插入

如果数据是有序的，每次插入到数组的第 k 个位置，需要把 k~n 这部分数据都往后移以为，若是在每个位置插入元素的概率是一样的，那么平均时间复杂度是 (1+2+...n)/n=O(n)。

若数据是无序的，数组只是一个存储数据的集合，这种情况下，要把数据插入到第 k 个位置，可以尝试把第 k 个元素移到数组的最后面，把新元素插入到第 k 个位置，这样在特定场景下，插入一个元素到第 k 个位置时间复杂度可以降为 O(1)。

## 删除

和插入一样，最好情况下时间复杂度是 O(1)，如果删除开头的数据，则是最坏情况时间复杂度 O(n)，平均情况下时间复杂度是 O(n)。

如果我们将多次删除操作集中在一起删除，就可以提高删除的效率，这也是 jvm 的标记清楚垃圾回收算法。

## 容器

ArrayList 相比数组，最大的优势就是将许多细节封装起来了，比如前面提到的数组插入、删除时需要搬移其他数据等。另外的优势就是自动扩容了。

但不是所有情况都需要用到 ArrayList。比如

1. ArrayList 无法存储基本类型。自动封箱拆箱需要性能消耗。
2. 有些操作较为简单，无需用到 ArrayList。
3. 定义多维数组时，若是用 ArrayList 看起来不直观。

![image-20190215235559326](/Users/jack/Desktop/md/images/image-20190215235559326.png)

# 三、链表

​	缓存是一种提高数据读取性能的技术，在硬件设计、软件开发中都有着非常广泛的应用，比如常 见的 **CPU 缓存、数据库缓存、浏览器缓存等等。** 

​	缓存的大小有限，当缓存被用满时，哪些数据应该被清理出去，哪些数据应该被保留?这就需要 缓存淘汰策略来决定。**==常见的策略有三种:先进先出策略 FIFO(First In，First Out)、最少使 用策略 LFU(Least Frequently Used)、最近最少使用策略 LRU(Least Recently Used)。==** 

## 数组和链表的内存比较

![image-20190217105102418](/Users/jack/Desktop/md/images/image-20190217105102418.png)

​	从图中我们看到，数组需要一块连续的内存空间来存储，对内 存的要求比较高。如果我们申请一个 100MB 大小的数组，当内存中没有连续的、足够大的存储 空间时，即便内存的剩余总可用空间大于 100MB，仍然会申请失败。 

而链表恰恰相反，它并不需要一块连续的内存空间，它通过“指针”将一组零散的内存块串联起 来使用，所以如果我们申请的是 100MB 大小的链表，根本不会有问题。 

​	链表是通过“指针”将一组零散的内存块串联起来的数据结构，相比数组就是使用一组连续的内存块来存储数据的数据结构。

常见的链表有：

-  **单链表**： 每个数据块只有一个指针指向下一节点的数据。其中有两个特殊的节点，一个是头节点，数据块是空的，只有一个指针指向下一节点；另一个节点是尾节点，他的特点是，指针是指向空地址 NULL，表示这是链表的最后一个节点。![image-20190217105145325](/Users/jack/Desktop/md/images/image-20190217105145325.png)
-  **循环链表**： 循环链表是，每个数据块都有一个指针指向下一节点，尾节点的指针指向头节点，另有一个单独的头指针指向开头。![image-20190217105345482](/Users/jack/Desktop/md/images/image-20190217105345482.png)
-  **双链表**： 双链表是在单链表的基础上，**在每个数据块节点上增加一个指针指向上一节点。**每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针prev 指向前面的结点。![image-20190217105948132](/Users/jack/Desktop/md/images/image-20190217105948132.png)
-  **双向循环链表**：双向循环链表是每个数据块都有两个指针，一个向前指向，一个向后指向，另有一个单独的指针指向一个数据块节点，这个指针是头指针。![image-20190217110211704](/Users/jack/Desktop/md/images/image-20190217110211704.png)

## 性能

​	==链表的随机访问性能是 O(n),数组是 O(1)。链表的插入、删除操作的性能是 O(1)，数组是 O(n)。==

​	这里的链表，插入，删除，是指知道要插入的点，删除的点的指针，比如单链表插入时知道插入点上一节点的指针时，通过改变指针的指向就可以完成 O(1) 时间内的数据插入，删除同理。

​	若是单链表删除时，不知道指向要删除的具体节点的指针，那么就要在删除前先进行随机访问，那么性能就是 O(n)。

​	对于有序双向链表，查询效率会比单链表高一点，因为我们可以记录上次查找的位置 P，每次查询时，根据要查询的值与 P 的大小关系，决定往前还是往后查找，所以平均只需要查找一般的数据。

**在 Java 语言中，LinkedHashMap 这个容器，他的实现原理就用到了双向链表这个数据结构。**

## 数组 VS 链表

​	数组简单易用，在实现上是使用连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中不是连续存储，对 CPU 缓存不友好，没办法有效预读。

​	**数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致“内存不足(out of memory)”。**如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然地支持动态扩容，我觉得这也是它与数组最大的区别。	

​	但数组的特点也是它的不足，他的内存空间是固定的，如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致内存不足(out of memory)，例如如果现在系统由 100M 不连续的内存空间，声明 100M 数组就会失败，另外到数组扩容时，复制原数组的内容到新数组也很费时。这就是数组和链表最大的区别。

另外如果我们的代码对内存使用非常苛刻，那应该使用数组，比如安卓之类的，因为链表需要维护额外的空间去存储指针。而且对链表进行频繁的插入、删除操作，还对导致频繁的内存申请和释放，容易造成内存碎片。如果是 Java 语言，就可能导致频繁的 gc。![image-20190217110226500](/Users/jack/Desktop/md/images/image-20190217110226500.png)

## 如何书写正确的链表代码

### 技巧一：理解指针或引用的含义

​	**将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，或者反过来说，指针中存储了这个变量的内存地址，指向这个变量，通过指针就能找到这个变量。**

如：在编写链表代码的时候，我们经常会有这样的代码:p->next=q。这行代码是说，p 结点中的 next 指针存储了 q 结点的内存地址。 

还有一个更复杂的，也是我们写链表代码经常会用到的:p->next=p->next->next。这行代码 表示，p 结点的 next 指针存储了 p 结点的下下一个结点的内存地址。 

### 技巧二：警惕指针丢失和内存泄漏

​	写链表时，一定要注意指针指向哪了，对于脑子转不过来的情况，可以在纸上画图辅助思考。
 对于自己管理内存的语言，如 C 语言，如果没有手动释放节点对应的内存空间，就会产生内存泄漏。不过，对于 Java 这种虚拟机自动管理内存的编程语言来说，就不需要考虑那么多了。

### 技巧三：利用哨兵简化实现难度

​	有时代码写不出来，也是因为代码的小逻辑多而乱，如果能够实现分析代码，简化逻辑，那么写起代码来就会更容易轻松了。
 比如，**当在单链表插入一个新节点时，需要两个小逻辑：1. *链表是空的的情况* 2. *链表不是空的情况* 写起来的代码就会像这样复杂。而如果我们有一个哨兵节点，那么就只需“无脑”往这个节点后面插入新节点而不用进行一次判空特殊处理了。**

其实就是加了一个虚拟头节点，这个结点是不存储数据的。因为哨兵结点一直存在，所以插入第一个结点和插入其他结点，删除最后一个结点和删除其他结点，都可以统一为相同的代码实现逻辑了。

**拓展**：在很多算法中都有用到哨兵做简化，比如插入排序、归并排序、动态规划等。
 下面这个例子就是用了哨兵提升性能：

```
inf find(char* a, int n, int key) {
  if (a[n-1] == key) {
    return n-1;
  }
  char tmp = a[n-1];
  a[n-1] = key;
  int i = 0;
  while (a[i] != key) {
    ++i;
  }
  a[n-1] = tmp;
  if (i == n-1) return -1;
  return i;
}
```

### 技巧四：重点留意边界条件处理

软件开发中，我们往往是从“通常情况入手，设计代码”，这种情况下，如果不注意特殊情况（边界情况）时，就容易产生 BUG。一定要在写完代码后，检查边界条件是否考虑齐全。
 常用来检查链表代码是否正确的边界条件有这样几个：

- 如果链表为空时，代码能否正常工作？
- 如果链表只包含一个节点时，代码能否正常工作？
- 如果链表只包含两个节点时，代码能否正常工作？
- 代码逻辑在处理头节点和尾节点时，能否正常工作？

### 技巧五：画图举例，辅助思考

感觉这也是软件设计图的细节版。写出来，整理一下，就明白了。![image-20190217120701097](/Users/jack/Desktop/md/images/image-20190217120701097.png)

### 技巧六：多写多练，没有捷径

#### 5个常见的链表操作：

- 单链表反转
- 链表中环的检测
- 两个有序的链表合并
- 删除链表倒数第 n 个结点
- 求链表的中间结点

对应LeetCode题目：206，141，21，19，876

# 四、栈

栈，是一种“操作受限”的线性表，只允许在一端插入和删除数据。后进后出是它的最大特点。

## 栈的实现

​	栈可以用数组和链表实现。数组实现的栈叫顺序栈，链表实现的栈叫链式栈。特别要注意的是，顺序栈的动态扩容，应用平摊分析法，最终分析出插入的时间复杂度仍是 O(1)。![image-20190217131404224](/Users/jack/Desktop/md/images/image-20190217131404224.png)

## 栈的应用

1. **函数调用栈**
    操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构，用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈。**当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。![image-20190217150150940](/Users/jack/Desktop/md/images/image-20190217150150940.png)**![image-20190217150202171](/Users/jack/Desktop/md/images/image-20190217150202171.png)
2. **栈在函数表达式中的应用**
    编译器就是通过两个栈来实现表达式的运算的，一个保存操作数的栈，另一个保存运算符的栈。我们从左向右遍历表达式，**当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶符号比较。如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，**从操作数的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。
   1. 例子：3+5*8-6![image-20190217151249246](/Users/jack/Desktop/md/images/image-20190217151249246.png)
3. **栈在括号匹配中的应用**
    **我们用栈来保存未匹配的左括号**，从左到右依次扫描字符串。**当扫描到左括号时，则讲其压入栈中；当扫描到右括号时，从栈顶取出一个左括号。如果能够匹配，则继续扫描剩下的字符串。如果扫描的过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。**
    当所有括号都扫描完成之后，如果栈为空，则说明字符串是合法格式；否则，说明有未匹配的左括号，为非法格式。

## 课后思考

1. **我们在讲栈的应用时，讲到用函数调用栈来保存临时变量，为什么函数调用要用“栈”来保存临时变量呢？其他数据结构不行吗？**

特定数据结构是特定应用场景的抽象。

函数调用的顺序，符合先进者后出，后进者先出的特点，还有函数中调用函数，也是这样，先开始执行的函数，必须等到内部调用的其他函数执行完毕，该函数才能执行结束。

比如函数中的局部变量的生命周期的长短，是先定义的局部变量生命周期长，后定义的局部变量生命周期短。

1. **我们都知道，JVM 内存管理中有个“堆栈”的概念。栈内存用来存储局部变量和方法调用，堆内存用来存储 Java 中的对象。那么 JVM 里面的“栈”跟我们这里说的“栈”是不是一回事呢？如果不是，那它又为什么叫做“栈”呢？**

内存中的堆栈和数据结构堆栈不是一个概念。内存中的堆栈是真实存在的物理区，数据结构中的堆栈是抽象的数据结构。
 内存空间在逻辑上分为三部分：代码区、静态数据区和动态数据区。动态数据区又分为栈区和堆区。
 代码区：存储方法体的二进制代码。高级调度（作业调度）、中级调度（内存调度）、低级调度（进程调度）控制代码区执行代码的切换。
 静态数据区：存储全局变量、静态变量、常量，常量包括 final 修饰的常量和 String 常量。系统自动分配和回收。
 栈区：存储方法的形参、局部变量、返回值。由系统自动分配和回收。
 堆区：new 操作符创建的一个对象的引用地址存储在栈区，指向该对象存储在堆区中的真实数据。

# 五、队列

队列也是一种“操作受限”的线性表，只支持两种基本操作：入队和出队。

队列的应用非常广泛，特别是一些具有某些额外特性的队列，比如循环队列、阻塞队列、并发队列。它们在很多偏底层的系统、框架、中间件的开发中，起着关键性的作用。比如高性能队列 Disruptor、Linux 环形缓存，都用到了循环并发队列；Java concurrent 并发包利用 ArrayBlockingQueue 来实现公平锁等。

​	**队列有两个指针，一个head指针和一个tail指针，分别指向队头和队尾，当插入元素的时候，即入队的时候，tail指针向右移动，head指针不变；当出队的时候，head指针向右移动，tail指针不变**

![image-20190224230644568](/Users/jack/Desktop/md/images/image-20190224230644568.png)

​	当我们调用两次出队操作之后，队列中 head 指针指向下标为 2 的位置，tail 指针仍然指向下标为 4 的位置。![image-20190224230659386](/Users/jack/Desktop/md/images/image-20190224230659386.png)

​	当队列的 tail 指针移动到数组的最右边后，如果有新的数据入队，我们可以将 head 到 tail 之间的数据，整体搬移到数组中 0 到 tail-head 的位置。![image-20190224230807069](/Users/jack/Desktop/md/images/image-20190224230807069.png)

## 顺序队列和链式队列

用数组实现的队列叫顺序队列，用链表实现的队列叫链式队列。

==顺序队列在没有空闲空间时，需要触发一次数据的搬移操作==。

## 循环队列

![image-20190224231004881](/Users/jack/Desktop/md/images/image-20190224231004881.png)

​	图中这个队列的大小为 8，当前 head=4，tail=7。当有一个新的元素 a 入队时，我们放入下标为 7 的位置。但这个时候，我们并不把 tail 更新为 8，而是将其在环中后移一位，到下标为 0 的位置。当再有一个元素 b 入队时，我们将 b 放入下标为 0 的位置，然后tail 加 1 更新为 1。所以，在 a，b 依次入队之后，循环队列中的元素就变成了下面的样子:![image-20190224231118349](/Users/jack/Desktop/md/images/image-20190224231118349.png)

​	将顺序队列首尾连接起来就是循环队列。要注意的点就是，队列判满的条件是==(tail + 1) % n = head==。如果 head == tail 表示队列为空。

队满的情况：

![image-20190224231304271](/Users/jack/Desktop/md/images/image-20190224231304271.png)

​	当队列满时，图中的 tail 指向的位置实际上是没有存储数据的。所以，循环队列会浪费一个数组的存储空间。

## 阻塞队列和并发队列

​	**阻塞队列**就是在队列的基础上增加了阻塞操作。简单来说，就是在队列为空的时候，出队操作会被阻塞，当队列满的时候，入队操作会被阻塞。其实，上面的定义，就是一个“**生产者-消费者**”模型。

​	这种模型，可以有效协调生产和消费的速度。当“生产者”生产速度过快，“消费者”来不及消费时，存储队列很快就会满了。这个时候，生产者就阻塞等待，直到“消费者”消费了数据，“生产者”才会被唤醒继续生产。

​	而且不仅如此，基于阻塞队列，我们还可以协调“生产者”和“消费者”的个数，来提高数据处理的效率，比如，我们可以多配置几个“消费者”，来对应一个“生产者”。

**并发队列**：线程安全的队列我们叫做并发队列。最简单的实现方式就是直接在 enqueue()、dequeue() 方法上加锁，但是锁粒度大并发度会比较低。实际上，基于 CAS 原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因。

## 队列在线程池中的应用

当线程池没有空闲线程时，新的任务请求线程资源时，线程池该如何处理？各种处理策略又是如何实现的呢？

我们一般有两种处理策略一种是非阻塞队列，一种是阻塞队列。

阻塞队列又有两种实现方式，一种是无限排队等待，另一种就是基于数组的有限队列，这里，给数组队列设置一个合理的队列大小，是非常有讲究的。队列太大导致等待的请求太多，队列太小会导致无法充分利用系统资源、发挥最大性能。

## 基于链表和数组的队列的区别

基于链表的实现方式，可以实现一个支持**无限排队的无界队列(unbounded queue)**，但是可 能会导致过多的请求排队等待，请求处理的响应时间过长。所以，针对响应时间比较敏感的系 统，基于链表实现的无限排队的线程池是不合适的。 

而基于数组实现的有界队列(bounded queue)，队列的大小有限，所以线程池中排队的请求 超过队列大小时，接下来的请求就会被拒绝，这种方式对响应时间敏感的系统来说，就相对更加合理。不过，设置一个合理的队列大小，也是非常有讲究的。队列太大导致等待的请求太多，队列太小会导致无法充分利用系统资源、发挥最大性能。

==可以使用 cas + 数组的方式实现无锁并发队列。分布式消息队列，如 kafka 也是一种队列。==







