# 一、简介

消息队列，是分布式系统中重要的组件。

- 主要解决应用耦合，异步消息，流量削锋等问题。
- 可实现高性能，高可用，可伸缩和最终一致性架构，是大型分布式系统不可缺少的中间件。

目前主流的消息队列有

- Kafka
- RabbitMQ
- RocketMQ ，老版本是 MetaQ 。
- ActiveMQ ，目前用的人越来越少了。

另外，消息队列容易和 Java 中的本地 MessageQueue 搞混，所以消息队列更多被称为消息中间件、分布式消息队列等等。

如下图所示：

![MQ 角色](/Users/jack/Desktop/md/images/01-8801949.png)

- 生产者（Producer）：负责产生消息。
- 消费者（Consumer）：负责消费消息
- 消息代理（Message Broker）：负责存储消息和转发消息两件事情。其中，转发消息分为推送和拉取两种方式。
  - 拉取（Pull），是指 Consumer 主动从 Message Broker 获取消息
  - 推送（Push），是指 Message Broker 主动将 Consumer 感兴趣的消息推送给 Consumer 。

# 二、应用场景

一般来说，有四大类使用场景：

- 应用解耦
- 异步处理
- 流量削峰
- 消息通讯
- 日志处理

**其中，应用解耦、异步处理是比较核心的**。

## 1.应用解耦

​	传统模式下，系统间耦合性太强。系统 A 在代码中直接调用系统 B 和系统 C 的代码，如果将来 D 系统接入，系统 A 还需要修改代码，过于麻烦！并且，万一系统 A、B、C 万一还改接口，还要持续跟进。将消息写入消息队列，需要消息的系统自己从消息队列中订阅，从而系统 A 不需要做任何修改。

​	所以，有了消息队列之后，从主动调用的方式，变成了消息的订阅发布( 或者说，事件的发布和监听 )，从而解耦。举个实际场景的例子，用户支付订单完成后，系统需要给用户发红包、增加积分等等行为，就可以通过这样的方式进行解耦。

## 2.异步处理

传统模式下，如下图所示：![传统模式](/Users/jack/Desktop/md/images/05-8802099.png)

A 系统需要串行逐个同步调用系统 B、C、D 。这其中会有很多问题：

- 如果每个系统调用执行是 200ms ，那么这个逻辑就要执行 600ms ，非常慢。
- 如果任一一个系统调用异常报错，那么整个逻辑就报错了。
- 如果任一一个系统调用超时，那么整个逻辑就超时了。

引入消息队列后，如下图所示：![新模式](/Users/jack/Desktop/md/images/06-8802147.png)

- 通过发送 3 条 MQ 消息，通过 Consumer 消费，从而异步、并行调用系统 B、C、D 。
  - 因为发送 MQ 消息是比较快的，假设每个操作 2 ms ，那么这个逻辑只要执行 6 ms ，非常快。
  - 当发送 MQ 消息失败时，可以==异步重试==。当然，可能异步重试的过程中，JVM 进程挂了，此时又需要其他的机制来保证。不过，相比**串行**逐个**同步**调用系统 B、C、D 来说，出错的几率会低很多很多。

另外，使用消息队列进行异步处理，会有一个前提，**返回的结果不依赖于处理的结果。**

## 3.流量削峰

传统模式下，如下图所示：![传统模式](/Users/jack/Desktop/md/images/07-8802221.png)

- 对于大多数系统，一定会有访问量的波峰和波谷。比较明显的，就是我们经常使用的美团外卖，或秒杀。
- 如果在并发量大的时间，所有的请求直接打到数据库，造成数据库直接挂掉。

引入消息队列后，如下图所示：![新模式](/Users/jack/Desktop/md/images/08-8802302.png)

- ==通过将请求先转发到消息队列中==。然后，系统 A 慢慢的按照数据库能处理的并发量，从消息队列中逐步拉取消息进行消费。在**生产中，这个短暂的高峰期积压是允许的**，相比把数据库打挂来说。
- 相比来说，消息队列的性能会比数据库性能更好，并且，横向的扩展能力更强。

## 4.消息通讯

消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现：

- IM 聊天。
- 点对点消息队列。可能大家会比较懵逼，有基于消息队列的 RPC 框架实现，例如 [rabbitmq-jsonrpc](https://github.com/rabbitmq/rabbitmq-jsonrpc) ，虽然现在用的人比较少。
- 面向物联网的 MQTT 。阿里在开源的 RocketMQ 基础上，增加了 MQTT 协议的支持，可见 [消息队列 for IoT](https://cn.aliyun.com/product/ons) 

## 5.日志处理

日志处理，是指将消息队列用在日志处理中，比如 Kafka 的应用，解决大量**日志传输**的问题。

![日志传输](/Users/jack/Desktop/md/images/09-8802413.png)

- 日志采集客户端，负责日志数据采集，定时批量写入 Kafka 队列。
- **Kafka 消息队列，负责日志数据的接收，存储和转发。**
- 日志处理应用：订阅并消费 Kafka 队列中的日志数据。

大家最熟悉的就是 [ELK + Kafka 日志方案](http://www.demodashi.com/demo/10181.html)。

- Kafka ：接收用户日志的消息队列。
- Logstash ：对接 Kafka 写入的日志，做日志解析，统一成 JSON 输出给 Elasticsearch 中。
- Elasticsearch ：实时日志分析服务的核心技术，一个 schemaless ，实时的数据存储服务，通过 index 组织数据，兼具强大的搜索和统计功能。
- Kibana ：基于 Elasticsearch 的数据可视化组件，超强的数据可视化能力是众多公司选择 ELK stack 的重要原因。

























参照：[芋道源码](http://svip.iocoder.cn/MQ/Interview/)