# 一、常见的缓存算法

缓存算法，比较常见的是三种：

- LRU（least recently used ，最近最少使用)
- LFU（Least Frequently used ，最不经常使用)
- FIFO（first in first out ，先进先出)

## **手写 LRU 代码的实现**

​	手写 LRU 代码的实现，有多种方式。其中，最简单的是基于 **LinkedHashMap** 来实现，代码如下：

```java
class LRUCache<K, V> extends LinkedHashMap<K, V> {
    private final int CACHE_SIZE;

    /**
     * 传递进来最多能缓存多少数据
     * @param cacheSize 缓存大小
     */
    public LRUCache(int cacheSize) {
    // true 表示让 LinkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最后访问的放在尾部。
        super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true);
        CACHE_SIZE = cacheSize;
    }

    @Override
    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
        // 当 map 中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。
        return size() > CACHE_SIZE;
    }
    
}
```

> 自我实现：
>
> 实现一：
>
> - 采用了与 HashMap 一样的保存数据方式，只是自己手动实现了一个简易版。
> - 内部采用了一个队列来保存每次写入的数据。
> - 写入的时候判断缓存是否大于了阈值 N，如果满足则根据队列的 FIFO 特性将队列头的数据删除。因为队列头的数据肯定是最先放进去的。
> - **再开启了一个守护线程用于判断最先放进去的数据是否超期（因为就算超期也是最先放进去的数据最有可能满足超期条件。）**
> - 设置为守护线程可以更好的表明其目的（最坏的情况下，如果是一个用户线程最终有可能导致程序不能正常退出，因为该线程一直在运行，守护线程则不会有这个情况。）
>
> 以下代码：就是最近**最少使用**没有满足，删除的数据都是最先放入的数据。

```java
import com.google.common.util.concurrent.ThreadFactoryBuilder;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import java.util.Set;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicInteger;
/**
 * Function:
 * 1.在做 key 生成 hashcode 时是用的 HashMap 的 hash 函数
 * 2.在做 put get 时，如果存在 key 相等时候为了简单没有去比较 equal 和 hashcode
 * 3.限制大小， map的最大size是1024， 超过1024后，就淘汰掉最久没有访问的kv 键值对， 当淘汰时，需要调用一个callback   lruCallback(K key, V value)
 * 是利用每次 put 都将值写入一个内部队列，这样只需要判断队列里的第一个即可。
 * 4.具备超时功能， 当键值对1小时内没有被访问， 就被淘汰掉, 当淘汰时， 需要调用一个callback   timeoutCallback(K key, V value);
 * 超时同理，单独开启一个守护进程来处理，取的是队列里的第一个 因为第一个是最早放进去的。
 * 但是像 HashMap 里的扩容，链表在超过阈值之类的没有考虑进来。
 */
public class LRUAbstractMap extends java.util.AbstractMap {
    private final static Logger LOGGER = LoggerFactory.getLogger(LRUAbstractMap.class);

    //检查是否超期线程
    private ExecutorService checkTimePool ;

    //map 最大size
    private final static int MAX_SIZE = 1024 ;

    private final static ArrayBlockingQueue<Node> QUEUE = new ArrayBlockingQueue<>(MAX_SIZE) ;

    // 默认大小
    private final static int DEFAULT_ARRAY_SIZE =1024 ;
    private int arraySize ;			// 数组大小
    private Object[] arrays ;		// 数组
    private volatile boolean flag = true ;		// 判断是否停止 flag
    private final static Long EXPIRE_TIME = 60 * 60 * 1000L ;	// 超时时间
    private volatile AtomicInteger size  ;		// 整个 Map 的大小
    
    public LRUAbstractMap() {
        arraySize = DEFAULT_ARRAY_SIZE;
        arrays = new Object[arraySize] ;
        //开启一个线程检查最先放入队列的值是否超期
        executeCheckTime();
    }

    /**
     * 开启一个线程检查最先放入队列的值是否超期 设置为守护线程
     */
    private void executeCheckTime() {
        ThreadFactory namedThreadFactory = new ThreadFactoryBuilder()
                .setNameFormat("check-thread-%d")
                .setDaemon(true)
                .build();
        checkTimePool = new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS,
                new ArrayBlockingQueue<>(1),namedThreadFactory,new ThreadPoolExecutor.AbortPolicy());
        checkTimePool.execute(new CheckTimeThread()) ;
    }

    @Override
    public Set<Entry> entrySet() {
        return super.keySet();
    }

    @Override
    public Object put(Object key, Object value) {
        int hash = hash(key);
        int index = hash % arraySize ;
        Node currentNode = (Node) arrays[index] ;
        if (currentNode == null){
            arrays[index] = new Node(null,null, key, value);
            //写入队列
            QUEUE.offer((Node) arrays[index]) ;
            sizeUp();
        }else {
            Node cNode = currentNode ;
            Node nNode = cNode ;
            if (nNode.key == key){		//存在就覆盖
                cNode.val = value ;
            }

            while (nNode.next != null){
                //key 存在 就覆盖 简单判断
                if (nNode.key == key){
                    nNode.val = value ;
                    break ;
                }else {
                    //不存在就新增链表
                    sizeUp();
                    Node node = new Node(nNode,null,key,value) ;
                    //写入队列
                    QUEUE.offer(currentNode) ;
                    cNode.next = node ;
                }
                nNode = nNode.next ;
            }
        }
        return null ;
    }

    @Override
    public Object get(Object key) {
        int hash = hash(key) ;
        int index = hash % arraySize ;
        Node currentNode = (Node) arrays[index] ;
        if (currentNode == null){
            return null ;
        }
        if (currentNode.next == null){
            currentNode.setUpdateTime(System.currentTimeMillis());	//更新时间
            return currentNode ;		 //没有冲突
        }
        Node nNode = currentNode ;
        while (nNode.next != null){
            if (nNode.key == key){
                currentNode.setUpdateTime(System.currentTimeMillis());	//更新时间
                return nNode ;
            }
            nNode = nNode.next ;
        }
        return super.get(key);
    }


    @Override
    public Object remove(Object key) {
        int hash = hash(key) ;
        int index = hash % arraySize ;
        Node currentNode = (Node) arrays[index] ;
        if (currentNode == null){
            return null ;
        }
        if (currentNode.key == key){
            sizeDown();
            arrays[index] = null ;
            QUEUE.poll();		//移除队列
            return currentNode ;
        }
        Node nNode = currentNode ;
        while (nNode.next != null){
            if (nNode.key == key){
                sizeDown();
                //在链表中找到了 把上一个节点的 next 指向当前节点的下一个节点
                nNode.pre.next = nNode.next ;
                nNode = null ;
                QUEUE.poll();		//移除队列
                return nNode;
            }
            nNode = nNode.next ;
        }
        return super.remove(key);
    }

    // 扩容
    private void sizeUp(){
        flag = true ;		//在put值时候认为里边已经有数据了
        if (size == null){
            size = new AtomicInteger() ;
        }
        int size = this.size.incrementAndGet();
        if (size >= MAX_SIZE) {
            //找到队列头的数据
            Node node = QUEUE.poll() ;
            if (node == null){
                throw new RuntimeException("data error") ;
            }
            //移除该 key
            Object key = node.key ;
            remove(key) ;
            lruCallback() ;
        }
    }

   // 缩容
    private void sizeDown(){
        if (QUEUE.size() == 0){
            flag = false ;
        }
        this.size.decrementAndGet() ;
    }

    @Override
    public int size() {
        return size.get() ;
    }

   //链表
    private class Node{
        private Node next ;
        private Node pre ;
        private Object key ;
        private Object val ;
        private Long updateTime ;
        public Node(Node pre,Node next, Object key, Object val) {
            this.pre = pre ;
            this.next = next;
            this.key = key;
            this.val = val;
            this.updateTime = System.currentTimeMillis() ;
        }

        public void setUpdateTime(Long updateTime) {
            this.updateTime = updateTime;
        }

        public Long getUpdateTime() {
            return updateTime;
        }

        @Override
        public String toString() {
            return "Node{" +
                    "key=" + key +
                    ", val=" + val +
                    '}';
        }
    }

    /**
     * copy HashMap 的 hash 实现
     * @param key
     * @return
     */
    public int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    }

    private void lruCallback(){
        LOGGER.debug("lruCallback");
    }


    private class CheckTimeThread implements Runnable{
        @Override
        public void run() {
            while (flag){
                try {
                    Node node = QUEUE.poll();
                    if (node == null){
                        continue ;
                    }
                    Long updateTime = node.getUpdateTime() ;

                    if ((updateTime - System.currentTimeMillis()) >= EXPIRE_TIME){
                        remove(node.key) ;
                    }
                } catch (Exception e) {
                    LOGGER.error("InterruptedException");
                }
            }
        }
    }
}
```

> ## 实现二
>
> - 要记录最近最少使用，那至少需要一个有序的集合来保证写入的顺序。
> - 在使用了数据之后能够更新它的顺序。
>
> 基于以上两点很容易想到一个常用的数据结构：**双向链表**。
>
> 1. **每次写入数据时将数据放入链表头结点。**
> 2. 使用数据时候将数据**移动到头结点**。
> 3. ==缓存数量超过阈值时移除链表尾部数据。==

```java
public class LRUMap<K, V> {
    private final Map<K, V> cacheMap = new HashMap<>();

    //最大缓存大小
    private int cacheSize;
    //节点大小
    private int nodeCount;
    // 头结点
    private Node<K, V> header;
    // 尾结点
    private Node<K, V> tailer;

    public LRUMap(int cacheSize) {
        this.cacheSize = cacheSize;
        //头结点的下一个结点为空
        header = new Node<>();
        header.next = null;
        //尾结点的上一个结点为空
        tailer = new Node<>();
        tailer.tail = null;
        //双向链表 头结点的上结点指向尾结点
        header.tail = tailer;
        //尾结点的下结点指向头结点
        tailer.next = header;
    }

    public void put(K key, V value) {
        cacheMap.put(key, value);
        //双向链表中添加结点，写入头节点
        addNode(key, value);
    }

    public V get(K key){
        Node<K, V> node = getNode(key);
        //移动到头结点
        moveToHead(node) ;
        return cacheMap.get(key);
    }

    private void moveToHead(Node<K,V> node){
        //如果是最后的一个节点
        if (node.tail == null){
            node.next.tail = null ;
            tailer = node.next ;
            nodeCount -- ;
        }
        //如果是本来就是头节点 不作处理
        if (node.next == null){
            return ;
        }

        //如果处于中间节点
        if (node.tail != null && node.next != null){
            //它的上一节点指向它的下一节点 也就删除当前节点
            node.tail.next = node.next ;
            node.next.tail = node.tail;
            nodeCount -- ;
        }

        //最后在头部增加当前节点
        //注意这里需要重新 new 一个对象，不然原本的node 还有着下面的引用，会造成内存溢出。
        node = new Node<>(node.getKey(),node.getValue()) ;
        addHead(node) ;
    }

    /**
     * 链表查询 效率较低
     * @param key
     * @return
     */
    private Node<K,V> getNode(K key){
        Node<K,V> node = tailer ;
        while (node != null){
            if (node.getKey().equals(key)){
                return node ;
            }
            node = node.next ;
        }
        return null ;
    }

    /**
     * 写入头结点
     * @param key
     * @param value
     */
    private void addNode(K key, V value) {
        Node<K, V> node = new Node<>(key, value);
        //容量满了删除最后一个
        if (cacheSize == nodeCount) {
            //删除尾结点
            delTail();
        }
        //写入头结点
        addHead(node);
    }
    
    /**
     * 添加头结点
     * @param node
     */
    private void addHead(Node<K, V> node) {
        //写入头结点
        header.next = node;
        node.tail = header;
        header = node;
        nodeCount++;
        //如果写入的数据大于2个 就将初始化的头尾结点删除
        if (nodeCount == 2) {
            tailer.next.next.tail = null;
            tailer = tailer.next.next;
        }
    }

    private void delTail() {
        //把尾结点从缓存中删除
        cacheMap.remove(tailer.getKey());
        //删除尾结点
        tailer.next.tail = null;
        tailer = tailer.next;
        nodeCount--;
    }

    private class Node<K, V> {
        private K key;
        private V value;
        Node<K, V> tail;
        Node<K, V> next;
        public Node(K key, V value) {
            this.key = key;
            this.value = value;
        }
        public Node() {
        }
        public K getKey() {
            return key;
        }
        public void setKey(K key) {
            this.key = key;
        }
        public V getValue() {
            return value;
        }
        public void setValue(V value) {
            this.value = value;
        }
    }

    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder() ;
        Node<K,V> node = tailer ;
        while (node != null){
            sb.append(node.getKey()).append(":")
                    .append(node.getValue())
                    .append("-->") ;
            node = node.next ;
        }
        return sb.toString();
    }
}
```

> 实际效果，写入时：
>
> ```java
> @Test
>     public void put() throws Exception {
>         LRUMap<String,Integer> lruMap = new LRUMap(3) ;
>         lruMap.put("1",1) ;
>         lruMap.put("2",2) ;
>         lruMap.put("3",3) ;
>         System.out.println(lruMap.toString());
>         lruMap.put("4",4) ;
>         System.out.println(lruMap.toString());
>         lruMap.put("5",5) ;
>         System.out.println(lruMap.toString());
>     }
> 
> //输出：
> 1:1-->2:2-->3:3-->
> 2:2-->3:3-->4:4-->
> 3:3-->4:4-->5:5-->
> ```
>
> 使用时：
>
> ```java
> @Test
>     public void get() throws Exception {
>         LRUMap<String,Integer> lruMap = new LRUMap(3) ;
>         lruMap.put("1",1) ;
>         lruMap.put("2",2) ;
>         lruMap.put("3",3) ;
>         System.out.println(lruMap.toString());
>         System.out.println("==============");
>         Integer integer = lruMap.get("1");
>         System.out.println(integer);
>         System.out.println("==============");
>         System.out.println(lruMap.toString());
>     }
> //输出
> 1:1-->2:2-->3:3-->
> ==============
> 1
> ==============
> 2:2-->3:3-->1:1-->
> ```
>
> - 数据是直接利用 HashMap 来存放的。
> - 内部使用了一个双向链表来存放数据，所以有一个头结点 header，以及尾结点 tailer。
> - 每次写入头结点，删除尾结点时都是依赖于 header tailer。
> - 使用数据移动到链表头时，第一步是需要在双向链表中找到该节点。这里就体现出链表的问题了。查找效率很低，最差需要 `O(N)`。之后依赖于当前节点进行移动。
> - 在写入头结点时有判断链表大小等于 2 时需要删除初始化的头尾结点。这是因为初始化时候生成了两个双向节点，没有数据只是为了形成一个数据结构。当真实数据进来之后需要删除以方便后续的操作（这点可以继续优化）。
> - 以上的所有操作都是线程不安全的，需要使用者自行控制。
>
> ### 初始化时
>
> ![img](/Users/jack/Desktop/md/images/5cd1d7b842ebd.jpg)
>
> ### 写入数据时
>
> ```java 
> LRUMap<String,Integer> lruMap = new LRUMap(3) ;
> lruMap.put("1",1) ;
> lruMap.put("2",2) ;
> lruMap.put("3",3) ;
> lruMap.put("4",4) ;
> ```
>
> ![img](/Users/jack/Desktop/md/images/5cd1d7bace008.jpg)
>
> ![img](/Users/jack/Desktop/md/images/5cd1d7bdae29e.jpg)
>
> ![img](/Users/jack/Desktop/md/images/5cd1d7bf974c6.jpg)
>
> ![img](/Users/jack/Desktop/md/images/5cd1d7c26fee5.jpg)
>
> ### 获取数据时
>
> ```java
> Integer integer = lruMap.get("2");
> ```
>
> ![img](/Users/jack/Desktop/md/images/5cd1d7c54a763.jpg)

参照：[《动手实现一个 LRU Cache》](https://crossoverjie.top/2018/04/07/algorithm/LRU-cache/)

在 Java 后端开发中，常见的缓存工具和框架列举如下：

- 本地缓存：Guava LocalCache、Ehcache、Caffeine 。
  - Ehcache 的功能更加丰富，Caffeine 的性能要比 Guava LocalCache 好。
- 分布式缓存：Redis、MemCache、Tair 。
  - Redis 最为主流和常用。

# 二、缓存存在的问题及应对措施

![image.png-276.4kB](/Users/jack/Desktop/md/images/image.png)

## 1.缓存穿透

​	指查询一个一定不存在的数据，由于缓存是不命中时被动写( *被动写，指的是从 DB 查询到数据，则更新到缓存中* )的，并且处于容错考虑，**如果从 DB 查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到 DB 去查询，失去了缓存的意义。**

> 缓存穿透问题可能会使后端存储负载加大，由于很多后端存储不具备高并发性，甚至可能造成后端存储宕掉。通常可以在程序中分别统计总调用数、缓存层命中数、存储层命中数，如果发现大量存储层空命中，可能就是出现了缓存穿透问题。
>
> 参照：[Redis架构之防雪崩设计：网站不宕机背后的兵法](https://mp.weixin.qq.com/s/TBCEwLVAXdsTszRVpXhVug)

​	在流量大时，可能 DB 就挂掉了，要是有人利用不存在的 key 频繁攻击我们的应用，这就是漏洞。如下图：

![é"å®¢æ"å"](/Users/jack/Desktop/md/images/01-20190529003825986.png)

### 有两种方案可以解决：

- ==方案一，缓存空对象==：当从 DB 查询数据为空，我们仍然**将这个空结果进行缓存，具体的值需要使用特殊的标识，能和真正缓存的数据区分开。另外，需要设置较短的过期时间，一般建议不要超过 5 分钟。**

  > 缓存空对象会有两个问题：
  >
  > 第一，空值做了缓存，**意味着缓存层中存了更多的键，需要更多的内存空间** ( 如果是攻击，问题更严重 )，==比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除==。
  >
  > 第二，缓存层和存储层的数据会有一段时间窗口的不一致，可能会对业务有一定影响。例如过期时间设置为 5 分钟，如果此时存储层添加了这个数据，那此段时间就会出现缓存层和存储层数据的不一致，此时可以利用消息系统或者其他方式清除掉缓存层中的空对象。
  >
  > 伪代码：
  >
  > ![image-20190605212802296](/Users/jack/Desktop/md/images/image-20190605212802296.png)

- ==方案二，BloomFilter 布隆过滤器==：在缓存服务的基础上，构建 BloomFilter 数据结构，在 BloomFilter 中存储对应的 KEY 是否存在，如果存在，说明该 KEY 对应的值为空。那么整个逻辑的如下：

  - 1、根据 KEY 查询缓存。如果存在对应的值，直接返回；如果不存在，继续向下执行。
  - 2、根据 KEY 查询在缓存 BloomFilter 的值。如果存在值，说明该 KEY 不存在对应的值，直接返回空；如果不存在值，继续向下执行。
  - 3、查询 DB 对应的值，如果存在，则更新到缓存，并返回该值。如果不存在值，更新到 缓存 BloomFilter 中，并返回空。

  > 如下图所示，在访问缓存层和存储层之前，将存在的 key 用布隆过滤器提前保存起来，做第一层拦截。例如： 一个个性化推荐系统有 4 亿个用户 ID，每个小时算法工程师会根据每个用户之前历史行为做出来的个性化放到存储层中，但是最新的用户由于没有历史行为，就会发生缓存穿透的行为，为此可以将所有有个性化推荐数据的用户做成布隆过滤器。如果布隆过滤器认为该用户 ID 不存在，那么就不会访问存储层，在一定程度保护了存储层。
  >
  > ![image-20190605212919537](/Users/jack/Desktop/md/images/image-20190605212919537.png)
  >
  > 可以利用 Redis 的 Bitmaps 实现布隆过滤器，GitHub 上已经开源了类似的方案，可以进行参考：
  >
  > https://github.com/erikdubbelboer/Redis-Lua-scaling-bloom-filter
  >
  > **这种方法适用于数据命中不高，数据相对固定实时性低（通常是数据集较大）的应用场景**，代码维护较为复杂，但是缓存空间占用少。

> 本质上布隆过滤器是一种数据结构，比较巧妙的概率型数据结构（probabilistic data structure），特点是高效地插入和查询，可以用来告诉你 “某样东西一定不存在或者可能存在”。
>
> 布隆过滤器是一个 bit 向量或者说 bit 数组，长这样：
>
> ![image-20190529004822040](/Users/jack/Desktop/md/images/image-20190529004822040.png)
>
> 对于每个key，只需要k个比特位，每个存储一个标志，用来判断key是否在集合中。
>
> 1. 首先需要k个hash函数，每个函数可以把key散列成为1个整数
> 2. 初始化时，需要一个长度为n比特的数组，每个比特位初始化为0
> 3. 某个key加入集合时，用k个hash函数计算出k个散列值，并把数组中对应的比特位置为1
> 4. 判断某个key是否在集合时，用k个hash函数计算出k个散列值，并查询数组中对应的比特位，如果所有的比特位都是1，认为在集合中。
>
> 参照：<https://www.jianshu.com/p/2104d11ee0a2>
>
> <https://www.cnblogs.com/liyulong1982/p/6013002.html>

两者比较：

|          | 缓存空对象                                            | BloomFilter 布隆过滤器                     |
| -------- | ----------------------------------------------------- | ------------------------------------------ |
| 适用场景 | 1、数据命中不高  2、保证一致性                        | 1、数据命中不高  2、数据相对固定、实时性低 |
| 维护成本 | 1、代码维护简单  2、需要过多的缓存空间  3、数据不一致 | 1、代码维护复杂  2、缓存空间占用小         |

## 2.缓存雪崩

​	==缓存雪崩，是指缓存由于某些原因无法提供服务( 例如，缓存挂掉了 )，所有请求全部达到 DB 中，导致 DB 负荷大增，最终挂掉的情况。==

​	从下图可以很清晰出什么是缓存雪崩：**由于缓存层承载着大量请求，有效的保护了存储层，但是如果缓存层由于某些原因整体不能提供服务，于是所有的请求都会达到存储层，存储层的调用量会暴增，造成存储层也会挂掉的情况。** 缓存雪崩的英文原意是 stampeding herd（奔逃的野牛），指的是缓存层宕掉后，流量会像奔逃的野牛一样，打向后端存储。

![image-20190605214256829](/Users/jack/Desktop/md/images/image-20190605214256829.png)

### 解决方案

1）缓存高可用

​	通过搭建缓存的高可用，避免缓存挂掉导致无法提供服务的情况，从而降低出现缓存雪崩的情况。

> 假设我们使用 Redis 作为缓存，则可以使用 Redis Sentinel 或 Redis Cluster 实现高可用。

2）本地缓存

如果使用本地缓存时，即使分布式缓存挂了，也可以将 DB 查询到的结果缓存到本地，避免后续请求全部到达 DB 中。当然，引入本地缓存也会有相应的问题，例如说：

- 本地缓存的实时性怎么保证？

  - 方案一，可以引入消息队列。在数据更新时，发布数据更新的消息；而进程中有相应的消费者消费该消息，从而更新本地缓存。

    > 也可以使用 Redis Pub / Sub 取代消息队列来实现，但此时 Redis 可能已经挂了，所以也不一定合适。

  - 方案二，设置较短的过期时间，请求时从 DB 重新拉取。

  - 方案三，手动设置Redis过期时间。

- 每个进程可能会本地缓存相同的数据，导致数据浪费？

  - 方案一，需要配置本地缓存的过期策略和缓存数量上限。

> 如果我们使用 JVM ，则可以使用 Ehcache、Guava Cache 实现本地缓存的功能。

3）请求 DB 限流

通过限制 DB 的每秒请求数，避免把 DB 也打挂了。这样至少能有两个好处：

1. 可能有一部分用户，还可以使用，系统还没死透。
2. 未来缓存服务恢复后，系统立即就已经恢复，无需在处理 DB 也挂掉的情况。

> 如果我们使用 Java ，则可以使用 Guava RateLimiter、Sentinel 实现限流的功能。

4）服务降级

​	如果请求被限流，或者请求 DB 超时，我们可以服务降级，提供一些默认的值，或者友情提示，甚至空白的值也行。

如果我们使用 Java ，则可以使用 Hystrix、Sentinel 实现限流的功能。

5）提前演练

在项目上线前，演练缓存宕掉后，应用以及后端的负载情况以及可能出现的问题，在此基础上做一些预案设定。

## 3.缓存击穿

​	缓存击穿，是指某个**极度“热点”**数据在某个时间点过期时，==恰好在这个时间点对这个 KEY 有大量的并发请求过来，这些请求发现缓存过期一般都会从 DB 加载数据并回设到缓存，但是这个时候大并发的请求可能会瞬间 DB 压垮。==

- 对于一些设置了过期时间的 KEY ，如果这些 KEY 可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑这个问题。

  > 重建缓存不能在短时间完成，可能是一个复杂计算，例如复杂的 SQL、多次 IO、多个依赖等。
  >
  > 在缓存失效的瞬间，有大量线程来重建缓存 ( 如下图)，造成后端负载加大，甚至可能会让应用崩溃。
  >
  > ![image-20190605215447772](/Users/jack/Desktop/md/images/image-20190605215447772.png)

- 缓存被“击穿”的问题，和缓存“雪崩“”的区别在于，**前者针对某一 KEY 缓存，后者则是很多 KEY 。**

- 缓存被“击穿”的问题，和缓存“穿透“”的区别在于，这个 KEY 是真实存在对应的值的。

### 解决方案

- 方案一，**使用互斥锁**：请求发现缓存不存在后，去查询 DB 前，使用分布式锁，保证有且只有一个线程去查询 DB ，并更新到缓存。流程如下：

  - 1、获取分布式锁，直到成功或超时。如果超时，则抛出异常，返回。如果成功，继续向下执行。
  - 2、再去缓存中。如果存在值，则直接返回；如果不存在，则继续往下执行。因为，获得到锁，可能已经被“那个”线程去查询过 DB ，并更新到缓存中了。
  - 3、查询 DB ，并更新到缓存中，返回值。

  > ![image-20190605220012079](/Users/jack/Desktop/md/images/image-20190605220012079.png)
  >
  > 下面代码使用 Redis 的 setnx 命令实现上述功能。
  >
  > ![image-20190605215931152](/Users/jack/Desktop/md/images/image-20190605215931152.png)

- 方案二，**手动过期**：缓存上从不设置过期时间，功能上将过期时间存在 KEY 对应的 VALUE 里，如果发现要过期，通过一个后台的异步线程进行缓存的构建，也就是“手动”过期。通过后台的异步线程，保证有且只有一个线程去查询 DB。

  > 整个过程如下图所示：
  >
  > ![image-20190605220158219](/Users/jack/Desktop/md/images/image-20190605220158219.png)
  >
  > 从实战看，此方法有效杜绝了热点 key 产生的问题，但唯一不足的就是重构缓存期间，会出现数据不一致的情况，这取决于应用方是否容忍这种不一致。下面代码使用 Redis 进行模拟：
  >
  > ![image-20190605220233727](/Users/jack/Desktop/md/images/image-20190605220233727.png)

​	作为一个并发量较大的应用，**在使用缓存时有三个目标：第一，加快用户访问速度，提高用户体验。第二，降低后端负载，减少潜在的风险，保证系统平稳。第三，保证数据“尽可能”及时更新。下面将按照这三个维度对上述两种解决方案进行分析。**

- 互斥锁 (mutex key)：这种方案思路比较简单，但是存在一定的隐患，如果构建缓存过程出现问题或者时间较长，可能会存在死锁和线程池阻塞的风险，但是这种方法能够较好的降低后端存储负载并在一致性上做的比较好。
- " 永远不过期 "：这种方案由于没有设置真正的过期时间，实际上已经不存在热点 key 产生的一系列危害，但是会存在数据不一致的情况，同时代码复杂度会增大。

这两个方案，各有其优缺点。

|      | 使用互斥锁                           | 手动过期                  |
| ---- | ------------------------------------ | ------------------------- |
| 优点 | 1、思路简单  2、保证一致性           | 1、性价最佳，用户无需等待 |
| 缺点 | 1、代码复杂度增大  2、存在死锁的风险 | 1、无法保证缓存一致性     |

# 三、缓存和DB的一致性

## **产生原因**

主要有两种情况，会导致缓存和 DB 的一致性问题：

1. 并发的场景下，导致读取老的 DB 数据，更新到缓存中。
2. 缓存和 DB 的操作，不在一个事务中，可能只有一个操作成功，而另一个操作失败，导致不一致。

当然，有一点我们要注意，缓存和 DB 的一致性，我们**指的更多的是最终一致性**。我们**使用缓存只要是提高读操作的性能，真正在写操作的业务逻辑，还是以数据库为准。**例如说，我们可能缓存用户钱包的余额在缓存中，在前端查询钱包余额时，读取缓存，在使用钱包余额时，读取数据库。

## 更新缓存的设计模式

### 1.Cache Aside Pattern(旁路缓存)

这是最常用最常用的pattern了。其具体逻辑如下：

- **失效**：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。

- **命中**：应用程序从cache中取数据，取到后返回。

- **更新**：先把数据存到数据库中，成功后，再让缓存失效。

![Cache-Aside-Design-Pattern-Flow-Diagram](/Users/jack/Desktop/md/images/Cache-Aside-Design-Pattern-Flow-Diagram-e1470471723210.png)

![Updating-Data-using-the-Cache-Aside-Pattern-Flow-Diagram-1](/Users/jack/Desktop/md/images/Updating-Data-using-the-Cache-Aside-Pattern-Flow-Diagram-1-e1470471761402.png)

​	一个是查询操作，一个是更新操作的并发，首先，没有了删除cache数据的操作了，而是先更新了数据库中的数据，此时，缓存依然有效，所以，并发的查询操作拿的是没有更新的数据，但是，更新操作马上让缓存的失效了，后续的查询操作再把数据从数据库中拉出来。而不会像文章开头的那个逻辑产生的问题，后续的查询操作一直都在取老的数据。

> **要么通过2PC或是Paxos协议保证一致性，要么就是拼命的降低并发时脏数据的概率，而Facebook使用了这个降低概率的玩法，因为2PC太慢，而Paxos太复杂。当然，最好还是为缓存设置上过期时间。**

### 2.Read/Write Through Pattern

​	在上面的Cache Aside套路中，我们的应用代码需要维护两个数据存储，**一个是缓存（Cache），一个是数据库（Repository）。**所以，应用程序比较啰嗦。而==Read/Write Through套路是把更新数据库（Repository）的操作由缓存自己代理了，所以，对于应用层来说，就简单很多了==。**可以理解为，应用认为后端就是一个单一的存储，而存储自己维护自己的Cache。**

#### Read Through

​	Read Through 套路就是**在查询操作中更新缓存**，也就是说，==当缓存失效的时候（过期或LRU换出），Cache Aside是由调用方负责把数据加载入缓存，而Read Through则用缓存服务自己来加载，从而对应用方是透明的。==

#### Write Through

​	Write Through 套路和Read Through相仿，**不过是在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作）**

下图自来Wikipedia的[Cache词条](https://en.wikipedia.org/wiki/Cache_(computing))。其中的Memory你可以理解为就是我们例子里的数据库。

![Write-through_with_no-write-allocation](/Users/jack/Desktop/md/images/460px-Write-through_with_no-write-allocation.svg_.png)

### 3.Write Behind Caching Pattern

​	Write Behind 又叫 Write Back。**write back就是Linux文件系统的Page Cache的算法**。

==Write Back套路，一句说就是，在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。==

> 这个设计的好处就是让数据的I/O操作飞快无比（因为直接操作内存嘛 ），因为异步，write backg还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。

​	但是，其带来的问题是，数据不是强一致性的，而且可能会丢失（我们知道Unix/Linux非正常关机会导致数据丢失，就是因为这个事）。在软件设计上，我们基本上不可能做出一个没有缺陷的设计，就像算法设计中的时间换空间，空间换时间一个道理，有时候，强一致性和高性能，高可用和高性性是有冲突的。软件设计从来都是取舍Trade-Off。

另外，Write Back实现逻辑比较复杂，因为他需要track有哪数据是被更新了的，需要刷到持久层上。操作系统的write back会在仅当这个cache需要失效的时候，才会被真正持久起来，比如，内存不够了，或是进程退出了等情况，这又叫lazy write。

在wikipedia上有一张write back的流程图，基本逻辑如下：

![Write-back_with_write-allocation](/Users/jack/Desktop/md/images/Write-back_with_write-allocation.png)

参照：左耳朵耗子[《缓存更新的套路》](https://coolshell.cn/articles/17416.html)

## 缓存架构设计：

### 1.更新缓存 VS 淘汰缓存

更新缓存：数据不但写入数据库，还会写入缓存；优点：缓存不会增加一次miss，命中率高

淘汰缓存：数据只会写入数据库，不会写入缓存，只会把数据淘汰掉；优点：简单

**这两者的选择主要取决于“更新缓存的复杂度”。**

> 例如，上述场景，只是简单的把余额money设置成一个值，那么：
>
> （1）淘汰缓存的操作为deleteCache(uid)
>
> （2）更新缓存的操作为setCache(uid, money)
>
> 更新缓存的代价很小，此时我们应该更倾向于更新缓存，以保证更高的缓存命中率
>
> 如果余额是通过很复杂的数据计算得出来的，例如业务上除了账户表account，还有商品表product，折扣表discount
>
> account(uid, money)
>
> product(pid, type, price, pinfo)
>
> discount(type, zhekou)
>
> 业务场景是用户买了一个商品product，这个商品的价格是price，这个商品从属于type类商品，type类商品在做促销活动要打折扣zhekou，购买了商品过后，这个余额的计算就复杂了，需要：
>
> （1）先把商品的品类，价格取出来：SELECT type, price FROM product WHERE pid=XXX
>
> （2）再把这个品类的折扣取出来：SELECT zhekou FROM discount WHERE type=XXX
>
> （3）再把原有余额从缓存中查询出来money = getCache(uid)
>
> （4）再把新的余额写入到缓存中去setCache(uid, money-price*zhekou)
>
> 更新缓存的代价很大，此时我们应该更倾向于淘汰缓存。

**总之，淘汰缓存操作简单，并且带来的副作用只是增加了一次cache miss，建议作为通用的处理方式。**

### 2.先操作数据库 vs 先操作缓存

当写操作发生时，假设淘汰缓存作为对缓存通用的处理方式，又面临两种抉择：

（1）先写数据库，再淘汰缓存

（2）先淘汰缓存，再写数据库

对于一个不能保证事务性的操作，一定涉及“哪个任务先做，哪个任务后做”的问题，解决这个问题的方向是：**如果出现不一致，谁先做对业务的影响较小，就谁先执行。**

由于写数据库与淘汰缓存不能保证原子性，谁先谁后同样要遵循上述原则。

![db与cache不一致](/Users/jack/Desktop/md/images/1493892726802117.jpg)

假设先写数据库，再淘汰缓存：第一步写数据库操作成功，第二步淘汰缓存失败，则会出现DB中是新数据，Cache中是旧数据，数据不一致。

![db中修改失败](/Users/jack/Desktop/md/images/1493892821722805.jpg)

假设先淘汰缓存，再写数据库：第一步淘汰缓存成功，第二步写数据库失败，则只会引发一次Cache miss。

**结论：数据和缓存的操作时序：先淘汰缓存，再写数据库。**

### 3.缓存架构优化

![业务线需同时关注db与cache](https://7n.w3cschool.cn/attachments/image/20170504/1493892943880057.jpg)

上述缓存架构有一个**缺点**：业务方需要同时关注缓存与DB，主要有两种优化方案：

![主流优化方案](/Users/jack/Desktop/md/images/1493893048550264.jpg)

一种方案是服务化：加入一个服务层，向上游提供帅气的数据访问接口，向上游屏蔽底层数据存储的细节，这样业务线不需要关注数据是来自于cache还是DB。

![非主流方案](/Users/jack/Desktop/md/images/1493893153380835.jpg)

另一种方案是**异步缓存更新**：业务线所有的写操作都走数据库，所有的读操作都总缓存，由一个异步的工具来做数据库与缓存之间数据的同步，具体细节是：

（1）要有一个init cache的过程，将需要缓存的数据全量写入cache

（2）如果DB有写操作，异步更新程序读取binlog，更新cache

在（1）和（2）的合作下，cache中有全部的数据，这样：

（a）业务线读cache，一定能够hit（很短的时间内，可能有脏数据），无需关注数据库

（b）业务线写DB，cache中能得到异步更新，无需关注缓存

这样将**大大简化业务线的调用逻辑**，存在的缺点是，如果缓存的数据业务逻辑比较复杂，async-update异步更新的逻辑可能也会比较复杂。

### 4.结论：

（1）淘汰缓存是一种通用的缓存处理方式

（2）**先淘汰缓存，再写数据库**

（3）服务化是向业务方屏蔽底层数据库与缓存复杂性的一种通用方式

参照：沈剑[《缓存架构设计细节二三事》](https://www.w3cschool.cn/architectroad/architectroad-cache-architecture-design.html)

## 缓存和DB一致性的解决方案

### 1）先淘汰缓存，再写数据库

​	因为先淘汰缓存，所以数据的最终一致性是可以得到有效的保证的。因为先淘汰缓存，即使写数据库发生异常，也就是下次缓存读取时，多读取一次数据库。

​	但是，这种方案会存在缓存和 DB 的数据会不一致的情况，参照[《缓存与数据库一致性优化》](https://www.w3cschool.cn/architectroad/architectroad-consistency-of-cache-with-database.html) 所说。

我们需要解决缓存并行写，实现串行写。比较简单的方式，引入分布式锁。

- 在写请求时，先淘汰缓存之前，获取该分布式锁。
- 在读请求时，发现缓存不存在时，先获取分布式锁。

> 这样，缓存的并行写就成功的变成串行写落。写请求时，是否主动更新缓存，根据自己业务的需要，是否有，都没问题。

### 2）先写数据库，再更新缓存

按照“先写数据库，再更新缓存”，我们要保证 DB 和缓存的操作，能够在“同一个事务”中，从而实现最终一致性。

#### **基于定时任务来实现**

- 首先，写入数据库。
- 然后，在写入数据库所在的事务中，插入一条记录到任务表。该记录会存储需要更新的缓存 KEY 和 VALUE 。
- 【异步】最后，定时任务每秒扫描任务表，更新到缓存中，之后删除该记录。

#### **基于消息队列来实现**

- 首先，写入数据库。
- 然后，发送带有缓存 KEY 和 VALUE 的事务消息。此时，需要有支持事务消息特性的消息队列，或者我们自己封装消息队列，支持事务消息。
- 【异步】最后，消费者消费该消息，更新到缓存中。

这两种方式，可以进一步优化，**可以先尝试更新缓存，如果失败，则插入任务表，或者事务消息。**

另外，极端情况下，如果并发写执行时，先更新成功 DB 的，结果后更新缓存：

![image-20190607224201276](/Users/jack/Desktop/md/images/image-20190607224201276.png)

- 理论来说，希望的更新缓存顺序是，线程 1 快于线程 2 ，但是实际线程1 晚于线程 2 ，导致数据不一致。
- 图中一直是基于定时任务或消息队列来实现异步更新缓存，如果网络抖动，导致【插入任务表，或者事务消息】的顺序不一致。
- 那么怎么解决呢？需要做如下三件事情：
  - 1、在缓存值中，拼接上数据版本号或者时间戳。例如说：`value = {value: 原值, version: xxx}` 。
  - 2、在任务表的记录，或者事务消息中，增加上数据版本号或者时间戳的字段。
  - 3、在定时任务或消息队列执行更新缓存时，先读取缓存，对比版本号或时间戳，大于才进行更新。 当然，此处也会有并发问题，所以还是得引入分布式锁或 CAS 操作。
    - 关于 Redis 分布式锁，可以看看 [《精尽 Redis 面试题》](http://svip.iocoder.cn/Redis/Interview) 的 [「如何使用 Redis 实现分布式锁？」](http://svip.iocoder.cn/Cache/Interview/#) 问题。
    - 关于 Redis CAS 操作，可以看看 [《精尽 Redis 面试题》](http://svip.iocoder.cn/Redis/Interview) 的 [「什么是 Redis 事务？」](http://svip.iocoder.cn/Cache/Interview/#) 问题。

### 3) 基于数据库的 binlog 日志

> **1、重客户端**

**写入缓存：**

![image.png](/Users/jack/Desktop/md/images/1240-20190607224223418.png)

- 应用同时更新数据库和缓存
- 如果数据库更新成功，则开始更新缓存，否则如果数据库更新失败，则整个更新过程失败。
- 判断更新缓存是否成功，如果成功则返回
- 如果缓存没有更新成功，则将数据发到MQ中
- 应用监控MQ通道，收到消息后继续更新Redis。

**问题点：**如果更新Redis失败，同时在将数据发到MQ之前的时间，应用重启了，这时候MQ就没有需要更新的数据，如果Redis对所有数据没有设置过期时间，同时在读多写少的场景下，只能通过人工介入来更新缓存。

**读缓存：**

如何来解决这个问题？那么**在写入Redis数据的时候，在数据中增加一个时间戳插入到Redis中。**在从Redis中读取数据的时候，首先要判断一下当前时间有没有过期，如果没有则从缓存中读取，如果过期了则从数据库中读取最新数据覆盖当前Redis数据并更新时间戳。具体过程如下图所示：

![image.png](/Users/jack/Desktop/md/images/1240.png)

> **2、客户端数据库与缓存解耦**

​	上述方案对于应用的研发人员来讲比较重，需要研发人员同时考虑数据库和Redis是否成功来做不同方案，如何让研发人员只关注数据库层面，而不用关心缓存层呢？请看下图：
![image.png](/Users/jack/Desktop/md/images/1240-20190607224223219.png)

- 应用直接写数据到数据库中。
- 数据库更新binlog日志。
- 利用Canal中间件读取binlog日志。
- Canal借助于限流组件按频率将数据发到MQ中。
- 应用监控MQ通道，将MQ的数据更新到Redis缓存中。

可以看到这种方案对研发人员来说比较轻量，不用关心缓存层面，而且这个方案虽然比较重，但是却容易形成统一的解决方案。

参照： [《技术专题讨论第五期：论系统架构设计中缓存的重要性》](http://www.spring4all.com/question/177)

> PS：下面这两种比较实用
>
> - “**先淘汰缓存，再写数据库**”的方案，并且无需引入分布式锁。
> - “**先写数据库，再更新缓存**”的方案，并且无需引入定时任务或者消息队列。
>
> 使用缓存过程中，经常会遇到缓存数据的不一致性和脏读现象。一般情况下，采取缓存双淘汰机制，在更新数据库的**前**淘汰缓存。此外，设定超时时间，例如三十分钟。
>
> **极端场景下，即使有脏数据进入缓存，这个脏数据也最存在一段时间后自动销毁。**

另外，在 DB 主从架构下，方案会更加复杂。详细可以看看 [《主从 DB 与 cache 一致性优化》](https://www.w3cschool.cn/architectroad/architectroad-consistency-of-cache-with-master-and-slave-database.html) 。

# 四、缓存预热

​	在刚启动的缓存系统中，如果缓存中没有任何数据，如果依靠用户请求的方式重建缓存数据，那么对数据库的压力非常大，而且系统的性能开销也是巨大的。

​	此时，最好的策略是启动时就把热点数据加载好。这样，用户请求时，直接读取的就是缓存的数据，而无需去读取 DB 重建缓存数据。

​	举个例子，热门的或者推荐的商品，需要提前预热到缓存中。

一般来说，有如下几种方式来实现：

> 1. 数据量不大时，项目启动时，自动进行初始化。
> 2. 写个修复数据脚本，手动执行该脚本。
> 3. 写个管理界面，可以手动点击，预热对应的数据到缓存中。

## 五、缓存数据的淘汰策略

​	除了缓存服务器自带的缓存**自动**失效策略之外，我们还可以根据具体的业务需求进行自定义的**“手动”**缓存淘汰，常见的策略有两种：

- 1、定时去清理过期的缓存。
- 2、当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。

**两者各有优劣，第一种的缺点是维护大量缓存的 key 是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！**

# 六、缓存如何存储 POJO 对象

实际场景下，**缓存值可能是一个 POJO 对象，就需要考虑如何 POJO 对象存储的问题**。目前有两种方式：

- 方案一，将 POJO 对象序列化进行存储，适合 Redis 和 Memcached 。

  > ​	当我们的数据存储到Redis的时候，我们的键（key）和值（value）都是通过Spring提供的Serializer序列化到数据库的。RedisTemplate默认使用的是JdkSerializationRedisSerializer，StringRedisTemplate默认使用的是StringRedisSerializer。
  >
  > ​	**Spring Data JPA为我们提供了下面的Serializer：GenericToStringSerializer、Jackson2JsonRedisSerializer、JacksonJsonRedisSerializer、JdkSerializationRedisSerializer、OxmSerializer、StringRedisSerializer。**
  >
  > 序列化方式对比：
  >
  > JdkSerializationRedisSerializer: 使用JDK提供的序列化功能。 优点是反序列化时不需要提供类型信息(class)，但缺点是需要实现Serializable接口，还有序列化后的结果非常庞大，是JSON格式的5倍左右，这样就会消耗redis服务器的大量内存。
  >
  > Jackson2JsonRedisSerializer： 使用Jackson库将对象序列化为JSON字符串。优点是速度快，序列化后的字符串短小精悍，不需要实现Serializable接口。但缺点也非常致命，那就是此类的构造函数中有一个类型参数，必须提供要序列化对象的类型信息(.class对象)。 通过查看源代码，发现其只在反序列化过程中用到了类型信息。

  - 参考 [《Redis 序列化方式StringRedisSerializer、FastJsonRedisSerializer和KryoRedisSerializer》](https://blog.csdn.net/xiaolyuh123/article/details/78682200) 。

- 方案二，使用 Hash 数据结构，适合 Redis 。

  - 可参考 [《Redis 之序列化 POJO》](https://my.oschina.net/yuyidi/blog/499951) 文章。

参照：芋道源码
